{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73dcde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    lr = 1e-3\n",
    "    batch = 4096\n",
    "    tstBat = 4096\n",
    "    reg = 1e-5\n",
    "    epoch = 200\n",
    "    latdim = 32\n",
    "    gnn_layer = 2\n",
    "    topk = 10\n",
    "    #data = 'yelp'\n",
    "    ssl_reg = 0.1\n",
    "    ib_reg = 0.1\n",
    "    temp = 0.5\n",
    "    tstEpoch = 1\n",
    "    gpu = -1\n",
    "    lambda0 = 1e-4\n",
    "    gamma = -0.45\n",
    "    zeta = 1.05\n",
    "    init_temperature = 2.0\n",
    "    temperature_decay = 0.98\n",
    "    eps = 1e-3\n",
    "    seed = 421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f89e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='ml-100k'\n",
    "dataset_folder='ml'\n",
    "preflix_folder='24_07_19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0911bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def innerProduct(usrEmbeds, itmEmbeds):\n",
    "    return t.sum(usrEmbeds * itmEmbeds, dim=-1)\n",
    "\n",
    "def pairPredict(ancEmbeds, posEmbeds, negEmbeds):\n",
    "    return innerProduct(ancEmbeds, posEmbeds) - innerProduct(ancEmbeds, negEmbeds)\n",
    "\n",
    "def calcRegLoss(model):\n",
    "    ret = 0\n",
    "    for W in model.parameters():\n",
    "        ret += W.norm(2).square()\n",
    "    return ret\n",
    "\n",
    "def contrastLoss(embeds1, embeds2, nodes, temp):\n",
    "    embeds1 = F.normalize(embeds1, p=2)\n",
    "    embeds2 = F.normalize(embeds2, p=2)\n",
    "    pckEmbeds1 = embeds1[nodes]\n",
    "    pckEmbeds2 = embeds2[nodes]\n",
    "    nume = t.exp(t.sum(pckEmbeds1 * pckEmbeds2, dim=-1) / temp)\n",
    "    deno = t.exp(pckEmbeds1 @ embeds2.T / temp).sum(-1)\n",
    "    return -t.log(nume / deno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589e8075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "#from Params import args\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.sparse as sp\n",
    "#from Utils.Utils import contrastLoss, calcRegLoss, pairPredict\n",
    "import time\n",
    "#import torch_sparse\n",
    "\n",
    "init = nn.init.xavier_uniform_\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.uEmbeds = nn.Parameter(init(torch.empty(args.user, args.latdim)))\n",
    "        self.iEmbeds = nn.Parameter(init(torch.empty(args.item, args.latdim)))\n",
    "        self.gcnLayers = nn.Sequential(*[GCNLayer() for i in range(args.gnn_layer)])\n",
    "\n",
    "    def forward_gcn(self, adj):\n",
    "        iniEmbeds = torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "        embedsLst = [iniEmbeds]\n",
    "        for gcn in self.gcnLayers:\n",
    "            embeds = gcn(adj, embedsLst[-1])\n",
    "            embedsLst.append(embeds)\n",
    "        mainEmbeds = sum(embedsLst)\n",
    "\n",
    "        return mainEmbeds[:args.user], mainEmbeds[args.user:]\n",
    "\n",
    "    def forward_graphcl(self, adj):\n",
    "        iniEmbeds = torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "        embedsLst = [iniEmbeds]\n",
    "        for gcn in self.gcnLayers:\n",
    "            embeds = gcn(adj, embedsLst[-1])\n",
    "            embedsLst.append(embeds)\n",
    "        mainEmbeds = sum(embedsLst)\n",
    "\n",
    "        return mainEmbeds\n",
    "\n",
    "    def forward_graphcl_(self, generator):\n",
    "        iniEmbeds = torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "        embedsLst = [iniEmbeds]\t\t\n",
    "        count = 0\n",
    "        for gcn in self.gcnLayers:\n",
    "            with torch.no_grad():\n",
    "                adj = generator.generate(x=embedsLst[-1], layer=count)\n",
    "            embeds = gcn(adj, embedsLst[-1])\n",
    "            embedsLst.append(embeds)\n",
    "            count += 1\n",
    "        mainEmbeds = sum(embedsLst)\n",
    "\n",
    "        return mainEmbeds\n",
    "\n",
    "    def loss_graphcl(self, x1, x2, users, items):\n",
    "        T = args.temp\n",
    "        user_embeddings1, item_embeddings1 = torch.split(x1, [args.user, args.item], dim=0)\n",
    "        user_embeddings2, item_embeddings2 = torch.split(x2, [args.user, args.item], dim=0)\n",
    "\n",
    "        user_embeddings1 = F.normalize(user_embeddings1, dim=1)\n",
    "        item_embeddings1 = F.normalize(item_embeddings1, dim=1)\n",
    "        user_embeddings2 = F.normalize(user_embeddings2, dim=1)\n",
    "        item_embeddings2 = F.normalize(item_embeddings2, dim=1)\n",
    "\n",
    "        user_embs1 = F.embedding(users, user_embeddings1)\n",
    "        item_embs1 = F.embedding(items, item_embeddings1)\n",
    "        user_embs2 = F.embedding(users, user_embeddings2)\n",
    "        item_embs2 = F.embedding(items, item_embeddings2)\n",
    "\n",
    "        all_embs1 = torch.cat([user_embs1, item_embs1], dim=0)\n",
    "        all_embs2 = torch.cat([user_embs2, item_embs2], dim=0)\n",
    "\n",
    "        all_embs1_abs = all_embs1.norm(dim=1)\n",
    "        all_embs2_abs = all_embs2.norm(dim=1)\n",
    "\n",
    "        sim_matrix = torch.einsum('ik,jk->ij', all_embs1, all_embs2) / torch.einsum('i,j->ij', all_embs1_abs, all_embs2_abs)\n",
    "        sim_matrix = torch.exp(sim_matrix / T)\n",
    "        pos_sim = sim_matrix[np.arange(all_embs1.shape[0]), np.arange(all_embs1.shape[0])]\n",
    "        loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n",
    "        loss = - torch.log(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def getEmbeds(self):\n",
    "        self.unfreeze(self.gcnLayers)\n",
    "        return torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "    def unfreeze(self, layer):\n",
    "        for child in layer.children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def getGCN(self):\n",
    "        return self.gcnLayers\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCNLayer, self).__init__()\n",
    "\n",
    "    def forward(self, adj, embeds, flag=True):\n",
    "        if (flag):\n",
    "            return torch.spmm(adj, embeds)\n",
    "        else:\n",
    "            return torch.spmm(adj, embeds)\n",
    "        #torch_sparse.spmm(adj.indices(), adj.values(), adj.shape[0], adj.shape[1], embeds)\n",
    "\n",
    "class vgae_encoder(Model):\n",
    "    def __init__(self):\n",
    "        super(vgae_encoder, self).__init__()\n",
    "        hidden = args.latdim\n",
    "        self.encoder_mean = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, hidden))\n",
    "        self.encoder_std = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, hidden), nn.Softplus())\n",
    "\n",
    "    def forward(self, adj):\n",
    "        x = self.forward_graphcl(adj)\n",
    "\n",
    "        x_mean = self.encoder_mean(x)\n",
    "        x_std = self.encoder_std(x)\n",
    "        gaussian_noise = torch.randn(x_mean.shape).cuda()\n",
    "        x = gaussian_noise * x_std + x_mean\n",
    "        return x, x_mean, x_std\n",
    "\n",
    "class vgae_decoder(nn.Module):\n",
    "    def __init__(self, hidden=args.latdim):\n",
    "        super(vgae_decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(nn.ReLU(inplace=True), nn.Linear(hidden, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, 1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bceloss = nn.BCELoss(reduction='none')\n",
    "\n",
    "    def forward(self, x, x_mean, x_std, users, items, neg_items, encoder):\n",
    "        x_user, x_item = torch.split(x, [args.user, args.item], dim=0)\n",
    "\n",
    "        edge_pos_pred = self.sigmoid(self.decoder(x_user[users] * x_item[items]))\n",
    "        edge_neg_pred = self.sigmoid(self.decoder(x_user[users] * x_item[neg_items]))\n",
    "\n",
    "        loss_edge_pos = self.bceloss( edge_pos_pred, torch.ones(edge_pos_pred.shape).cuda() )\n",
    "        loss_edge_neg = self.bceloss( edge_neg_pred, torch.zeros(edge_neg_pred.shape).cuda() )\n",
    "        loss_rec = loss_edge_pos + loss_edge_neg\n",
    "\n",
    "        kl_divergence = - 0.5 * (1 + 2 * torch.log(x_std) - x_mean**2 - x_std**2).sum(dim=1)\n",
    "\n",
    "        ancEmbeds = x_user[users]\n",
    "        posEmbeds = x_item[items]\n",
    "        negEmbeds = x_item[neg_items]\n",
    "        scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "        bprLoss = - (scoreDiff).sigmoid().log().sum() / args.batch\n",
    "        regLoss = calcRegLoss(encoder) * args.reg\n",
    "\n",
    "        beta = 0.1\n",
    "        loss = (loss_rec + beta * kl_divergence.mean() + bprLoss + regLoss).mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class vgae(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(vgae, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, data, users, items, neg_items):\n",
    "        x, x_mean, x_std = self.encoder(data)\n",
    "        loss = self.decoder(x, x_mean, x_std, users, items, neg_items, self.encoder)\n",
    "        return loss\n",
    "\n",
    "    def generate(self, data, edge_index, adj):\n",
    "        x, _, _ = self.encoder(data)\n",
    "\n",
    "        edge_pred = self.decoder.sigmoid(self.decoder.decoder(x[edge_index[0]] * x[edge_index[1]]))\n",
    "\n",
    "        vals = adj._values()\n",
    "        idxs = adj._indices()\n",
    "        edgeNum = vals.size()\n",
    "        edge_pred = edge_pred[:, 0]\n",
    "        mask = ((edge_pred + 0.5).floor()).type(torch.bool)\n",
    "\n",
    "        newVals = vals[mask]\n",
    "\n",
    "        newVals = newVals / (newVals.shape[0] / edgeNum[0])\n",
    "        newIdxs = idxs[:, mask]\n",
    "\n",
    "        return torch.sparse.FloatTensor(newIdxs, newVals, adj.shape)\n",
    "\n",
    "class DenoisingNet(nn.Module):\n",
    "    def __init__(self, gcnLayers, features):\n",
    "        super(DenoisingNet, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        self.gcnLayers = gcnLayers\n",
    "\n",
    "        self.edge_weights = []\n",
    "        self.nblayers = []\n",
    "        self.selflayers = []\n",
    "\n",
    "        self.attentions = []\n",
    "        self.attentions.append([])\n",
    "        self.attentions.append([])\n",
    "\n",
    "        hidden = args.latdim\n",
    "\n",
    "        self.nblayers_0 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "        self.nblayers_1 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "\n",
    "        self.selflayers_0 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "        self.selflayers_1 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "\n",
    "        self.attentions_0 = nn.Sequential(nn.Linear( 2 * hidden, 1))\n",
    "        self.attentions_1 = nn.Sequential(nn.Linear( 2 * hidden, 1))\n",
    "\n",
    "    def freeze(self, layer):\n",
    "        for child in layer.children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def get_attention(self, input1, input2, layer=0):\n",
    "        if layer == 0:\n",
    "            nb_layer = self.nblayers_0\n",
    "            selflayer = self.selflayers_0\n",
    "        if layer == 1:\n",
    "            nb_layer = self.nblayers_1\n",
    "            selflayer = self.selflayers_1\n",
    "\n",
    "        input1 = nb_layer(input1)\n",
    "        input2 = selflayer(input2)\n",
    "\n",
    "        input10 = torch.concat([input1, input2], axis=1)\n",
    "\n",
    "        if layer == 0:\n",
    "            weight10 = self.attentions_0(input10)\n",
    "        if layer == 1:\n",
    "            weight10 = self.attentions_1(input10)\n",
    "\n",
    "        return weight10\n",
    "\n",
    "    def hard_concrete_sample(self, log_alpha, beta=1.0, training=True):\n",
    "        gamma = args.gamma\n",
    "        zeta = args.zeta\n",
    "\n",
    "        if training:\n",
    "            debug_var = 1e-7\n",
    "            bias = 0.0\n",
    "            np_random = np.random.uniform(low=debug_var, high=1.0-debug_var, size=np.shape(log_alpha.cpu().detach().numpy()))\n",
    "            random_noise = bias + torch.tensor(np_random)\n",
    "            gate_inputs = torch.log(random_noise) - torch.log(1.0 - random_noise)\n",
    "            gate_inputs = (gate_inputs.cuda() + log_alpha) / beta\n",
    "            gate_inputs = torch.sigmoid(gate_inputs)\n",
    "        else:\n",
    "            gate_inputs = torch.sigmoid(log_alpha)\n",
    "\n",
    "        stretched_values = gate_inputs * (zeta-gamma) +gamma\n",
    "        cliped = torch.clamp(stretched_values, 0.0, 1.0)\n",
    "        return cliped.float()\n",
    "\n",
    "    def generate(self, x, layer=0):\n",
    "        f1_features = x[self.row, :]\n",
    "        f2_features = x[self.col, :]\n",
    "\n",
    "        weight = self.get_attention(f1_features, f2_features, layer)\n",
    "\n",
    "        mask = self.hard_concrete_sample(weight, training=False)\n",
    "\n",
    "        mask = torch.squeeze(mask)\n",
    "        adj = torch.sparse.FloatTensor(self.adj_mat._indices(), mask, self.adj_mat.shape)\n",
    "\n",
    "        ind = deepcopy(adj._indices())\n",
    "        row = ind[0, :]\n",
    "        col = ind[1, :]\n",
    "\n",
    "        rowsum = torch.sparse.sum(adj, dim=-1).to_dense()\n",
    "        d_inv_sqrt = torch.reshape(torch.pow(rowsum, -0.5), [-1])\n",
    "        d_inv_sqrt = torch.clamp(d_inv_sqrt, 0.0, 10.0)\n",
    "        row_inv_sqrt = d_inv_sqrt[row]\n",
    "        col_inv_sqrt = d_inv_sqrt[col]\n",
    "        values = torch.mul(adj._values(), row_inv_sqrt)\n",
    "        values = torch.mul(values, col_inv_sqrt)\n",
    "\n",
    "        support = torch.sparse.FloatTensor(adj._indices(), values, adj.shape)\n",
    "\n",
    "        return support\n",
    "\n",
    "    def l0_norm(self, log_alpha, beta):\n",
    "        gamma = args.gamma\n",
    "        zeta = args.zeta\n",
    "        gamma = torch.tensor(gamma)\n",
    "        zeta = torch.tensor(zeta)\n",
    "        reg_per_weight = torch.sigmoid(log_alpha - beta * torch.log(-gamma/zeta))\n",
    "\n",
    "        return torch.mean(reg_per_weight)\n",
    "\n",
    "    def set_fea_adj(self, nodes, adj):\n",
    "        self.node_size = nodes\n",
    "        self.adj_mat = adj\n",
    "\n",
    "        ind = deepcopy(adj._indices())\n",
    "\n",
    "        self.row = ind[0, :]\n",
    "        self.col = ind[1, :]\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            temperature = inputs\n",
    "        else:\n",
    "            temperature = 1.0\n",
    "\n",
    "        self.maskes = []\n",
    "\n",
    "        x = self.features.detach()\n",
    "        layer_index = 0\n",
    "        embedsLst = [self.features.detach()]\n",
    "\n",
    "        for layer in self.gcnLayers:\n",
    "            xs = []\n",
    "            f1_features = x[self.row, :]\n",
    "            f2_features = x[self.col, :]\n",
    "\n",
    "            weight = self.get_attention(f1_features, f2_features, layer=layer_index)\n",
    "            mask = self.hard_concrete_sample(weight, temperature, training)\n",
    "\n",
    "            self.edge_weights.append(weight)\n",
    "            self.maskes.append(mask)\n",
    "            mask = torch.squeeze(mask)\n",
    "\n",
    "            adj = torch.sparse.FloatTensor(self.adj_mat._indices(), mask, self.adj_mat.shape).coalesce()\n",
    "            ind = deepcopy(adj._indices())\n",
    "            row = ind[0, :]\n",
    "            col = ind[1, :]\n",
    "\n",
    "            rowsum = torch.sparse.sum(adj, dim=-1).to_dense() + 1e-6\n",
    "            d_inv_sqrt = torch.reshape(torch.pow(rowsum, -0.5), [-1])\n",
    "            d_inv_sqrt = torch.clamp(d_inv_sqrt, 0.0, 10.0)\n",
    "            row_inv_sqrt = d_inv_sqrt[row]\n",
    "            col_inv_sqrt = d_inv_sqrt[col]\n",
    "            values = torch.mul(adj.values(), row_inv_sqrt)\n",
    "            values = torch.mul(values, col_inv_sqrt)\n",
    "            support = torch.sparse.FloatTensor(adj._indices(), values, adj.shape).coalesce()\n",
    "\n",
    "            nextx = layer(support, x, False)\n",
    "            xs.append(nextx)\n",
    "            x = xs[0]\n",
    "            embedsLst.append(x)\n",
    "            layer_index += 1\n",
    "        return sum(embedsLst)\n",
    "\n",
    "    def lossl0(self, temperature):\n",
    "        l0_loss = torch.zeros([]).cuda()\n",
    "        for weight in self.edge_weights:\n",
    "            l0_loss += self.l0_norm(weight, temperature)\n",
    "        self.edge_weights = []\n",
    "        return l0_loss\n",
    "\n",
    "    def forward(self, users, items, neg_items, temperature):\n",
    "        self.freeze(self.gcnLayers)\n",
    "        x = self.call(temperature, True)\n",
    "        x_user, x_item = torch.split(x, [args.user, args.item], dim=0)\n",
    "        ancEmbeds = x_user[users]\n",
    "        posEmbeds = x_item[items]\n",
    "        negEmbeds = x_item[neg_items]\n",
    "        scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "        bprLoss = - (scoreDiff).sigmoid().log().sum() / args.batch\n",
    "        regLoss = calcRegLoss(self) * args.reg\n",
    "\n",
    "        lossl0 = self.lossl0(temperature) * args.lambda0\n",
    "        return bprLoss + regLoss + lossl0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c8378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix, dok_matrix\n",
    "#from Params import args\n",
    "import scipy.sparse as sp\n",
    "#from Utils.TimeLogger import log\n",
    "import torch as t\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data as dataloader\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self):\n",
    "        predir='E:/datasets/'+dataset_folder+'/'+dataset_name+'/'+preflix_folder+'/'\n",
    "        self.predir = predir\n",
    "        self.trnfile = predir + dataset_name+'_adagcl_train_data.pkl'\n",
    "        self.tstfile = predir + dataset_name+'_adagcl_test_data.pkl'\n",
    "\n",
    "    def loadOneFile(self, filename):\n",
    "        print(filename)\n",
    "        with open(filename, 'rb') as fs:\n",
    "            ret = (pickle.load(fs) != 0).astype(np.float32)\n",
    "        if type(ret) != coo_matrix:\n",
    "            ret = sp.coo_matrix(ret)\n",
    "        return ret\n",
    "\n",
    "    def normalizeAdj(self, mat):\n",
    "        degree = np.array(mat.sum(axis=-1))\n",
    "        dInvSqrt = np.reshape(np.power(degree, -0.5), [-1])\n",
    "        dInvSqrt[np.isinf(dInvSqrt)] = 0.0\n",
    "        dInvSqrtMat = sp.diags(dInvSqrt)\n",
    "        return mat.dot(dInvSqrtMat).transpose().dot(dInvSqrtMat).tocoo()\n",
    "\n",
    "    def makeTorchAdj(self, mat):\n",
    "        # make ui adj\n",
    "        a = sp.csr_matrix((args.user, args.user))\n",
    "        b = sp.csr_matrix((args.item, args.item))\n",
    "        mat = sp.vstack([sp.hstack([a, mat]), sp.hstack([mat.transpose(), b])])\n",
    "        mat = (mat != 0) * 1.0\n",
    "        mat = (mat + sp.eye(mat.shape[0])) * 1.0\n",
    "        mat = self.normalizeAdj(mat)\n",
    "\n",
    "        # make cuda tensor\n",
    "        idxs = t.from_numpy(np.vstack([mat.row, mat.col]).astype(np.int64))\n",
    "        vals = t.from_numpy(mat.data.astype(np.float32))\n",
    "        shape = t.Size(mat.shape)\n",
    "        return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n",
    "\n",
    "    def LoadData(self):\n",
    "        trnMat = self.loadOneFile(self.trnfile)\n",
    "        tstMat = self.loadOneFile(self.tstfile)\n",
    "        self.trnMat = trnMat\n",
    "        args.user, args.item = trnMat.shape\n",
    "        self.torchBiAdj = self.makeTorchAdj(trnMat)\n",
    "        trnData = TrnData(trnMat)\n",
    "        self.trnLoader = dataloader.DataLoader(trnData, batch_size=args.batch, shuffle=True, num_workers=0)\n",
    "        tstData = TstData(tstMat, trnMat)\n",
    "        self.tstLoader = dataloader.DataLoader(tstData, batch_size=args.tstBat, shuffle=False, num_workers=0)\n",
    "\n",
    "class TrnData(data.Dataset):\n",
    "    def __init__(self, coomat):\n",
    "        self.rows = coomat.row\n",
    "        self.cols = coomat.col\n",
    "        self.dokmat = coomat.todok()\n",
    "        self.negs = np.zeros(len(self.rows)).astype(np.int32)\n",
    "\n",
    "    def negSampling(self):\n",
    "        for i in range(len(self.rows)):\n",
    "            u = self.rows[i]\n",
    "            while True:\n",
    "                iNeg = np.random.randint(args.item)\n",
    "                if (u, iNeg) not in self.dokmat:\n",
    "                    break\n",
    "            self.negs[i] = iNeg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rows[idx], self.cols[idx], self.negs[idx]\n",
    "\n",
    "class TstData(data.Dataset):\n",
    "    def __init__(self, coomat, trnMat):\n",
    "        self.csrmat = (trnMat.tocsr() != 0) * 1.0\n",
    "\n",
    "        tstLocs = [None] * coomat.shape[0]\n",
    "        tstUsrs = set()\n",
    "        for i in range(len(coomat.data)):\n",
    "            row = coomat.row[i]\n",
    "            col = coomat.col[i]\n",
    "            if tstLocs[row] is None:\n",
    "                tstLocs[row] = list()\n",
    "            tstLocs[row].append(col)\n",
    "            tstUsrs.add(row)\n",
    "        tstUsrs = np.array(list(tstUsrs))\n",
    "        self.tstUsrs = tstUsrs\n",
    "        self.tstLocs = tstLocs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tstUsrs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tstUsrs[idx], np.reshape(self.csrmat[self.tstUsrs[idx]].toarray(), [-1]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ade36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix, dok_matrix\n",
    "#from Params import args\n",
    "import scipy.sparse as sp\n",
    "#from Utils.TimeLogger import log\n",
    "import torch as t\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data as dataloader\n",
    "\n",
    "class my_DataHandler:\n",
    "    def __init__(self):\n",
    "        predir='E:/datasets/'+dataset_folder+'/'+dataset_name+'/'+preflix_folder+'/'\n",
    "        self.predir = predir\n",
    "        self.trnfile = predir + dataset_name+'_adagcl_train_data.pkl'\n",
    "        self.tstfile = predir + dataset_name+'_adagcl_test_data.pkl'\n",
    "\n",
    "    def loadOneFile(self, filename):\n",
    "        print(filename)\n",
    "        with open(filename, 'rb') as fs:\n",
    "            ret = (pickle.load(fs) != 0).astype(np.float32)\n",
    "        if type(ret) != coo_matrix:\n",
    "            ret = sp.coo_matrix(ret)\n",
    "        return ret\n",
    "\n",
    "    def normalizeAdj(self, mat):\n",
    "        degree = np.array(mat.sum(axis=-1))\n",
    "        dInvSqrt = np.reshape(np.power(degree, -0.5), [-1])\n",
    "        dInvSqrt[np.isinf(dInvSqrt)] = 0.0\n",
    "        dInvSqrtMat = sp.diags(dInvSqrt)\n",
    "        return mat.dot(dInvSqrtMat).transpose().dot(dInvSqrtMat).tocoo()\n",
    "\n",
    "    def makeTorchAdj(self, mat):\n",
    "        # make ui adj\n",
    "        a = sp.csr_matrix((args.user, args.user))\n",
    "        b = sp.csr_matrix((args.item, args.item))\n",
    "        mat = sp.vstack([sp.hstack([a, mat]), sp.hstack([mat.transpose(), b])])\n",
    "        mat = (mat != 0) * 1.0\n",
    "        mat = (mat + sp.eye(mat.shape[0])) * 1.0\n",
    "        mat = self.normalizeAdj(mat)\n",
    "\n",
    "        # make cuda tensor\n",
    "        idxs = t.from_numpy(np.vstack([mat.row, mat.col]).astype(np.int64))\n",
    "        vals = t.from_numpy(mat.data.astype(np.float32))\n",
    "        shape = t.Size(mat.shape)\n",
    "        return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n",
    "\n",
    "    def LoadData(self):\n",
    "        trnMat = self.loadOneFile(self.trnfile)\n",
    "        tstMat = self.loadOneFile(self.tstfile)\n",
    "        self.trnMat = trnMat\n",
    "        args.user, args.item = trnMat.shape\n",
    "        self.torchBiAdj = self.makeTorchAdj(trnMat)\n",
    "        trnData = TrnData(trnMat)\n",
    "        self.trnLoader = dataloader.DataLoader(trnData, batch_size=args.batch, shuffle=True, num_workers=0)\n",
    "        tstData = my_TstData(tstMat, trnMat)\n",
    "        self.tstLoader = dataloader.DataLoader(tstData, batch_size=args.tstBat, shuffle=False, num_workers=0)\n",
    "\n",
    "class TrnData(data.Dataset):\n",
    "    def __init__(self, coomat):\n",
    "        self.rows = coomat.row\n",
    "        self.cols = coomat.col\n",
    "        self.dokmat = coomat.todok()\n",
    "        self.negs = np.zeros(len(self.rows)).astype(np.int32)\n",
    "\n",
    "    def negSampling(self):\n",
    "        for i in range(len(self.rows)):\n",
    "            u = self.rows[i]\n",
    "            while True:\n",
    "                iNeg = np.random.randint(args.item)\n",
    "                if (u, iNeg) not in self.dokmat:\n",
    "                    break\n",
    "            self.negs[i] = iNeg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rows[idx], self.cols[idx], self.negs[idx]\n",
    "\n",
    "class my_TstData(data.Dataset):\n",
    "    def __init__(self, coomat, trnMat):\n",
    "        self.csrmat = (trnMat.tocsr() != 0) * 1.0\n",
    "        tstLocs = [None] * coomat.shape[0]\n",
    "        tstUsrs = set()\n",
    "        target_user=[]\n",
    "        target_item=[]\n",
    "        for i in range(len(coomat.data)):\n",
    "            row = coomat.row[i]\n",
    "            col = coomat.col[i]\n",
    "            if tstLocs[row] is None:\n",
    "                tstLocs[row] = list()\n",
    "            tstLocs[row].append(col)\n",
    "            tstUsrs.add(row)\n",
    "            target_user.append(row)\n",
    "            target_item.append(col)\n",
    "        tstUsrs = np.array(list(tstUsrs))\n",
    "        self.tstUsrs = tstUsrs\n",
    "        self.tstLocs = tstLocs\n",
    "        self.target_user=target_user\n",
    "        self.target_item=target_item\n",
    "        print(len(self.target_user),len(self.target_item))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_user)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.target_user[idx], self.target_item[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b8b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(rank, k):\n",
    "    \"\"\"Hit Rate.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: hit rate.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1\n",
    "    return res / len(rank)\n",
    "\n",
    "\n",
    "def mrr(rank, k):\n",
    "    \"\"\"Mean Reciprocal Rank.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: mrr.\n",
    "    \"\"\"\n",
    "    mrr = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            mrr += 1 / (r + 1)\n",
    "    return mrr / len(rank)\n",
    "\n",
    "\n",
    "def ndcg(rank, k):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: ndcg.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1 / np.log2(r + 2)\n",
    "    return res / len(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51650149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "E:/datasets/ml/ml-100k/24_07_19/ml-100k_adagcl_train_data.pkl\n",
      "E:/datasets/ml/ml-100k/24_07_19/ml-100k_adagcl_test_data.pkl\n",
      "16098 16098\n",
      "Load Data\n",
      "USER 943 ITEM 1523\n",
      "NUM OF INTERACTIONS 58196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_30676\\2995634190.py:47: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:607.)\n",
      "  return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prepared\n",
      "Model Initialized\n",
      "Epoch 0/200, Train: Gen_1 Loss = 3.6185, Gen_2 Loss = 0.7031, BPR Loss = 0.7025, IM Loss = 0.7477, IB Loss = 1.4943, Reg Loss = 0.0013  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.001727 \t mrr: 0.00045\t ndcg: 0.00074\t acc: 0.00018\n",
      "Epoch 1/200, Train: Gen_1 Loss = 3.5759, Gen_2 Loss = 0.7031, BPR Loss = 0.7015, IM Loss = 0.7503, IB Loss = 1.4940, Reg Loss = 0.0013  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.006213 \t mrr: 0.00152\t ndcg: 0.00258\t acc: 0.00037\n",
      "Epoch 2/200, Train: Gen_1 Loss = 3.5406, Gen_2 Loss = 0.7031, BPR Loss = 0.6997, IM Loss = 0.7493, IB Loss = 1.4941, Reg Loss = 0.0013  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.013201 \t mrr: 0.00387\t ndcg: 0.00601\t acc: 0.00124\n",
      "Epoch 3/200, Train: Gen_1 Loss = 3.5057, Gen_2 Loss = 0.7032, BPR Loss = 0.6968, IM Loss = 0.7484, IB Loss = 1.4945, Reg Loss = 0.0015  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.017696 \t mrr: 0.00544\t ndcg: 0.00825\t acc: 0.00181\n",
      "Epoch 4/200, Train: Gen_1 Loss = 3.4502, Gen_2 Loss = 0.7032, BPR Loss = 0.6919, IM Loss = 0.7496, IB Loss = 1.4952, Reg Loss = 0.0017  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.021412 \t mrr: 0.00657\t ndcg: 0.00997\t acc: 0.00232\n",
      "Epoch 5/200, Train: Gen_1 Loss = 3.3680, Gen_2 Loss = 0.7031, BPR Loss = 0.6830, IM Loss = 0.7520, IB Loss = 1.4966, Reg Loss = 0.0022  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.024941 \t mrr: 0.00745\t ndcg: 0.01145\t acc: 0.00250\n",
      "Epoch 6/200, Train: Gen_1 Loss = 3.1460, Gen_2 Loss = 0.7031, BPR Loss = 0.6688, IM Loss = 0.7522, IB Loss = 1.4986, Reg Loss = 0.0030  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.027643 \t mrr: 0.00808\t ndcg: 0.01255\t acc: 0.00276\n",
      "Epoch 7/200, Train: Gen_1 Loss = 2.9784, Gen_2 Loss = 0.7031, BPR Loss = 0.6490, IM Loss = 0.7511, IB Loss = 1.5008, Reg Loss = 0.0041  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.030698 \t mrr: 0.00889\t ndcg: 0.01384\t acc: 0.00327\n",
      "Epoch 8/200, Train: Gen_1 Loss = 2.8694, Gen_2 Loss = 0.7031, BPR Loss = 0.6252, IM Loss = 0.7526, IB Loss = 1.5038, Reg Loss = 0.0055  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.031614 \t mrr: 0.00926\t ndcg: 0.01435\t acc: 0.00327\n",
      "Epoch 9/200, Train: Gen_1 Loss = 2.7775, Gen_2 Loss = 0.7031, BPR Loss = 0.5974, IM Loss = 0.7544, IB Loss = 1.5070, Reg Loss = 0.0072  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.033547 \t mrr: 0.00975\t ndcg: 0.01517\t acc: 0.00345\n",
      "Epoch 10/200, Train: Gen_1 Loss = 2.6708, Gen_2 Loss = 0.7031, BPR Loss = 0.5682, IM Loss = 0.7561, IB Loss = 1.5104, Reg Loss = 0.0091  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.034669 \t mrr: 0.01005\t ndcg: 0.01566\t acc: 0.00344\n",
      "Epoch 11/200, Train: Gen_1 Loss = 2.6515, Gen_2 Loss = 0.7031, BPR Loss = 0.5374, IM Loss = 0.7577, IB Loss = 1.5135, Reg Loss = 0.0112  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.036841 \t mrr: 0.01054\t ndcg: 0.01653\t acc: 0.00362\n",
      "Epoch 12/200, Train: Gen_1 Loss = 2.5973, Gen_2 Loss = 0.7031, BPR Loss = 0.5072, IM Loss = 0.7592, IB Loss = 1.5166, Reg Loss = 0.0134  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.037931 \t mrr: 0.01086\t ndcg: 0.01703\t acc: 0.00368\n",
      "Epoch 13/200, Train: Gen_1 Loss = 2.5680, Gen_2 Loss = 0.7031, BPR Loss = 0.4781, IM Loss = 0.7611, IB Loss = 1.5204, Reg Loss = 0.0156  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.039776 \t mrr: 0.01105\t ndcg: 0.01759\t acc: 0.00355\n",
      "Epoch 14/200, Train: Gen_1 Loss = 2.5485, Gen_2 Loss = 0.7031, BPR Loss = 0.4453, IM Loss = 0.7637, IB Loss = 1.5257, Reg Loss = 0.0178  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.041508 \t mrr: 0.01154\t ndcg: 0.01835\t acc: 0.00380\n",
      "Epoch 15/200, Train: Gen_1 Loss = 2.5170, Gen_2 Loss = 0.7031, BPR Loss = 0.4112, IM Loss = 0.7676, IB Loss = 1.5334, Reg Loss = 0.0200  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043145 \t mrr: 0.01196\t ndcg: 0.01904\t acc: 0.00385\n",
      "Epoch 16/200, Train: Gen_1 Loss = 2.5108, Gen_2 Loss = 0.7031, BPR Loss = 0.3711, IM Loss = 0.7727, IB Loss = 1.5431, Reg Loss = 0.0221  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045379 \t mrr: 0.01266\t ndcg: 0.02008\t acc: 0.00416\n",
      "Epoch 17/200, Train: Gen_1 Loss = 2.4801, Gen_2 Loss = 0.7031, BPR Loss = 0.3326, IM Loss = 0.7779, IB Loss = 1.5533, Reg Loss = 0.0243  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.047617 \t mrr: 0.01328\t ndcg: 0.02107\t acc: 0.00452\n",
      "Epoch 18/200, Train: Gen_1 Loss = 2.4856, Gen_2 Loss = 0.7031, BPR Loss = 0.3000, IM Loss = 0.7824, IB Loss = 1.5619, Reg Loss = 0.0264  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.048298 \t mrr: 0.01350\t ndcg: 0.02142\t acc: 0.00433\n",
      "Epoch 19/200, Train: Gen_1 Loss = 2.4607, Gen_2 Loss = 0.7031, BPR Loss = 0.2728, IM Loss = 0.7856, IB Loss = 1.5680, Reg Loss = 0.0284  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.048635 \t mrr: 0.01368\t ndcg: 0.02164\t acc: 0.00433\n",
      "Epoch 20/200, Train: Gen_1 Loss = 2.4546, Gen_2 Loss = 0.7031, BPR Loss = 0.2526, IM Loss = 0.7876, IB Loss = 1.5718, Reg Loss = 0.0302  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.048856 \t mrr: 0.01384\t ndcg: 0.02183\t acc: 0.00433\n",
      "Epoch 21/200, Train: Gen_1 Loss = 2.4479, Gen_2 Loss = 0.7031, BPR Loss = 0.2385, IM Loss = 0.7887, IB Loss = 1.5738, Reg Loss = 0.0320  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.048791 \t mrr: 0.01368\t ndcg: 0.02170\t acc: 0.00409\n",
      "Epoch 22/200, Train: Gen_1 Loss = 2.4076, Gen_2 Loss = 0.7031, BPR Loss = 0.2265, IM Loss = 0.7889, IB Loss = 1.5741, Reg Loss = 0.0336  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.049603 \t mrr: 0.01367\t ndcg: 0.02187\t acc: 0.00390\n",
      "Epoch 23/200, Train: Gen_1 Loss = 2.4279, Gen_2 Loss = 0.7031, BPR Loss = 0.2193, IM Loss = 0.7889, IB Loss = 1.5739, Reg Loss = 0.0351  \n",
      "rating shape: torch.Size([4096, 1524])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.049297 \t mrr: 0.01370\t ndcg: 0.02182\t acc: 0.00404\n",
      "Epoch 24/200, Train: Gen_1 Loss = 2.4160, Gen_2 Loss = 0.7031, BPR Loss = 0.2102, IM Loss = 0.7887, IB Loss = 1.5734, Reg Loss = 0.0365  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.049058 \t mrr: 0.01362\t ndcg: 0.02170\t acc: 0.00392\n",
      "Epoch 25/200, Train: Gen_1 Loss = 2.4271, Gen_2 Loss = 0.7031, BPR Loss = 0.2072, IM Loss = 0.7879, IB Loss = 1.5719, Reg Loss = 0.0379  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.048110 \t mrr: 0.01352\t ndcg: 0.02142\t acc: 0.00405\n",
      "Epoch 26/200, Train: Gen_1 Loss = 2.4044, Gen_2 Loss = 0.7031, BPR Loss = 0.2013, IM Loss = 0.7870, IB Loss = 1.5700, Reg Loss = 0.0392  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.048180 \t mrr: 0.01348\t ndcg: 0.02139\t acc: 0.00423\n",
      "Epoch 27/200, Train: Gen_1 Loss = 2.4124, Gen_2 Loss = 0.7031, BPR Loss = 0.1983, IM Loss = 0.7862, IB Loss = 1.5684, Reg Loss = 0.0404  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.047805 \t mrr: 0.01329\t ndcg: 0.02115\t acc: 0.00417\n",
      "Epoch 28/200, Train: Gen_1 Loss = 2.4202, Gen_2 Loss = 0.7031, BPR Loss = 0.1959, IM Loss = 0.7856, IB Loss = 1.5670, Reg Loss = 0.0415  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.047063 \t mrr: 0.01317\t ndcg: 0.02090\t acc: 0.00404\n",
      "Epoch 29/200, Train: Gen_1 Loss = 2.4150, Gen_2 Loss = 0.7031, BPR Loss = 0.1886, IM Loss = 0.7846, IB Loss = 1.5650, Reg Loss = 0.0427  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.047050 \t mrr: 0.01313\t ndcg: 0.02086\t acc: 0.00417\n",
      "Epoch 30/200, Train: Gen_1 Loss = 2.3962, Gen_2 Loss = 0.7031, BPR Loss = 0.1847, IM Loss = 0.7839, IB Loss = 1.5637, Reg Loss = 0.0438  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.046867 \t mrr: 0.01315\t ndcg: 0.02082\t acc: 0.00442\n",
      "Epoch 31/200, Train: Gen_1 Loss = 2.4000, Gen_2 Loss = 0.7031, BPR Loss = 0.1842, IM Loss = 0.7836, IB Loss = 1.5630, Reg Loss = 0.0448  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.047312 \t mrr: 0.01309\t ndcg: 0.02087\t acc: 0.00430\n",
      "Epoch 32/200, Train: Gen_1 Loss = 2.3959, Gen_2 Loss = 0.7031, BPR Loss = 0.1801, IM Loss = 0.7828, IB Loss = 1.5614, Reg Loss = 0.0458  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.047665 \t mrr: 0.01299\t ndcg: 0.02087\t acc: 0.00424\n",
      "Epoch 33/200, Train: Gen_1 Loss = 2.4140, Gen_2 Loss = 0.7030, BPR Loss = 0.1796, IM Loss = 0.7820, IB Loss = 1.5599, Reg Loss = 0.0467  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.047115 \t mrr: 0.01312\t ndcg: 0.02085\t acc: 0.00455\n",
      "Epoch 34/200, Train: Gen_1 Loss = 2.4021, Gen_2 Loss = 0.7031, BPR Loss = 0.1755, IM Loss = 0.7814, IB Loss = 1.5586, Reg Loss = 0.0477  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.046749 \t mrr: 0.01303\t ndcg: 0.02070\t acc: 0.00443\n",
      "Epoch 35/200, Train: Gen_1 Loss = 2.4131, Gen_2 Loss = 0.7031, BPR Loss = 0.1755, IM Loss = 0.7809, IB Loss = 1.5575, Reg Loss = 0.0486  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.046383 \t mrr: 0.01288\t ndcg: 0.02050\t acc: 0.00429\n",
      "Epoch 36/200, Train: Gen_1 Loss = 2.3938, Gen_2 Loss = 0.7031, BPR Loss = 0.1709, IM Loss = 0.7802, IB Loss = 1.5563, Reg Loss = 0.0495  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.046360 \t mrr: 0.01279\t ndcg: 0.02042\t acc: 0.00418\n",
      "Epoch 37/200, Train: Gen_1 Loss = 2.4023, Gen_2 Loss = 0.7030, BPR Loss = 0.1706, IM Loss = 0.7798, IB Loss = 1.5553, Reg Loss = 0.0503  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045840 \t mrr: 0.01287\t ndcg: 0.02037\t acc: 0.00443\n",
      "Epoch 38/200, Train: Gen_1 Loss = 2.3969, Gen_2 Loss = 0.7031, BPR Loss = 0.1672, IM Loss = 0.7793, IB Loss = 1.5545, Reg Loss = 0.0511  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045582 \t mrr: 0.01274\t ndcg: 0.02021\t acc: 0.00443\n",
      "Epoch 39/200, Train: Gen_1 Loss = 2.3938, Gen_2 Loss = 0.7031, BPR Loss = 0.1642, IM Loss = 0.7786, IB Loss = 1.5532, Reg Loss = 0.0519  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045544 \t mrr: 0.01277\t ndcg: 0.02022\t acc: 0.00461\n",
      "Epoch 40/200, Train: Gen_1 Loss = 2.4043, Gen_2 Loss = 0.7030, BPR Loss = 0.1632, IM Loss = 0.7781, IB Loss = 1.5521, Reg Loss = 0.0527  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045684 \t mrr: 0.01273\t ndcg: 0.02021\t acc: 0.00442\n",
      "Epoch 41/200, Train: Gen_1 Loss = 2.3906, Gen_2 Loss = 0.7030, BPR Loss = 0.1627, IM Loss = 0.7777, IB Loss = 1.5513, Reg Loss = 0.0535  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045060 \t mrr: 0.01257\t ndcg: 0.01996\t acc: 0.00430\n",
      "Epoch 42/200, Train: Gen_1 Loss = 2.3901, Gen_2 Loss = 0.7030, BPR Loss = 0.1621, IM Loss = 0.7773, IB Loss = 1.5504, Reg Loss = 0.0542  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045309 \t mrr: 0.01254\t ndcg: 0.01998\t acc: 0.00423\n",
      "Epoch 43/200, Train: Gen_1 Loss = 2.4084, Gen_2 Loss = 0.7030, BPR Loss = 0.1598, IM Loss = 0.7769, IB Loss = 1.5496, Reg Loss = 0.0549  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045994 \t mrr: 0.01248\t ndcg: 0.02008\t acc: 0.00411\n",
      "Epoch 44/200, Train: Gen_1 Loss = 2.3947, Gen_2 Loss = 0.7030, BPR Loss = 0.1579, IM Loss = 0.7764, IB Loss = 1.5487, Reg Loss = 0.0556  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045802 \t mrr: 0.01256\t ndcg: 0.02010\t acc: 0.00429\n",
      "Epoch 45/200, Train: Gen_1 Loss = 2.3980, Gen_2 Loss = 0.7030, BPR Loss = 0.1586, IM Loss = 0.7759, IB Loss = 1.5478, Reg Loss = 0.0562  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045666 \t mrr: 0.01247\t ndcg: 0.02001\t acc: 0.00416\n",
      "Epoch 46/200, Train: Gen_1 Loss = 2.3837, Gen_2 Loss = 0.7030, BPR Loss = 0.1541, IM Loss = 0.7755, IB Loss = 1.5470, Reg Loss = 0.0569  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.045783 \t mrr: 0.01228\t ndcg: 0.01987\t acc: 0.00392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train: Gen_1 Loss = 2.4183, Gen_2 Loss = 0.7030, BPR Loss = 0.1558, IM Loss = 0.7752, IB Loss = 1.5462, Reg Loss = 0.0575  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.044840 \t mrr: 0.01213\t ndcg: 0.01956\t acc: 0.00385\n",
      "Epoch 48/200, Train: Gen_1 Loss = 2.3944, Gen_2 Loss = 0.7030, BPR Loss = 0.1526, IM Loss = 0.7746, IB Loss = 1.5452, Reg Loss = 0.0582  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.044831 \t mrr: 0.01211\t ndcg: 0.01955\t acc: 0.00373\n",
      "Epoch 49/200, Train: Gen_1 Loss = 2.3868, Gen_2 Loss = 0.7030, BPR Loss = 0.1499, IM Loss = 0.7741, IB Loss = 1.5443, Reg Loss = 0.0588  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.044442 \t mrr: 0.01213\t ndcg: 0.01948\t acc: 0.00379\n",
      "Epoch 50/200, Train: Gen_1 Loss = 2.3958, Gen_2 Loss = 0.7030, BPR Loss = 0.1536, IM Loss = 0.7740, IB Loss = 1.5440, Reg Loss = 0.0594  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.044643 \t mrr: 0.01220\t ndcg: 0.01957\t acc: 0.00398\n",
      "Epoch 51/200, Train: Gen_1 Loss = 2.3745, Gen_2 Loss = 0.7030, BPR Loss = 0.1486, IM Loss = 0.7736, IB Loss = 1.5432, Reg Loss = 0.0600  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043963 \t mrr: 0.01199\t ndcg: 0.01926\t acc: 0.00373\n",
      "Epoch 52/200, Train: Gen_1 Loss = 2.3927, Gen_2 Loss = 0.7030, BPR Loss = 0.1486, IM Loss = 0.7733, IB Loss = 1.5427, Reg Loss = 0.0606  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043710 \t mrr: 0.01186\t ndcg: 0.01910\t acc: 0.00367\n",
      "Epoch 53/200, Train: Gen_1 Loss = 2.3985, Gen_2 Loss = 0.7030, BPR Loss = 0.1469, IM Loss = 0.7733, IB Loss = 1.5426, Reg Loss = 0.0611  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043653 \t mrr: 0.01183\t ndcg: 0.01907\t acc: 0.00360\n",
      "Epoch 54/200, Train: Gen_1 Loss = 2.3816, Gen_2 Loss = 0.7030, BPR Loss = 0.1465, IM Loss = 0.7729, IB Loss = 1.5417, Reg Loss = 0.0617  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043339 \t mrr: 0.01175\t ndcg: 0.01894\t acc: 0.00354\n",
      "Epoch 55/200, Train: Gen_1 Loss = 2.3962, Gen_2 Loss = 0.7030, BPR Loss = 0.1443, IM Loss = 0.7725, IB Loss = 1.5411, Reg Loss = 0.0622  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043775 \t mrr: 0.01184\t ndcg: 0.01910\t acc: 0.00361\n",
      "Epoch 56/200, Train: Gen_1 Loss = 2.3944, Gen_2 Loss = 0.7030, BPR Loss = 0.1442, IM Loss = 0.7724, IB Loss = 1.5407, Reg Loss = 0.0628  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043362 \t mrr: 0.01184\t ndcg: 0.01901\t acc: 0.00367\n",
      "Epoch 57/200, Train: Gen_1 Loss = 2.4059, Gen_2 Loss = 0.7030, BPR Loss = 0.1440, IM Loss = 0.7721, IB Loss = 1.5402, Reg Loss = 0.0633  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043610 \t mrr: 0.01197\t ndcg: 0.01916\t acc: 0.00379\n",
      "Epoch 58/200, Train: Gen_1 Loss = 2.3804, Gen_2 Loss = 0.7030, BPR Loss = 0.1425, IM Loss = 0.7717, IB Loss = 1.5395, Reg Loss = 0.0638  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043432 \t mrr: 0.01180\t ndcg: 0.01900\t acc: 0.00355\n",
      "Epoch 59/200, Train: Gen_1 Loss = 2.3892, Gen_2 Loss = 0.7030, BPR Loss = 0.1414, IM Loss = 0.7715, IB Loss = 1.5391, Reg Loss = 0.0642  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043728 \t mrr: 0.01184\t ndcg: 0.01909\t acc: 0.00368\n",
      "Epoch 60/200, Train: Gen_1 Loss = 2.3984, Gen_2 Loss = 0.7030, BPR Loss = 0.1416, IM Loss = 0.7714, IB Loss = 1.5388, Reg Loss = 0.0647  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043662 \t mrr: 0.01181\t ndcg: 0.01904\t acc: 0.00368\n",
      "Epoch 61/200, Train: Gen_1 Loss = 2.3977, Gen_2 Loss = 0.7030, BPR Loss = 0.1398, IM Loss = 0.7710, IB Loss = 1.5380, Reg Loss = 0.0651  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043793 \t mrr: 0.01176\t ndcg: 0.01904\t acc: 0.00343\n",
      "Epoch 62/200, Train: Gen_1 Loss = 2.3809, Gen_2 Loss = 0.7030, BPR Loss = 0.1394, IM Loss = 0.7708, IB Loss = 1.5377, Reg Loss = 0.0656  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.043348 \t mrr: 0.01172\t ndcg: 0.01892\t acc: 0.00349\n",
      "Epoch 63/200, Train: Gen_1 Loss = 2.3803, Gen_2 Loss = 0.7030, BPR Loss = 0.1403, IM Loss = 0.7705, IB Loss = 1.5371, Reg Loss = 0.0660  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042911 \t mrr: 0.01163\t ndcg: 0.01874\t acc: 0.00349\n",
      "Epoch 64/200, Train: Gen_1 Loss = 2.3944, Gen_2 Loss = 0.7030, BPR Loss = 0.1374, IM Loss = 0.7703, IB Loss = 1.5366, Reg Loss = 0.0665  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042466 \t mrr: 0.01165\t ndcg: 0.01866\t acc: 0.00355\n",
      "Epoch 65/200, Train: Gen_1 Loss = 2.3993, Gen_2 Loss = 0.7030, BPR Loss = 0.1371, IM Loss = 0.7701, IB Loss = 1.5363, Reg Loss = 0.0669  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042602 \t mrr: 0.01168\t ndcg: 0.01871\t acc: 0.00367\n",
      "Epoch 66/200, Train: Gen_1 Loss = 2.3819, Gen_2 Loss = 0.7030, BPR Loss = 0.1363, IM Loss = 0.7701, IB Loss = 1.5363, Reg Loss = 0.0673  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042850 \t mrr: 0.01172\t ndcg: 0.01880\t acc: 0.00355\n",
      "Epoch 67/200, Train: Gen_1 Loss = 2.3855, Gen_2 Loss = 0.7030, BPR Loss = 0.1364, IM Loss = 0.7699, IB Loss = 1.5358, Reg Loss = 0.0678  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042690 \t mrr: 0.01167\t ndcg: 0.01873\t acc: 0.00355\n",
      "Epoch 68/200, Train: Gen_1 Loss = 2.3937, Gen_2 Loss = 0.7030, BPR Loss = 0.1368, IM Loss = 0.7695, IB Loss = 1.5352, Reg Loss = 0.0682  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042315 \t mrr: 0.01155\t ndcg: 0.01855\t acc: 0.00349\n",
      "Epoch 69/200, Train: Gen_1 Loss = 2.3855, Gen_2 Loss = 0.7030, BPR Loss = 0.1330, IM Loss = 0.7694, IB Loss = 1.5349, Reg Loss = 0.0685  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042564 \t mrr: 0.01158\t ndcg: 0.01863\t acc: 0.00355\n",
      "Epoch 70/200, Train: Gen_1 Loss = 2.3888, Gen_2 Loss = 0.7030, BPR Loss = 0.1333, IM Loss = 0.7692, IB Loss = 1.5345, Reg Loss = 0.0689  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042686 \t mrr: 0.01145\t ndcg: 0.01856\t acc: 0.00324\n",
      "Epoch 71/200, Train: Gen_1 Loss = 2.3897, Gen_2 Loss = 0.7030, BPR Loss = 0.1334, IM Loss = 0.7692, IB Loss = 1.5345, Reg Loss = 0.0693  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042503 \t mrr: 0.01144\t ndcg: 0.01851\t acc: 0.00331\n",
      "Epoch 72/200, Train: Gen_1 Loss = 2.3961, Gen_2 Loss = 0.7030, BPR Loss = 0.1336, IM Loss = 0.7690, IB Loss = 1.5340, Reg Loss = 0.0696  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042629 \t mrr: 0.01157\t ndcg: 0.01862\t acc: 0.00350\n",
      "Epoch 73/200, Train: Gen_1 Loss = 2.3933, Gen_2 Loss = 0.7030, BPR Loss = 0.1326, IM Loss = 0.7687, IB Loss = 1.5334, Reg Loss = 0.0700  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042428 \t mrr: 0.01153\t ndcg: 0.01856\t acc: 0.00343\n",
      "Epoch 74/200, Train: Gen_1 Loss = 2.3736, Gen_2 Loss = 0.7030, BPR Loss = 0.1305, IM Loss = 0.7684, IB Loss = 1.5329, Reg Loss = 0.0703  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042611 \t mrr: 0.01156\t ndcg: 0.01863\t acc: 0.00337\n",
      "Epoch 75/200, Train: Gen_1 Loss = 2.3887, Gen_2 Loss = 0.7029, BPR Loss = 0.1310, IM Loss = 0.7685, IB Loss = 1.5330, Reg Loss = 0.0707  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042480 \t mrr: 0.01147\t ndcg: 0.01853\t acc: 0.00324\n",
      "Epoch 76/200, Train: Gen_1 Loss = 2.3809, Gen_2 Loss = 0.7030, BPR Loss = 0.1303, IM Loss = 0.7684, IB Loss = 1.5330, Reg Loss = 0.0710  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042541 \t mrr: 0.01151\t ndcg: 0.01856\t acc: 0.00336\n",
      "Epoch 77/200, Train: Gen_1 Loss = 2.3993, Gen_2 Loss = 0.7030, BPR Loss = 0.1297, IM Loss = 0.7683, IB Loss = 1.5326, Reg Loss = 0.0713  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042541 \t mrr: 0.01156\t ndcg: 0.01861\t acc: 0.00336\n",
      "Epoch 78/200, Train: Gen_1 Loss = 2.3895, Gen_2 Loss = 0.7030, BPR Loss = 0.1295, IM Loss = 0.7680, IB Loss = 1.5322, Reg Loss = 0.0716  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.042100 \t mrr: 0.01150\t ndcg: 0.01846\t acc: 0.00349\n",
      "Epoch 79/200, Train: Gen_1 Loss = 2.3925, Gen_2 Loss = 0.7029, BPR Loss = 0.1306, IM Loss = 0.7678, IB Loss = 1.5317, Reg Loss = 0.0719  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.041790 \t mrr: 0.01136\t ndcg: 0.01829\t acc: 0.00330\n",
      "Epoch 80/200, Train: Gen_1 Loss = 2.3875, Gen_2 Loss = 0.7029, BPR Loss = 0.1291, IM Loss = 0.7678, IB Loss = 1.5317, Reg Loss = 0.0722  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.041729 \t mrr: 0.01145\t ndcg: 0.01835\t acc: 0.00349\n",
      "Epoch 81/200, Train: Gen_1 Loss = 2.3873, Gen_2 Loss = 0.7030, BPR Loss = 0.1280, IM Loss = 0.7675, IB Loss = 1.5311, Reg Loss = 0.0725  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.041672 \t mrr: 0.01147\t ndcg: 0.01834\t acc: 0.00355\n",
      "Epoch 82/200, Train: Gen_1 Loss = 2.3914, Gen_2 Loss = 0.7029, BPR Loss = 0.1269, IM Loss = 0.7674, IB Loss = 1.5310, Reg Loss = 0.0728  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.041686 \t mrr: 0.01151\t ndcg: 0.01837\t acc: 0.00361\n",
      "Epoch 83/200, Train: Gen_1 Loss = 2.4004, Gen_2 Loss = 0.7030, BPR Loss = 0.1267, IM Loss = 0.7673, IB Loss = 1.5307, Reg Loss = 0.0731  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([3810, 1524])\n",
      "hr: 0.041616 \t mrr: 0.01148\t ndcg: 0.01834\t acc: 0.00361\n",
      "Epoch 84/200, Train: Gen_1 Loss = 2.3797, Gen_2 Loss = 0.7030, BPR Loss = 0.1253, IM Loss = 0.7673, IB Loss = 1.5307, Reg Loss = 0.0734  \n",
      "rating shape: torch.Size([4096, 1524])\n",
      "rating shape: torch.Size([4096, 1524])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 260\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    259\u001b[0m coach \u001b[38;5;241m=\u001b[39m Coach(handler)\n\u001b[1;32m--> 260\u001b[0m coach\u001b[38;5;241m.\u001b[39mrun()\n",
      "Cell \u001b[1;32mIn[8], line 52\u001b[0m, in \u001b[0;36mCoach.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakePrint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, ep, reses, tstFlag))\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tstFlag:\n\u001b[1;32m---> 52\u001b[0m         f_hr, f_mrr, f_ndcg, f_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestEpoch()\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhr: \u001b[39m\u001b[38;5;132;01m{:5f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m mrr: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m ndcg: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m acc: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f_hr, f_mrr, f_ndcg, f_acc))\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m'''if (reses['Recall'] > recallMax):\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m            recallMax = reses['Recall']\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m            ndcgMax = reses['NDCG']\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m    print()\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mprint('Best epoch : ', bestEpoch, ' , Recall : ', recallMax, ' , NDCG : ', ndcgMax)'''\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 189\u001b[0m, in \u001b[0;36mCoach.testEpoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating shape:\u001b[39m\u001b[38;5;124m'\u001b[39m,allPreds\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    188\u001b[0m rank \u001b[38;5;241m=\u001b[39m allPreds\u001b[38;5;241m.\u001b[39margsort()\u001b[38;5;241m.\u001b[39margsort()[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 189\u001b[0m rank\u001b[38;5;241m=\u001b[39mrank\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    190\u001b[0m res_1 \u001b[38;5;241m=\u001b[39m hr(rank, args\u001b[38;5;241m.\u001b[39mtopk)\n\u001b[0;32m    191\u001b[0m res_2 \u001b[38;5;241m=\u001b[39m ndcg(rank, args\u001b[38;5;241m.\u001b[39mtopk)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import Utils.TimeLogger as logger\n",
    "#from Utils.TimeLogger import log\n",
    "#from Params import args\n",
    "#from Model import Model, vgae_encoder, vgae_decoder, vgae, DenoisingNet\n",
    "#from DataHandler import DataHandler\n",
    "import numpy as np\n",
    "#from Utils.Utils import calcRegLoss, pairPredict\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import scipy.sparse as sp\n",
    "import random\n",
    "\n",
    "class Coach:\n",
    "    def __init__(self, handler):\n",
    "        self.handler = handler\n",
    "\n",
    "        print('USER', args.user, 'ITEM', args.item)\n",
    "        print('NUM OF INTERACTIONS', self.handler.trnLoader.dataset.__len__())\n",
    "        self.metrics = dict()\n",
    "        mets = ['Loss', 'preLoss', 'Recall', 'NDCG']\n",
    "        for met in mets:\n",
    "            self.metrics['Train' + met] = list()\n",
    "            self.metrics['Test' + met] = list()\n",
    "    def makePrint(self, name, ep, reses, save):\n",
    "        ret = 'Epoch %d/%d, %s: ' % (ep, args.epoch, name)\n",
    "        for metric in reses:\n",
    "            val = reses[metric]\n",
    "            ret += '%s = %.4f, ' % (metric, val)\n",
    "            tem = name + metric\n",
    "            if save and tem in self.metrics:\n",
    "                self.metrics[tem].append(val)\n",
    "        ret = ret[:-2] + '  '\n",
    "        return ret\n",
    "    def run(self):\n",
    "        self.prepareModel()\n",
    "        print('Model Prepared')\n",
    "\n",
    "        recallMax = 0\n",
    "        ndcgMax = 0\n",
    "        bestEpoch = 0\n",
    "\n",
    "        stloc = 0\n",
    "        print('Model Initialized')\n",
    "\n",
    "        for ep in range(stloc, args.epoch):\n",
    "            temperature = max(0.05, args.init_temperature * pow(args.temperature_decay, ep))\n",
    "            tstFlag = (ep % args.tstEpoch == 0)\n",
    "            reses = self.trainEpoch(temperature)\n",
    "            print(self.makePrint('Train', ep, reses, tstFlag))\n",
    "            if tstFlag:\n",
    "                f_hr, f_mrr, f_ndcg, f_acc = self.testEpoch()\n",
    "                print(\"hr: {:5f} \\t mrr: {:.5f}\\t ndcg: {:.5f}\\t acc: {:.5f}\".format(f_hr, f_mrr, f_ndcg, f_acc))\n",
    "                if (reses['Recall'] > recallMax):\n",
    "                    recallMax = reses['Recall']\n",
    "                    ndcgMax = reses['NDCG']\n",
    "                    bestEpoch = ep\n",
    "                print(self.makePrint('Test', ep, reses, tstFlag))\n",
    "            print()\n",
    "        print('Best epoch : ', bestEpoch, ' , Recall : ', recallMax, ' , NDCG : ', ndcgMax)\n",
    "    def prepareModel(self):\n",
    "        self.model = Model().cuda()\n",
    "\n",
    "        encoder = vgae_encoder().cuda()\n",
    "        decoder = vgae_decoder().cuda()\n",
    "        self.generator_1 = vgae(encoder, decoder).cuda()\n",
    "        self.generator_2 = DenoisingNet(self.model.getGCN(), self.model.getEmbeds()).cuda()\n",
    "        self.generator_2.set_fea_adj(args.user+args.item, deepcopy(self.handler.torchBiAdj).cuda())\n",
    "\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(), lr=args.lr, weight_decay=0)\n",
    "        self.opt_gen_1 = torch.optim.Adam(self.generator_1.parameters(), lr=args.lr, weight_decay=0)\n",
    "        self.opt_gen_2 = torch.optim.Adam(filter(lambda p: p.requires_grad, self.generator_2.parameters()), lr=args.lr, weight_decay=0, eps=args.eps)\n",
    "    def trainEpoch(self, temperature):\n",
    "        trnLoader = self.handler.trnLoader\n",
    "        trnLoader.dataset.negSampling()\n",
    "        generate_loss_1, generate_loss_2, bpr_loss, im_loss, ib_loss, reg_loss = 0, 0, 0, 0, 0, 0\n",
    "        steps = trnLoader.dataset.__len__() // args.batch\n",
    "\n",
    "        for i, tem in enumerate(trnLoader):\n",
    "            data = deepcopy(self.handler.torchBiAdj).cuda()\n",
    "\n",
    "            data1 = self.generator_generate(self.generator_1)\n",
    "\n",
    "            self.opt.zero_grad()\n",
    "            self.opt_gen_1.zero_grad()\n",
    "            self.opt_gen_2.zero_grad()\n",
    "\n",
    "            ancs, poss, negs = tem\n",
    "            ancs = ancs.long().cuda()\n",
    "            poss = poss.long().cuda()\n",
    "            negs = negs.long().cuda()\n",
    "\n",
    "            out1 = self.model.forward_graphcl(data1)\n",
    "            out2 = self.model.forward_graphcl_(self.generator_2)\n",
    "\n",
    "            loss = self.model.loss_graphcl(out1, out2, ancs, poss).mean() * args.ssl_reg\n",
    "            im_loss += float(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            # info bottleneck\n",
    "            _out1 = self.model.forward_graphcl(data1)\n",
    "            _out2 = self.model.forward_graphcl_(self.generator_2)\n",
    "\n",
    "            loss_ib = self.model.loss_graphcl(_out1, out1.detach(), ancs, poss) + self.model.loss_graphcl(_out2, out2.detach(), ancs, poss)\n",
    "            loss= loss_ib.mean() * args.ib_reg\n",
    "            ib_loss += float(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            # BPR\n",
    "            usrEmbeds, itmEmbeds = self.model.forward_gcn(data)\n",
    "            ancEmbeds = usrEmbeds[ancs]\n",
    "            posEmbeds = itmEmbeds[poss]\n",
    "            negEmbeds = itmEmbeds[negs]\n",
    "            scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "            bprLoss = - (scoreDiff).sigmoid().log().sum() / args.batch\n",
    "            regLoss = calcRegLoss(self.model) * args.reg\n",
    "            loss = bprLoss + regLoss\n",
    "            bpr_loss += float(bprLoss)\n",
    "            reg_loss += float(regLoss)\n",
    "            loss.backward()\n",
    "\n",
    "            loss_1 = self.generator_1(deepcopy(self.handler.torchBiAdj).cuda(), ancs, poss, negs)\n",
    "            loss_2 = self.generator_2(ancs, poss, negs, temperature)\n",
    "\n",
    "            loss = loss_1 + loss_2\n",
    "            generate_loss_1 += float(loss_1)\n",
    "            generate_loss_2 += float(loss_2)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt_gen_1.step()\n",
    "            self.opt_gen_2.step()\n",
    "            if False:\n",
    "                print('Step %d/%d: gen 1 : %.3f ; gen 2 : %.3f ; bpr : %.3f ; im : %.3f ; ib : %.3f ; reg : %.3f  ' % (\n",
    "                i, \n",
    "                steps,\n",
    "                generate_loss_1,\n",
    "                generate_loss_2,\n",
    "                bpr_loss,\n",
    "                im_loss,\n",
    "                ib_loss,\n",
    "                reg_loss,\n",
    "                ))\n",
    "\n",
    "        ret = dict()\n",
    "        ret['Gen_1 Loss'] = generate_loss_1 / steps\n",
    "        ret['Gen_2 Loss'] = generate_loss_2 / steps\n",
    "        ret['BPR Loss'] = bpr_loss / steps\n",
    "        ret['IM Loss'] = im_loss / steps\n",
    "        ret['IB Loss'] = ib_loss / steps\n",
    "        ret['Reg Loss'] = reg_loss / steps\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def testEpoch(self):\n",
    "        tstLoader = self.handler.tstLoader\n",
    "        epRecall, epNdcg = [0] * 2\n",
    "        i = 0\n",
    "        num = tstLoader.dataset.__len__()\n",
    "        #print('tst num',num)\n",
    "        steps = num // args.tstBat\n",
    "        hr_b,mrr_b,ndcg_b,acc_b=[],[],[],[]\n",
    "        for usr, tar_i in tstLoader:\n",
    "            i += 1\n",
    "            usr = usr.long().cuda()\n",
    "            tar_i=tar_i.long().cuda()\n",
    "            #trnMask = trnMask.cuda()\n",
    "            neg_indx = torch.arange(args.item).cuda().unsqueeze(0)\n",
    "            #neg_indx = torch.randint(low=1, high=args.item, size=(tar_i.shape[0], 1000)).cuda() \n",
    "\n",
    "            usrEmbeds, itmEmbeds = self.model.forward_gcn(self.handler.torchBiAdj)\n",
    "            \n",
    "            tar_i_emb=itmEmbeds[tar_i].unsqueeze(1)\n",
    "            tar_u_emb=usrEmbeds[usr].unsqueeze(1)\n",
    "            neg_i_emb=itmEmbeds[neg_indx].expand(tar_i_emb.shape[0], -1, -1)\n",
    "            \n",
    "            test_i_embeds=torch.cat([tar_i_emb,neg_i_emb],dim=1)\n",
    "            \n",
    "            allPreds = -torch.matmul(tar_u_emb, test_i_embeds.transpose(1,2)).squeeze(1)\n",
    "\n",
    "            print('rating shape:',allPreds.shape)\n",
    "            rank = allPreds.argsort().argsort()[:, 0]\n",
    "            rank=rank.cpu()\n",
    "            res_1 = hr(rank, args.topk)\n",
    "            res_2 = ndcg(rank, args.topk)\n",
    "            res_3 = mrr(rank, args.topk)\n",
    "            res_4 = hr(rank, 1)\n",
    "            \n",
    "            hr_b.append(res_1)\n",
    "            ndcg_b.append(res_2)\n",
    "            mrr_b.append(res_3)\n",
    "            acc_b.append(res_4)\n",
    "            \n",
    "        f_hr=np.mean(hr_b)\n",
    "        f_mrr=np.mean(mrr_b)\n",
    "        f_ndcg=np.mean(ndcg_b)\n",
    "        f_acc=np.mean(acc_b)\n",
    "\n",
    "        return f_hr, f_mrr, f_ndcg, f_acc\n",
    "\n",
    "    def calcRes(self, topLocs, tstLocs, batIds):\n",
    "        assert topLocs.shape[0] == len(batIds)\n",
    "        allRecall = allNdcg = 0\n",
    "        for i in range(len(batIds)):\n",
    "            temTopLocs = list(topLocs[i])\n",
    "            temTstLocs = tstLocs[batIds[i]]\n",
    "            tstNum = len(temTstLocs)\n",
    "            maxDcg = np.sum([np.reciprocal(np.log2(loc + 2)) for loc in range(min(tstNum, args.topk))])\n",
    "            recall = dcg = 0\n",
    "            for val in temTstLocs:\n",
    "                if val in temTopLocs:\n",
    "                    recall += 1\n",
    "                    dcg += np.reciprocal(np.log2(temTopLocs.index(val) + 2))\n",
    "            recall = recall / tstNum\n",
    "            ndcg = dcg / maxDcg\n",
    "            allRecall += recall\n",
    "            allNdcg += ndcg\n",
    "        return allRecall, allNdcg\n",
    "\n",
    "    def generator_generate(self, generator):\n",
    "        edge_index = []\n",
    "        edge_index.append([])\n",
    "        edge_index.append([])\n",
    "        adj = deepcopy(self.handler.torchBiAdj)\n",
    "        idxs = adj._indices()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            view = generator.generate(self.handler.torchBiAdj, idxs, adj)\n",
    "\n",
    "        return view\n",
    "\n",
    "def seed_it(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with torch.cuda.device(args.gpu):\n",
    "        #logger.saveDefault = True\n",
    "        seed_it(args.seed)\n",
    "\n",
    "        print('Start')\n",
    "        handler = my_DataHandler()\n",
    "        handler.LoadData()\n",
    "        print('Load Data')\n",
    "\n",
    "        coach = Coach(handler)\n",
    "        coach.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963087bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
