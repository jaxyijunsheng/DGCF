{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69f63710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "from collections import defaultdict\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f12eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/Zhouziyue/workspace/tensorflow2.5_torch2.1/AAAI_feedback/ml-100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecd9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TRAIN = False\n",
    "\n",
    "class RecsysData(Dataset):\n",
    "\n",
    "    def __init__(self, path=\"../data/recsys2\"):\n",
    "        # train or test\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        print(f'loading [{path}]')\n",
    "        self.mode_dict = {'train': 0, \"test\": 1}\n",
    "        self.mode = self.mode_dict['train']\n",
    "        train_file = path + '/train_imp.csv'\n",
    "        test_file = path + '/test_imp.csv'\n",
    "        self.path = path\n",
    "        self.trainSize = 0\n",
    "        self.testSize = 0\n",
    "\n",
    "        df = pd.read_csv(train_file)\n",
    "        self.trainUniqueUsers = pd.unique(df[\"users\"])\n",
    "        self.trainUser = df[\"users\"].to_numpy()\n",
    "        self.trainItem = df[\"pos_item\"].to_numpy()\n",
    "        self.trainSize = len(df)\n",
    "\n",
    "        #print(np.min(self.trainUser), np.min(self.trainItem))\n",
    "\n",
    "        df_test = pd.read_csv(test_file)\n",
    "        self.testUniqueUsers = pd.unique(df_test[\"users\"])\n",
    "        self.testUser = df_test[\"users\"].to_numpy()\n",
    "        self.testItem = df_test[\"pos_item\"].to_numpy()\n",
    "        \n",
    "        self.m_item = 1523\n",
    "        self.n_user = 943\n",
    "        print(self.m_item,self.n_user)\n",
    "        \n",
    "        self.testSize = len(df)\n",
    "\n",
    "        if ALL_TRAIN:\n",
    "            self.trainUser = np.concatenate((self.trainUser, self.testUser), axis=0)\n",
    "            self.trainItem = np.concatenate((self.trainItem, self.testItem), axis=0)\n",
    "            self.trainSize = self.trainSize + self.testSize\n",
    "        \n",
    "        self.Graph = None\n",
    "        print(f\"{self.trainSize} interactions for training\")\n",
    "        print(f\"{self.testSize} interactions for testing\")\n",
    "        print(f\"Sparsity : {(self.trainSize + self.testSize) / self.n_user / self.m_item}\")\n",
    "\n",
    "        # (users,items), bipartite graph\n",
    "        self.UserItemNet = csr_matrix((np.ones(len(self.trainUser)), \n",
    "                                        (self.trainUser, self.trainItem)),\n",
    "                                        shape=(self.n_user, self.m_item))\n",
    "        \n",
    "\n",
    "        # pre-calculate\n",
    "        self.allPos = self.getUserPosItems(list(range(self.n_user)))\n",
    "        self.testDict = self.__build_test()\n",
    "        print(f\"Ready to go\")\n",
    "\n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        row = torch.Tensor(coo.row).long()\n",
    "        col = torch.Tensor(coo.col).long()\n",
    "        index = torch.stack([row, col])\n",
    "        data = torch.FloatTensor(coo.data)\n",
    "        return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))\n",
    "        \n",
    "    def saveRatingMatrix(self):\n",
    "        test_ratings = csr_matrix((np.ones(len(self.testUser)), \n",
    "                                        (self.testUser, self.testItem)),\n",
    "                                        shape=(self.n_user, self.m_item))\n",
    "        sp.save_npz(self.path + '/train_mat.npz', self.UserItemNet)\n",
    "        sp.save_npz(self.path + '/test_mat.npz', test_ratings)\n",
    "\n",
    "\n",
    "    def getSparseGraph(self):\n",
    "        print(\"loading adjacency matrix\")\n",
    "        if self.Graph is None:\n",
    "            try:\n",
    "                pre_adj_mat = sp.load_npz(self.path + '/s_pre_adj_mat.npz')\n",
    "                print(\"successfully loaded...\")\n",
    "                norm_adj = pre_adj_mat\n",
    "            except :\n",
    "                print(\"generating adjacency matrix\")\n",
    "                s = time.time()\n",
    "                adj_mat = sp.dok_matrix((self.n_user + self.m_item, self.n_user + self.m_item), dtype=np.float32)\n",
    "                adj_mat = adj_mat.tolil()\n",
    "                R = self.UserItemNet.tolil()\n",
    "                adj_mat[:self.n_user, self.n_user:] = R\n",
    "                adj_mat[self.n_user:, :self.n_user] = R.T\n",
    "                adj_mat = adj_mat.todok()\n",
    "                \n",
    "                rowsum = np.array(adj_mat.sum(axis=1))\n",
    "                d_inv = np.power(rowsum, -0.5).flatten()\n",
    "                d_inv[np.isinf(d_inv)] = 0.\n",
    "                d_mat = sp.diags(d_inv)\n",
    "                \n",
    "                norm_adj = d_mat.dot(adj_mat)\n",
    "                norm_adj = norm_adj.dot(d_mat)\n",
    "                norm_adj = norm_adj.tocsr()\n",
    "                end = time.time()\n",
    "                print(f\"costing {end-s}s, saved norm_mat...\")\n",
    "                sp.save_npz(self.path + '/s_pre_adj_mat.npz', norm_adj)\n",
    "                \n",
    "\n",
    "            self.Graph = self._convert_sp_mat_to_sp_tensor(norm_adj)\n",
    "            self.Graph = self.Graph.coalesce().to(self.device)\n",
    "\n",
    "        return self.Graph\n",
    "\n",
    "\n",
    "    def __build_test(self):\n",
    "        test_data = defaultdict(set)\n",
    "        for user, item in zip(self.testUser, self.testItem):\n",
    "            test_data[user].add(item)\n",
    "\n",
    "        return test_data\n",
    "\n",
    "    def getUserItemFeedback(self, users, items):\n",
    "        return np.array(self.UserItemNet[users, items]).astype('uint8').reshape((-1,))\n",
    "\n",
    "    def getUserPosItems(self, users):\n",
    "        posItems = []\n",
    "        for user in users:\n",
    "            posItems.append(self.UserItemNet[user].nonzero()[1])\n",
    "        return posItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de701e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "def UniformSample(dataset:RecsysData):\n",
    "    users = np.random.randint(0, dataset.n_user, dataset.trainSize)\n",
    "    allPos = dataset.allPos\n",
    "    S = []\n",
    "    for user in users:\n",
    "        posForUser = allPos[user]\n",
    "        if len(posForUser) == 0:\n",
    "            continue\n",
    "\n",
    "        positem = posForUser[np.random.randint(0, len(posForUser))]\n",
    "        negitem = np.random.randint(0, dataset.m_item)\n",
    "        while negitem in posForUser:\n",
    "            negitem = np.random.randint(0, dataset.m_item)\n",
    "\n",
    "        S.append([user, positem, negitem])\n",
    "\n",
    "    return np.array(S)\n",
    "\n",
    "def shuffle(*arrays, **kwargs):\n",
    "\n",
    "    require_indices = kwargs.get('indices', False)\n",
    "\n",
    "    if len(set(len(x) for x in arrays)) != 1:\n",
    "        raise ValueError('All inputs to shuffle must have the same length.')\n",
    "\n",
    "    shuffle_indices = np.arange(len(arrays[0]))\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "\n",
    "    if len(arrays) == 1:\n",
    "        result = arrays[0][shuffle_indices]\n",
    "    else:\n",
    "        result = tuple(x[shuffle_indices] for x in arrays)\n",
    "\n",
    "    if require_indices:\n",
    "        return result, shuffle_indices\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def generate_batches(tensors, batch_size):\n",
    "    for i in range(0, len(tensors), batch_size):\n",
    "        yield tensors[i:i + batch_size]\n",
    "\n",
    "def my_generate_batches(tensors_list, batch_size):\n",
    "    for i in range(0, len(tensors_list[0]), batch_size):\n",
    "        yield tensors_list[0][i:i + batch_size], tensors_list[1][i:i + batch_size]\n",
    "        \n",
    "def minibatch(tensors, batch_size):\n",
    "    if len(tensors) == 1:\n",
    "        tensor = tensors[0]\n",
    "        for i in range(0, len(tensor), batch_size):\n",
    "            yield tensor[i:i + batch_size]\n",
    "    else:\n",
    "        for i in range(0, len(tensors[0]), batch_size):\n",
    "            yield tuple(x[i:i + batch_size] for x in tensors)\n",
    "\n",
    "def cust_mul(s, d, dim):\n",
    "    i = s._indices()\n",
    "    v = s._values()\n",
    "    dv = d[i[dim,:]]\n",
    "    return torch.sparse.FloatTensor(i, v * dv, s.size())\n",
    "\n",
    "\n",
    "def calc_recall(ratings, test_data, k, users):\n",
    "    num = ratings.sum(1)\n",
    "    den = np.array([len(test_data[u]) for u in users]).astype('float')\n",
    "    num[den == 0.] = 0.\n",
    "    den[den == 0.] = 1.\n",
    "    recall = np.sum(num/den)\n",
    "    return recall\n",
    "\n",
    "def calc_ndcg(ratings, test_data, k, users):\n",
    "    test_matrix = np.zeros((len(users), k))\n",
    "    for i,user in enumerate(users):\n",
    "        length = k if k <= len(test_data[user]) else len(test_data[user])\n",
    "        test_matrix[i, :length] = 1\n",
    "\n",
    "    idcg = np.sum(test_matrix * 1./np.log2(np.arange(2, k + 2)), axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    dcg = ratings*(1./np.log2(np.arange(2, k + 2)))\n",
    "    dcg = np.sum(dcg, axis=1)\n",
    "    ndcg = np.sum(dcg/idcg)\n",
    "    return ndcg\n",
    "\n",
    "def calc_ncrr(ratings, test_data, k, users):\n",
    "    fractions = [1.0/n for n in range(1,k+1)]\n",
    "    fractions = np.array(fractions)\n",
    "    crr = ratings.dot(fractions.T)\n",
    "\n",
    "    accum = np.cumsum(fractions)\n",
    "    icrr = np.array([accum[min(len(test_data[u])-1, k-1)] for u in users])\n",
    "    icrr[icrr == 0.] = 1.\n",
    "\n",
    "    ncrr = np.sum(crr/icrr)\n",
    "    return ncrr\n",
    "\n",
    "def calc_hm(a, b, c):\n",
    "    return 3/(1/a + 1/b + 1/c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2273d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMP_GCN(nn.Module):\n",
    "    def __init__(self,  \n",
    "                 dataset: RecsysData,\n",
    "                 latent_dim=200, \n",
    "                 n_layers=6, \n",
    "                 keep_prob=0.9,\n",
    "                 groups=4,\n",
    "                 device=torch.device('cuda'),\n",
    "                 dropout_bool=False,\n",
    "                 l2_w=1e-4,\n",
    "                 single=False):\n",
    "        super(IMP_GCN, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_bool = dropout_bool\n",
    "        self.keep_prob = keep_prob\n",
    "        self.Graph = dataset.getSparseGraph()\n",
    "        self.num_users  = dataset.n_user\n",
    "        self.num_items  = dataset.m_item\n",
    "        self.groups = groups\n",
    "        self.device = device\n",
    "        self.l2_w = l2_w\n",
    "        self.single = single\n",
    "        self.__init_weight()\n",
    "\n",
    "    def __init_weight(self):\n",
    "        self.embedding_user = torch.nn.Embedding(self.num_users, self.latent_dim)\n",
    "        self.embedding_item = torch.nn.Embedding(self.num_items, self.latent_dim)\n",
    "        self.fc = torch.nn.Linear(self.latent_dim, self.latent_dim)\n",
    "        self.leaky = torch.nn.LeakyReLU()\n",
    "        self.dropout = torch.nn.Dropout(p=0.4)\n",
    "        self.fc_g = torch.nn.Linear(self.latent_dim, self.groups)\n",
    "        self.f = nn.Sigmoid()\n",
    "\n",
    "        #nn.init.normal_(self.embedding_user.weight, std=0.1)\n",
    "        #nn.init.normal_(self.embedding_item.weight, std=0.1)\n",
    "        nn.init.xavier_uniform_(self.embedding_user.weight, gain=1)\n",
    "        nn.init.xavier_uniform_(self.embedding_item.weight, gain=1)\n",
    "        #nn.init.xavier_uniform_(self.fc.weight, gain=1)\n",
    "        #nn.init.xavier_uniform_(self.fc_g.weight, gain=1)\n",
    "\n",
    "    def __dropout_x(self, x, keep_prob):\n",
    "        size = x.size()\n",
    "        index = x.indices().t()\n",
    "        values = x.values()\n",
    "        random_index = torch.rand(len(values)) + keep_prob\n",
    "        random_index = random_index.int().bool()\n",
    "        index = index[random_index]\n",
    "        values = values[random_index]/keep_prob\n",
    "        g = torch.sparse.FloatTensor(index.t(), values, size)\n",
    "        return g\n",
    "    \n",
    "    def __dropout(self, keep_prob):\n",
    "        graph = self.__dropout_x(self.Graph, keep_prob)\n",
    "        return graph\n",
    "    \n",
    "\n",
    "    def computer(self):    \n",
    "        users_emb = self.embedding_user.weight\n",
    "        items_emb = self.embedding_item.weight\n",
    "        all_emb = torch.cat([users_emb, items_emb])\n",
    "        \n",
    "        if self.dropout_bool and self.training:\n",
    "            g_droped = self.__dropout(self.keep_prob)     \n",
    "        else:\n",
    "            g_droped = self.Graph\n",
    "        \n",
    "        # Compute ego + side embeddings\n",
    "        ego_embed = all_emb\n",
    "        side_embed = torch.sparse.mm(g_droped, all_emb)\n",
    "        \n",
    "        temp = self.dropout(self.leaky(self.fc(ego_embed + side_embed)))\n",
    "        group_scores = self.dropout(self.fc_g(temp))\n",
    "        #group_scores = self.fc_g(temp)\n",
    "\n",
    "        a_top, a_top_idx = torch.topk(group_scores, k=1, sorted=False)\n",
    "        one_hot_emb = torch.eq(group_scores,a_top).float()\n",
    "\n",
    "        u_one_hot, i_one_hot = torch.split(one_hot_emb, [self.num_users, self.num_items])\n",
    "        i_one_hot = torch.ones(i_one_hot.shape).to(self.device)\n",
    "        one_hot_emb = torch.cat([u_one_hot, i_one_hot]).t()\n",
    "\n",
    "        # Create Subgraphs\n",
    "        subgraph_list = []\n",
    "        for g in range(self.groups):\n",
    "            temp = cust_mul(g_droped, one_hot_emb[g], 1)\n",
    "            temp = cust_mul(temp, one_hot_emb[g], 0)\n",
    "            subgraph_list.append(temp)\n",
    "\n",
    "        all_emb_list = [[None for _ in range(self.groups)] for _ in range(self.n_layers)]\n",
    "        for g in range(0,self.groups):\n",
    "            all_emb_list[0][g] = ego_embed\n",
    "        \n",
    "        for k in range(1,self.n_layers):\n",
    "            for g in range(self.groups):\n",
    "                all_emb_list[k][g] = torch.sparse.mm(subgraph_list[g], all_emb_list[k-1][g])\n",
    "\n",
    "        \n",
    "        all_emb_list = [torch.sum(torch.stack(x),0) for x in all_emb_list]\n",
    "        \n",
    "        if self.single:\n",
    "            all_emb = all_emb_list[-1]\n",
    "        else:\n",
    "            weights = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "            all_emb_list = [x * w for x,w in zip(all_emb_list,weights)]\n",
    "            all_emb = torch.sum(torch.stack(all_emb_list),0)\n",
    "            #all_emb = torch.mean(torch.stack(all_emb_list),0)\n",
    "            #all_emb = all_emb_list[-1]\n",
    "\n",
    "        users, items = torch.split(all_emb, [self.num_users, self.num_items])\n",
    "        return users, items\n",
    "    \n",
    "    def getUsersRating(self, users):\n",
    "        all_users, all_items = self.computer()\n",
    "        users_emb = all_users[users.long()]\n",
    "        items_emb = all_items\n",
    "        rating = self.f(torch.matmul(users_emb, items_emb.t()))\n",
    "        return rating\n",
    "    \n",
    "    def my_getUsersRating(self, users,targets):\n",
    "        #items = torch.arange(self.item_num).to(users.device)\n",
    "        all_users, all_items = self.computer()\n",
    "        user_embeds = all_users[users].unsqueeze(1)#[b,1,h]\n",
    "        tar_item_embeds = all_items[targets].unsqueeze(1)#[b,1,h]\n",
    "        #neg_indx = torch.randint(low=1, high=self.num_items, size=(tar_item_embeds.shape[0], 1000))#.to(users.device)  \n",
    "        #neg_indx = torch.arange(self.item_num).to(users.device).unsqueeze(0)\n",
    "        neg_item_embeds = all_items.expand(tar_item_embeds.shape[0], -1, -1)\n",
    "        test_item_embeds=torch.cat([tar_item_embeds,neg_item_embeds],dim=1)#[b,1+1000,h]\n",
    "        #print('user_embeds',user_embeds.shape)\n",
    "        #print('test_item_embeds',test_item_embeds.shape)\n",
    "        \n",
    "        return torch.matmul(user_embeds,neg_item_embeds.transpose(1,2)).squeeze(1),\\\n",
    "    torch.matmul(user_embeds,tar_item_embeds.transpose(1,2)).squeeze(1)\n",
    "    \n",
    "    \n",
    "    def getEmbedding(self, users, pos_items, neg_items):\n",
    "        all_users, all_items = self.computer()\n",
    "        users_emb = all_users[users]\n",
    "        pos_emb = all_items[pos_items]\n",
    "        neg_emb = all_items[neg_items]\n",
    "        users_emb_ego = self.embedding_user(users)\n",
    "        pos_emb_ego = self.embedding_item(pos_items)\n",
    "        neg_emb_ego = self.embedding_item(neg_items)\n",
    "        return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego\n",
    "    \n",
    "    def bpr_loss(self, users, pos, neg):\n",
    "        (users_emb, pos_emb, neg_emb, \n",
    "        userEmb0,  posEmb0, negEmb0) = self.getEmbedding(users.long(), pos.long(), neg.long())\n",
    "        reg_loss = (1/2)*(userEmb0.norm(2).pow(2) + \n",
    "                         posEmb0.norm(2).pow(2)  +\n",
    "                         negEmb0.norm(2).pow(2))/float(len(users))\n",
    "        pos_scores = torch.mul(users_emb, pos_emb)\n",
    "        pos_scores = torch.sum(pos_scores, dim=1)\n",
    "        neg_scores = torch.mul(users_emb, neg_emb)\n",
    "        neg_scores = torch.sum(neg_scores, dim=1)\n",
    "        \n",
    "        loss = torch.mean(F.softplus(neg_scores - pos_scores))\n",
    "        \n",
    "        return loss + self.l2_w * reg_loss\n",
    "       \n",
    "    def forward(self, users, items):\n",
    "        all_users, all_items = self.computer()\n",
    "        users_emb = all_users[users]\n",
    "        items_emb = all_items[items]\n",
    "        inner_pro = torch.mul(users_emb, items_emb)\n",
    "        gamma     = torch.sum(inner_pro, dim=1)\n",
    "        return gamma\n",
    "\n",
    "\n",
    "        all_users, all_items = self.computer()\n",
    "        users_emb = all_users[users]\n",
    "        items_emb = all_items[items]\n",
    "        inner_pro = torch.mul(users_emb, items_emb)\n",
    "        gamma     = torch.sum(inner_pro, dim=1)\n",
    "        return gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8c354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716b4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92064f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading [C:/Users/Zhouziyue/workspace/tensorflow2.5_torch2.1/AAAI_feedback/ml-100k]\n",
      "1523 943\n",
      "58196 interactions for training\n",
      "58196 interactions for testing\n",
      "Sparsity : 0.08104225836571649\n",
      "Ready to go\n",
      "loading adjacency matrix\n",
      "successfully loaded...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_29636\\430940866.py:64: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:607.)\n",
      "  return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))\n"
     ]
    }
   ],
   "source": [
    "#from dataloader import RecsysData\n",
    "#from model import LightGCN, IMP_GCN\n",
    "\n",
    "dataset = RecsysData(path)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "model1 = IMP_GCN(dataset, latent_dim=64, n_layers=3, groups=3, dropout_bool=True, l2_w=0.0002, single=True).to(device)\n",
    "optim1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "args1 = {\"dataset\": dataset, \n",
    "        \"model\": model1,\n",
    "        \"optimiser\": optim1,\n",
    "        \"filename\": f\"imp_gcn_s_d{300}_l{3}_reg{2}_lr{'001'}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a9bd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/50]   Final train loss: 0.6776540  [Time taken: 1.4s]\n",
      "----------------------------------------\n",
      "TEST RESULTS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  6.88it/s]                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:00,  7.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:00,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:00,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:00,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:01,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:01,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:01,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:01,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:01,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:01,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:01,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([738, 1523]) torch.Size([738, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:01,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hr: 0.049784177040989155\n",
      "mrr: 0.015081105753779411\n",
      "ndcg: 0.02303271996264162\n",
      "ac: 0.005319983009400406\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/50]   Final train loss: 0.5586565  [Time taken: 1.2s]\n",
      "----------------------------------------\n",
      "TEST RESULTS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:00,  8.52it/s]                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:00,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:00,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:00,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:00,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:00,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:00,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:01,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:01,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:01,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:01,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:01,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:01,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:01,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:01,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([738, 1523]) torch.Size([738, 1])\n",
      "hr: 0.049492730034722224\n",
      "mrr: 0.015210982412099838\n",
      "ndcg: 0.023070921890423444\n",
      "ac: 0.005574048050050813\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/50]   Final train loss: 0.4339894  [Time taken: 1.4s]\n",
      "----------------------------------------\n",
      "TEST RESULTS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:00,  7.76it/s]                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:00,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:00,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:01,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:01,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([738, 1523]) torch.Size([738, 1])\n",
      "hr: 0.0500145888910061\n",
      "mrr: 0.015148666687309742\n",
      "ndcg: 0.023138284781354428\n",
      "ac: 0.005367289390667345\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/50]   Final train loss: 0.4003026  [Time taken: 1.5s]\n",
      "----------------------------------------\n",
      "TEST RESULTS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  6.86it/s]                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:00,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:00,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [00:01,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [00:01,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [00:01,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [00:01,  8.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [00:01,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [00:01,  7.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [00:01,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [00:01,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([738, 1523]) torch.Size([738, 1])\n",
      "hr: 0.048149956597222224\n",
      "mrr: 0.01468748040497303\n",
      "ndcg: 0.02238947409529774\n",
      "ac: 0.004841626175050813\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/50]   Final train loss: 0.3863030  [Time taken: 1.4s]\n",
      "----------------------------------------\n",
      "TEST RESULTS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  7.42it/s]                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:01,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:01,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:01,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([738, 1523]) torch.Size([738, 1])\n",
      "hr: 0.04841775041285569\n",
      "mrr: 0.014956897124648094\n",
      "ndcg: 0.022640991785795143\n",
      "ac: 0.005306254234417345\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6/50]   Final train loss: 0.3765738  [Time taken: 1.2s]\n",
      "----------------------------------------\n",
      "TEST RESULTS\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  6.97it/s]                                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:00,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:01,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:01,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:01,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([1024, 1523]) torch.Size([1024, 1])\n",
      "rating shape: torch.Size([738, 1523]) torch.Size([738, 1])\n",
      "hr: 0.04792946916285569\n",
      "mrr: 0.013846385292708874\n",
      "ndcg: 0.021685262485288972\n",
      "ac: 0.0036956869812838754\n",
      "----------------------------------------\n",
      "##########################################\n",
      "Early stop is triggered at 6 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#import utils\n",
    "SEED = 2021\n",
    "set_seed(SEED)\n",
    "\n",
    "#from dataloader import RecsysData, ALL_TRAIN\n",
    "#from model_configs import dataset, device, args1, args2\n",
    "#from model import LightGCN, IMP_GCN\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 50\n",
    "TEST_INTERVAL = 1\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "TOP_K = 10\n",
    "\n",
    "def run_train(dataset, model, optimiser):\n",
    "    model.train()\n",
    "    num_batches = dataset.trainSize // BATCH_SIZE + 1\n",
    "    mean_batch_loss = 0\n",
    "\n",
    "    S = UniformSample(dataset)\n",
    "    users = torch.Tensor(S[:, 0]).long().to(device)\n",
    "    posItems = torch.Tensor(S[:, 1]).long().to(device)\n",
    "    negItems = torch.Tensor(S[:, 2]).long().to(device)\n",
    "    users, posItems, negItems = shuffle(users, posItems, negItems)\n",
    "\n",
    "    for i,(b_users, b_pos, b_neg) in enumerate(minibatch((users,posItems,negItems), BATCH_SIZE)):\n",
    "        #bpr_loss, reg_loss = model.bpr_loss(b_users, b_pos, b_neg)\n",
    "        #loss = bpr_loss + reg_loss*L2_W\n",
    "        loss = model.bpr_loss(b_users, b_pos, b_neg)\n",
    "        mean_batch_loss += loss.cpu().item()\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        print(f\"  Batch {i+1}/{num_batches}: loss = {loss.cpu().item():.8f}\" + \" \" * 20, end='\\r')\n",
    "    \n",
    "\n",
    "    return f\"Final train loss: {mean_batch_loss/num_batches:.7f}\"\n",
    "\n",
    "def run_test(dataset, model):\n",
    "    model.eval()\n",
    "    print(\"-\"*40)\n",
    "    print(\"TEST RESULTS\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    test_data = dataset.testDict\n",
    "    test_users = list(test_data.keys())\n",
    "    test_batch_size = 100\n",
    "    cur_idx = 0\n",
    "    \n",
    "    t_recall = 0\n",
    "    t_ndcg = 0\n",
    "    t_ncrr = 0\n",
    "    num_batches = len(test_users) // test_batch_size + 1\n",
    "    for batch_users in tqdm(generate_batches(test_users, test_batch_size), total=num_batches):\n",
    "        with torch.no_grad():\n",
    "            allPos = dataset.getUserPosItems(batch_users)\n",
    "            batch_users_gpu = torch.Tensor(batch_users).long().to(device)\n",
    "            all_ratings = model.getUsersRating(batch_users_gpu)\n",
    "            exclude_index = []\n",
    "            exclude_items = []\n",
    "\n",
    "            for range_i, items in enumerate(allPos):\n",
    "                exclude_index.extend([range_i] * len(items))\n",
    "                exclude_items.extend(items)\n",
    "            all_ratings[exclude_index, exclude_items] = -(1<<10)\n",
    "\n",
    "            _, top_k_ratings = torch.topk(all_ratings, TOP_K, dim=1)\n",
    "            top_k_ratings = top_k_ratings.cpu().numpy()\n",
    "            del all_ratings\n",
    "        \n",
    "        r = []\n",
    "        for i,u in enumerate(batch_users):\n",
    "            pred = list(map(lambda x: x in test_data[u], top_k_ratings[i]))\n",
    "            pred = np.array(pred).astype('float')\n",
    "            r.append(pred)\n",
    "        r = np.array(r).astype('float')\n",
    "\n",
    "        t_recall +=calc_recall(r, test_data, TOP_K, batch_users)\n",
    "        t_ndcg += calc_ndcg(r, test_data, TOP_K, batch_users)\n",
    "        t_ncrr += calc_ncrr(r, test_data, TOP_K, batch_users)\n",
    "    \n",
    "    t_recall /= len(test_users)\n",
    "    t_ndcg /= len(test_users)\n",
    "    t_ncrr /= len(test_users)\n",
    "    hm = calc_hm(t_recall, t_ndcg, t_ncrr)\n",
    "\n",
    "    print(f\"Recall: {t_recall}\\n\" + f\"NDCG: {t_ndcg}\\n\" + f\"NCRR: {t_ncrr}\\n\" + f\"HM: {hm}\")\n",
    "    print(\"-\"*40)\n",
    "    return hm\n",
    "    return \"hm_\" + f\"{hm:.5f}\"[2:]\n",
    "\n",
    "def hr(rank, k):\n",
    "    \"\"\"Hit Rate.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: hit rate.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1\n",
    "    return res / len(rank)\n",
    "\n",
    "\n",
    "def mrr(rank, k):\n",
    "    \"\"\"Mean Reciprocal Rank.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: mrr.\n",
    "    \"\"\"\n",
    "    mrr = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            mrr += 1 / (r + 1)\n",
    "    return mrr / len(rank)\n",
    "\n",
    "\n",
    "def ndcg(rank, k):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: ndcg.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1 / np.log2(r + 2)\n",
    "    return res / len(rank)\n",
    "\n",
    "def my_run_test(dataset, model):\n",
    "    model.eval()\n",
    "    print(\"-\"*40)\n",
    "    print(\"TEST RESULTS\")\n",
    "    print(\"-\"*40)\n",
    "    \n",
    "    test_data = [dataset.testUser,dataset.testItem]\n",
    "    test_users = list(test_data[0])\n",
    "    test_batch_size = 1024\n",
    "    cur_idx = 0\n",
    "    \n",
    "    hr_b=[]\n",
    "    mrr_b=[]\n",
    "    ndcg_b=[]\n",
    "    acc_b=[]\n",
    "    num_batches = len(test_data) // test_batch_size + 1\n",
    "    for batch_users,batch_target in tqdm(my_generate_batches(test_data, test_batch_size), total=num_batches):\n",
    "        with torch.no_grad():\n",
    "            allPos = dataset.getUserPosItems(batch_users)\n",
    "            batch_users_gpu = torch.Tensor(batch_users).long().to(device)\n",
    "            all_rating,pos_rating = model.my_getUsersRating(batch_users,batch_target)\n",
    "            print('rating shape:',all_rating.shape,pos_rating.shape)\n",
    "            #rating = rating.cpu()\n",
    "            #all_rating += mask[batch_users]\n",
    "            rating=-torch.cat([pos_rating,all_rating],dim=1)\n",
    "            rank = rating.argsort().argsort()[:, 0]\n",
    "            rank=rank.cpu()\n",
    "            res_1 = hr(rank, TOP_K)\n",
    "            res_2 = ndcg(rank, TOP_K)\n",
    "            res_3 = mrr(rank, TOP_K)\n",
    "            res_4 = hr(rank, 1)\n",
    "            \n",
    "            hr_b.append(res_1)\n",
    "            mrr_b.append(res_3)\n",
    "            ndcg_b.append(res_2)\n",
    "            acc_b.append(res_4)\n",
    "            \n",
    "    f_hr=np.mean(hr_b)\n",
    "    f_mrr=np.mean(mrr_b)\n",
    "    f_ndcg=np.mean(ndcg_b)\n",
    "    f_acc=np.mean(acc_b)\n",
    "    print(f\"hr: {f_hr}\\n\" + f\"mrr: {f_mrr}\\n\" + f\"ndcg: {f_ndcg}\\n\" + f\"ac: {f_acc}\")\n",
    "    print(\"-\"*40)\n",
    "    return f_hr, f_mrr, f_ndcg, f_acc   \n",
    "\n",
    "\n",
    "def main(args):\n",
    "    dataset = args['dataset']\n",
    "    model = args['model']\n",
    "    optimiser = args['optimiser']\n",
    "    filename = args['filename']\n",
    "    best_epoch, best_recall, best_ndcg, best_hr = 0, 0, 0, 0\n",
    "    early_stop=False\n",
    "    for epoch in range(1,EPOCHS+1):\n",
    "        start = time.time()\n",
    "\n",
    "        train_info = run_train(dataset, model, optimiser)\n",
    "\n",
    "        total_time = time.time() - start\n",
    "        output_info = f'[Time taken: {total_time:.1f}s]'\n",
    "        print(f'Epoch[{epoch}/{EPOCHS}]   {train_info}  {output_info}')\n",
    "\n",
    "        if epoch % TEST_INTERVAL == 0:\n",
    "            if ALL_TRAIN:\n",
    "                generate_submission(model, dataset, f\"submissions/final_{epoch}_2_sub.txt\")\n",
    "            else:\n",
    "                \n",
    "                '''hm = run_test(dataset, model)\n",
    "                str_hm = \"hm_\" + f\"{hm:.5f}\"[2:]\n",
    "                temp = f\"{filename}_e{epoch}_{str_hm}\"'''\n",
    "                f_hr, f_mrr, f_ndcg, f_acc=my_run_test(dataset, model)\n",
    "            if f_hr > best_hr:\n",
    "                best_hr, best_mrr, best_ndcg,best_acc, best_epoch = f_hr, f_mrr, f_ndcg, f_acc, epoch\n",
    "                early_stop_count = 0\n",
    "\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "                if early_stop_count == 3:\n",
    "                    early_stop = True\n",
    "        \n",
    "        if early_stop:\n",
    "            print('##########################################')\n",
    "            print('Early stop is triggered at {} epochs.'.format(epoch))\n",
    "            break\n",
    "main(args1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92897ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
