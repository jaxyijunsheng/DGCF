{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73dcde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    lr = 1e-3\n",
    "    batch = 4096\n",
    "    tstBat = 4096\n",
    "    reg = 1e-5\n",
    "    epoch = 100\n",
    "    latdim = 32\n",
    "    gnn_layer = 2\n",
    "    topk = 10\n",
    "    #data = 'yelp'\n",
    "    ssl_reg = 1\n",
    "    ib_reg = 0.01\n",
    "    temp = 0.5\n",
    "    tstEpoch = 1\n",
    "    gpu = -1\n",
    "    lambda0 = 1e-4\n",
    "    gamma = -0.45\n",
    "    zeta = 1.05\n",
    "    init_temperature = 2.0\n",
    "    temperature_decay = 0.98\n",
    "    eps = 1e-3\n",
    "    seed = 421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f89e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='yelp2018'\n",
    "dataset_folder='yelp'\n",
    "preflix_folder='24_07_30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0911bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def innerProduct(usrEmbeds, itmEmbeds):\n",
    "    return t.sum(usrEmbeds * itmEmbeds, dim=-1)\n",
    "\n",
    "def pairPredict(ancEmbeds, posEmbeds, negEmbeds):\n",
    "    return innerProduct(ancEmbeds, posEmbeds) - innerProduct(ancEmbeds, negEmbeds)\n",
    "\n",
    "def calcRegLoss(model):\n",
    "    ret = 0\n",
    "    for W in model.parameters():\n",
    "        ret += W.norm(2).square()\n",
    "    return ret\n",
    "\n",
    "def contrastLoss(embeds1, embeds2, nodes, temp):\n",
    "    embeds1 = F.normalize(embeds1, p=2)\n",
    "    embeds2 = F.normalize(embeds2, p=2)\n",
    "    pckEmbeds1 = embeds1[nodes]\n",
    "    pckEmbeds2 = embeds2[nodes]\n",
    "    nume = t.exp(t.sum(pckEmbeds1 * pckEmbeds2, dim=-1) / temp)\n",
    "    deno = t.exp(pckEmbeds1 @ embeds2.T / temp).sum(-1)\n",
    "    return -t.log(nume / deno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589e8075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "#from Params import args\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.sparse as sp\n",
    "#from Utils.Utils import contrastLoss, calcRegLoss, pairPredict\n",
    "import time\n",
    "#import torch_sparse\n",
    "\n",
    "init = nn.init.xavier_uniform_\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.uEmbeds = nn.Parameter(init(torch.empty(args.user, args.latdim)))\n",
    "        self.iEmbeds = nn.Parameter(init(torch.empty(args.item, args.latdim)))\n",
    "        self.gcnLayers = nn.Sequential(*[GCNLayer() for i in range(args.gnn_layer)])\n",
    "\n",
    "    def forward_gcn(self, adj):\n",
    "        iniEmbeds = torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "        embedsLst = [iniEmbeds]\n",
    "        for gcn in self.gcnLayers:\n",
    "            embeds = gcn(adj, embedsLst[-1])\n",
    "            embedsLst.append(embeds)\n",
    "        mainEmbeds = sum(embedsLst)\n",
    "\n",
    "        return mainEmbeds[:args.user], mainEmbeds[args.user:]\n",
    "\n",
    "    def forward_graphcl(self, adj):\n",
    "        iniEmbeds = torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "        embedsLst = [iniEmbeds]\n",
    "        for gcn in self.gcnLayers:\n",
    "            embeds = gcn(adj, embedsLst[-1])\n",
    "            embedsLst.append(embeds)\n",
    "        mainEmbeds = sum(embedsLst)\n",
    "\n",
    "        return mainEmbeds\n",
    "\n",
    "    def forward_graphcl_(self, generator):\n",
    "        iniEmbeds = torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "        embedsLst = [iniEmbeds]\t\t\n",
    "        count = 0\n",
    "        for gcn in self.gcnLayers:\n",
    "            with torch.no_grad():\n",
    "                adj = generator.generate(x=embedsLst[-1], layer=count)\n",
    "            embeds = gcn(adj, embedsLst[-1])\n",
    "            embedsLst.append(embeds)\n",
    "            count += 1\n",
    "        mainEmbeds = sum(embedsLst)\n",
    "\n",
    "        return mainEmbeds\n",
    "\n",
    "    def loss_graphcl(self, x1, x2, users, items):\n",
    "        T = args.temp\n",
    "        user_embeddings1, item_embeddings1 = torch.split(x1, [args.user, args.item], dim=0)\n",
    "        user_embeddings2, item_embeddings2 = torch.split(x2, [args.user, args.item], dim=0)\n",
    "\n",
    "        user_embeddings1 = F.normalize(user_embeddings1, dim=1)\n",
    "        item_embeddings1 = F.normalize(item_embeddings1, dim=1)\n",
    "        user_embeddings2 = F.normalize(user_embeddings2, dim=1)\n",
    "        item_embeddings2 = F.normalize(item_embeddings2, dim=1)\n",
    "\n",
    "        user_embs1 = F.embedding(users, user_embeddings1)\n",
    "        item_embs1 = F.embedding(items, item_embeddings1)\n",
    "        user_embs2 = F.embedding(users, user_embeddings2)\n",
    "        item_embs2 = F.embedding(items, item_embeddings2)\n",
    "\n",
    "        all_embs1 = torch.cat([user_embs1, item_embs1], dim=0)\n",
    "        all_embs2 = torch.cat([user_embs2, item_embs2], dim=0)\n",
    "\n",
    "        all_embs1_abs = all_embs1.norm(dim=1)\n",
    "        all_embs2_abs = all_embs2.norm(dim=1)\n",
    "\n",
    "        sim_matrix = torch.einsum('ik,jk->ij', all_embs1, all_embs2) / torch.einsum('i,j->ij', all_embs1_abs, all_embs2_abs)\n",
    "        sim_matrix = torch.exp(sim_matrix / T)\n",
    "        pos_sim = sim_matrix[np.arange(all_embs1.shape[0]), np.arange(all_embs1.shape[0])]\n",
    "        loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n",
    "        loss = - torch.log(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def getEmbeds(self):\n",
    "        self.unfreeze(self.gcnLayers)\n",
    "        return torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "    def unfreeze(self, layer):\n",
    "        for child in layer.children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def getGCN(self):\n",
    "        return self.gcnLayers\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCNLayer, self).__init__()\n",
    "\n",
    "    def forward(self, adj, embeds, flag=True):\n",
    "        if (flag):\n",
    "            return torch.spmm(adj, embeds)\n",
    "        else:\n",
    "            return torch.spmm(adj, embeds)\n",
    "        #torch_sparse.spmm(adj.indices(), adj.values(), adj.shape[0], adj.shape[1], embeds)\n",
    "\n",
    "class vgae_encoder(Model):\n",
    "    def __init__(self):\n",
    "        super(vgae_encoder, self).__init__()\n",
    "        hidden = args.latdim\n",
    "        self.encoder_mean = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, hidden))\n",
    "        self.encoder_std = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, hidden), nn.Softplus())\n",
    "\n",
    "    def forward(self, adj):\n",
    "        x = self.forward_graphcl(adj)\n",
    "\n",
    "        x_mean = self.encoder_mean(x)\n",
    "        x_std = self.encoder_std(x)\n",
    "        gaussian_noise = torch.randn(x_mean.shape).cuda()\n",
    "        x = gaussian_noise * x_std + x_mean\n",
    "        return x, x_mean, x_std\n",
    "\n",
    "class vgae_decoder(nn.Module):\n",
    "    def __init__(self, hidden=args.latdim):\n",
    "        super(vgae_decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(nn.ReLU(inplace=True), nn.Linear(hidden, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, 1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bceloss = nn.BCELoss(reduction='none')\n",
    "\n",
    "    def forward(self, x, x_mean, x_std, users, items, neg_items, encoder):\n",
    "        x_user, x_item = torch.split(x, [args.user, args.item], dim=0)\n",
    "\n",
    "        edge_pos_pred = self.sigmoid(self.decoder(x_user[users] * x_item[items]))\n",
    "        edge_neg_pred = self.sigmoid(self.decoder(x_user[users] * x_item[neg_items]))\n",
    "\n",
    "        loss_edge_pos = self.bceloss( edge_pos_pred, torch.ones(edge_pos_pred.shape).cuda() )\n",
    "        loss_edge_neg = self.bceloss( edge_neg_pred, torch.zeros(edge_neg_pred.shape).cuda() )\n",
    "        loss_rec = loss_edge_pos + loss_edge_neg\n",
    "\n",
    "        kl_divergence = - 0.5 * (1 + 2 * torch.log(x_std) - x_mean**2 - x_std**2).sum(dim=1)\n",
    "\n",
    "        ancEmbeds = x_user[users]\n",
    "        posEmbeds = x_item[items]\n",
    "        negEmbeds = x_item[neg_items]\n",
    "        scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "        bprLoss = - (scoreDiff).sigmoid().log().sum() / args.batch\n",
    "        regLoss = calcRegLoss(encoder) * args.reg\n",
    "\n",
    "        beta = 0.1\n",
    "        loss = (loss_rec + beta * kl_divergence.mean() + bprLoss + regLoss).mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class vgae(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(vgae, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, data, users, items, neg_items):\n",
    "        x, x_mean, x_std = self.encoder(data)\n",
    "        loss = self.decoder(x, x_mean, x_std, users, items, neg_items, self.encoder)\n",
    "        return loss\n",
    "\n",
    "    def generate(self, data, edge_index, adj):\n",
    "        x, _, _ = self.encoder(data)\n",
    "\n",
    "        edge_pred = self.decoder.sigmoid(self.decoder.decoder(x[edge_index[0]] * x[edge_index[1]]))\n",
    "\n",
    "        vals = adj._values()\n",
    "        idxs = adj._indices()\n",
    "        edgeNum = vals.size()\n",
    "        edge_pred = edge_pred[:, 0]\n",
    "        mask = ((edge_pred + 0.5).floor()).type(torch.bool)\n",
    "\n",
    "        newVals = vals[mask]\n",
    "\n",
    "        newVals = newVals / (newVals.shape[0] / edgeNum[0])\n",
    "        newIdxs = idxs[:, mask]\n",
    "\n",
    "        return torch.sparse.FloatTensor(newIdxs, newVals, adj.shape)\n",
    "\n",
    "class DenoisingNet(nn.Module):\n",
    "    def __init__(self, gcnLayers, features):\n",
    "        super(DenoisingNet, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        self.gcnLayers = gcnLayers\n",
    "\n",
    "        self.edge_weights = []\n",
    "        self.nblayers = []\n",
    "        self.selflayers = []\n",
    "\n",
    "        self.attentions = []\n",
    "        self.attentions.append([])\n",
    "        self.attentions.append([])\n",
    "\n",
    "        hidden = args.latdim\n",
    "\n",
    "        self.nblayers_0 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "        self.nblayers_1 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "\n",
    "        self.selflayers_0 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "        self.selflayers_1 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "\n",
    "        self.attentions_0 = nn.Sequential(nn.Linear( 2 * hidden, 1))\n",
    "        self.attentions_1 = nn.Sequential(nn.Linear( 2 * hidden, 1))\n",
    "\n",
    "    def freeze(self, layer):\n",
    "        for child in layer.children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def get_attention(self, input1, input2, layer=0):\n",
    "        if layer == 0:\n",
    "            nb_layer = self.nblayers_0\n",
    "            selflayer = self.selflayers_0\n",
    "        if layer == 1:\n",
    "            nb_layer = self.nblayers_1\n",
    "            selflayer = self.selflayers_1\n",
    "\n",
    "        input1 = nb_layer(input1)\n",
    "        input2 = selflayer(input2)\n",
    "\n",
    "        input10 = torch.concat([input1, input2], axis=1)\n",
    "\n",
    "        if layer == 0:\n",
    "            weight10 = self.attentions_0(input10)\n",
    "        if layer == 1:\n",
    "            weight10 = self.attentions_1(input10)\n",
    "\n",
    "        return weight10\n",
    "\n",
    "    def hard_concrete_sample(self, log_alpha, beta=1.0, training=True):\n",
    "        gamma = args.gamma\n",
    "        zeta = args.zeta\n",
    "\n",
    "        if training:\n",
    "            debug_var = 1e-7\n",
    "            bias = 0.0\n",
    "            np_random = np.random.uniform(low=debug_var, high=1.0-debug_var, size=np.shape(log_alpha.cpu().detach().numpy()))\n",
    "            random_noise = bias + torch.tensor(np_random)\n",
    "            gate_inputs = torch.log(random_noise) - torch.log(1.0 - random_noise)\n",
    "            gate_inputs = (gate_inputs.cuda() + log_alpha) / beta\n",
    "            gate_inputs = torch.sigmoid(gate_inputs)\n",
    "        else:\n",
    "            gate_inputs = torch.sigmoid(log_alpha)\n",
    "\n",
    "        stretched_values = gate_inputs * (zeta-gamma) +gamma\n",
    "        cliped = torch.clamp(stretched_values, 0.0, 1.0)\n",
    "        return cliped.float()\n",
    "\n",
    "    def generate(self, x, layer=0):\n",
    "        f1_features = x[self.row, :]\n",
    "        f2_features = x[self.col, :]\n",
    "\n",
    "        weight = self.get_attention(f1_features, f2_features, layer)\n",
    "\n",
    "        mask = self.hard_concrete_sample(weight, training=False)\n",
    "\n",
    "        mask = torch.squeeze(mask)\n",
    "        adj = torch.sparse.FloatTensor(self.adj_mat._indices(), mask, self.adj_mat.shape)\n",
    "\n",
    "        ind = deepcopy(adj._indices())\n",
    "        row = ind[0, :]\n",
    "        col = ind[1, :]\n",
    "\n",
    "        rowsum = torch.sparse.sum(adj, dim=-1).to_dense()\n",
    "        d_inv_sqrt = torch.reshape(torch.pow(rowsum, -0.5), [-1])\n",
    "        d_inv_sqrt = torch.clamp(d_inv_sqrt, 0.0, 10.0)\n",
    "        row_inv_sqrt = d_inv_sqrt[row]\n",
    "        col_inv_sqrt = d_inv_sqrt[col]\n",
    "        values = torch.mul(adj._values(), row_inv_sqrt)\n",
    "        values = torch.mul(values, col_inv_sqrt)\n",
    "\n",
    "        support = torch.sparse.FloatTensor(adj._indices(), values, adj.shape)\n",
    "\n",
    "        return support\n",
    "\n",
    "    def l0_norm(self, log_alpha, beta):\n",
    "        gamma = args.gamma\n",
    "        zeta = args.zeta\n",
    "        gamma = torch.tensor(gamma)\n",
    "        zeta = torch.tensor(zeta)\n",
    "        reg_per_weight = torch.sigmoid(log_alpha - beta * torch.log(-gamma/zeta))\n",
    "\n",
    "        return torch.mean(reg_per_weight)\n",
    "\n",
    "    def set_fea_adj(self, nodes, adj):\n",
    "        self.node_size = nodes\n",
    "        self.adj_mat = adj\n",
    "\n",
    "        ind = deepcopy(adj._indices())\n",
    "\n",
    "        self.row = ind[0, :]\n",
    "        self.col = ind[1, :]\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            temperature = inputs\n",
    "        else:\n",
    "            temperature = 1.0\n",
    "\n",
    "        self.maskes = []\n",
    "\n",
    "        x = self.features.detach()\n",
    "        layer_index = 0\n",
    "        embedsLst = [self.features.detach()]\n",
    "\n",
    "        for layer in self.gcnLayers:\n",
    "            xs = []\n",
    "            f1_features = x[self.row, :]\n",
    "            f2_features = x[self.col, :]\n",
    "\n",
    "            weight = self.get_attention(f1_features, f2_features, layer=layer_index)\n",
    "            mask = self.hard_concrete_sample(weight, temperature, training)\n",
    "\n",
    "            self.edge_weights.append(weight)\n",
    "            self.maskes.append(mask)\n",
    "            mask = torch.squeeze(mask)\n",
    "\n",
    "            adj = torch.sparse.FloatTensor(self.adj_mat._indices(), mask, self.adj_mat.shape).coalesce()\n",
    "            ind = deepcopy(adj._indices())\n",
    "            row = ind[0, :]\n",
    "            col = ind[1, :]\n",
    "\n",
    "            rowsum = torch.sparse.sum(adj, dim=-1).to_dense() + 1e-6\n",
    "            d_inv_sqrt = torch.reshape(torch.pow(rowsum, -0.5), [-1])\n",
    "            d_inv_sqrt = torch.clamp(d_inv_sqrt, 0.0, 10.0)\n",
    "            row_inv_sqrt = d_inv_sqrt[row]\n",
    "            col_inv_sqrt = d_inv_sqrt[col]\n",
    "            values = torch.mul(adj.values(), row_inv_sqrt)\n",
    "            values = torch.mul(values, col_inv_sqrt)\n",
    "            support = torch.sparse.FloatTensor(adj._indices(), values, adj.shape).coalesce()\n",
    "\n",
    "            nextx = layer(support, x, False)\n",
    "            xs.append(nextx)\n",
    "            x = xs[0]\n",
    "            embedsLst.append(x)\n",
    "            layer_index += 1\n",
    "        return sum(embedsLst)\n",
    "\n",
    "    def lossl0(self, temperature):\n",
    "        l0_loss = torch.zeros([]).cuda()\n",
    "        for weight in self.edge_weights:\n",
    "            l0_loss += self.l0_norm(weight, temperature)\n",
    "        self.edge_weights = []\n",
    "        return l0_loss\n",
    "\n",
    "    def forward(self, users, items, neg_items, temperature):\n",
    "        self.freeze(self.gcnLayers)\n",
    "        x = self.call(temperature, True)\n",
    "        x_user, x_item = torch.split(x, [args.user, args.item], dim=0)\n",
    "        ancEmbeds = x_user[users]\n",
    "        posEmbeds = x_item[items]\n",
    "        negEmbeds = x_item[neg_items]\n",
    "        scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "        bprLoss = - (scoreDiff).sigmoid().log().sum() / args.batch\n",
    "        regLoss = calcRegLoss(self) * args.reg\n",
    "\n",
    "        lossl0 = self.lossl0(temperature) * args.lambda0\n",
    "        return bprLoss + regLoss + lossl0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c8378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix, dok_matrix\n",
    "#from Params import args\n",
    "import scipy.sparse as sp\n",
    "#from Utils.TimeLogger import log\n",
    "import torch as t\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data as dataloader\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self):\n",
    "        predir='E:/datasets/'+dataset_folder+'/'+dataset_name+'/'+preflix_folder+'/'\n",
    "        self.predir = predir\n",
    "        self.trnfile = predir + dataset_name+'_adagcl_train_data.pkl'\n",
    "        self.tstfile = predir + dataset_name+'_adagcl_test_data.pkl'\n",
    "\n",
    "    def loadOneFile(self, filename):\n",
    "        print(filename)\n",
    "        with open(filename, 'rb') as fs:\n",
    "            ret = (pickle.load(fs) != 0).astype(np.float32)\n",
    "        if type(ret) != coo_matrix:\n",
    "            ret = sp.coo_matrix(ret)\n",
    "        return ret\n",
    "\n",
    "    def normalizeAdj(self, mat):\n",
    "        degree = np.array(mat.sum(axis=-1))\n",
    "        dInvSqrt = np.reshape(np.power(degree, -0.5), [-1])\n",
    "        dInvSqrt[np.isinf(dInvSqrt)] = 0.0\n",
    "        dInvSqrtMat = sp.diags(dInvSqrt)\n",
    "        return mat.dot(dInvSqrtMat).transpose().dot(dInvSqrtMat).tocoo()\n",
    "\n",
    "    def makeTorchAdj(self, mat):\n",
    "        # make ui adj\n",
    "        a = sp.csr_matrix((args.user, args.user))\n",
    "        b = sp.csr_matrix((args.item, args.item))\n",
    "        mat = sp.vstack([sp.hstack([a, mat]), sp.hstack([mat.transpose(), b])])\n",
    "        mat = (mat != 0) * 1.0\n",
    "        mat = (mat + sp.eye(mat.shape[0])) * 1.0\n",
    "        mat = self.normalizeAdj(mat)\n",
    "\n",
    "        # make cuda tensor\n",
    "        idxs = t.from_numpy(np.vstack([mat.row, mat.col]).astype(np.int64))\n",
    "        vals = t.from_numpy(mat.data.astype(np.float32))\n",
    "        shape = t.Size(mat.shape)\n",
    "        return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n",
    "\n",
    "    def LoadData(self):\n",
    "        trnMat = self.loadOneFile(self.trnfile)\n",
    "        tstMat = self.loadOneFile(self.tstfile)\n",
    "        self.trnMat = trnMat\n",
    "        args.user, args.item = trnMat.shape\n",
    "        self.torchBiAdj = self.makeTorchAdj(trnMat)\n",
    "        trnData = TrnData(trnMat)\n",
    "        self.trnLoader = dataloader.DataLoader(trnData, batch_size=args.batch, shuffle=True, num_workers=0)\n",
    "        tstData = TstData(tstMat, trnMat)\n",
    "        self.tstLoader = dataloader.DataLoader(tstData, batch_size=args.tstBat, shuffle=False, num_workers=0)\n",
    "\n",
    "class TrnData(data.Dataset):\n",
    "    def __init__(self, coomat):\n",
    "        self.rows = coomat.row\n",
    "        self.cols = coomat.col\n",
    "        self.dokmat = coomat.todok()\n",
    "        self.negs = np.zeros(len(self.rows)).astype(np.int32)\n",
    "\n",
    "    def negSampling(self):\n",
    "        for i in range(len(self.rows)):\n",
    "            u = self.rows[i]\n",
    "            while True:\n",
    "                iNeg = np.random.randint(args.item)\n",
    "                if (u, iNeg) not in self.dokmat:\n",
    "                    break\n",
    "            self.negs[i] = iNeg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rows[idx], self.cols[idx], self.negs[idx]\n",
    "\n",
    "class TstData(data.Dataset):\n",
    "    def __init__(self, coomat, trnMat):\n",
    "        self.csrmat = (trnMat.tocsr() != 0) * 1.0\n",
    "\n",
    "        tstLocs = [None] * coomat.shape[0]\n",
    "        tstUsrs = set()\n",
    "        for i in range(len(coomat.data)):\n",
    "            row = coomat.row[i]\n",
    "            col = coomat.col[i]\n",
    "            if tstLocs[row] is None:\n",
    "                tstLocs[row] = list()\n",
    "            tstLocs[row].append(col)\n",
    "            tstUsrs.add(row)\n",
    "        tstUsrs = np.array(list(tstUsrs))\n",
    "        self.tstUsrs = tstUsrs\n",
    "        self.tstLocs = tstLocs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tstUsrs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tstUsrs[idx], np.reshape(self.csrmat[self.tstUsrs[idx]].toarray(), [-1]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ade36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix, dok_matrix\n",
    "#from Params import args\n",
    "import scipy.sparse as sp\n",
    "#from Utils.TimeLogger import log\n",
    "import torch as t\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data as dataloader\n",
    "\n",
    "class my_DataHandler:\n",
    "    def __init__(self):\n",
    "        predir='E:/datasets/'+dataset_folder+'/'+dataset_name+'/'+preflix_folder+'/'\n",
    "        self.predir = predir\n",
    "        self.trnfile = predir + dataset_name+'_adagcl_train_data.pkl'\n",
    "        self.tstfile = predir + dataset_name+'_adagcl_test_data.pkl'\n",
    "\n",
    "    def loadOneFile(self, filename):\n",
    "        print(filename)\n",
    "        with open(filename, 'rb') as fs:\n",
    "            ret = (pickle.load(fs) != 0).astype(np.float32)\n",
    "        if type(ret) != coo_matrix:\n",
    "            ret = sp.coo_matrix(ret)\n",
    "        return ret\n",
    "\n",
    "    def normalizeAdj(self, mat):\n",
    "        degree = np.array(mat.sum(axis=-1))\n",
    "        dInvSqrt = np.reshape(np.power(degree, -0.5), [-1])\n",
    "        dInvSqrt[np.isinf(dInvSqrt)] = 0.0\n",
    "        dInvSqrtMat = sp.diags(dInvSqrt)\n",
    "        return mat.dot(dInvSqrtMat).transpose().dot(dInvSqrtMat).tocoo()\n",
    "\n",
    "    def makeTorchAdj(self, mat):\n",
    "        # make ui adj\n",
    "        a = sp.csr_matrix((args.user, args.user))\n",
    "        b = sp.csr_matrix((args.item, args.item))\n",
    "        mat = sp.vstack([sp.hstack([a, mat]), sp.hstack([mat.transpose(), b])])\n",
    "        mat = (mat != 0) * 1.0\n",
    "        mat = (mat + sp.eye(mat.shape[0])) * 1.0\n",
    "        mat = self.normalizeAdj(mat)\n",
    "\n",
    "        # make cuda tensor\n",
    "        idxs = t.from_numpy(np.vstack([mat.row, mat.col]).astype(np.int64))\n",
    "        vals = t.from_numpy(mat.data.astype(np.float32))\n",
    "        shape = t.Size(mat.shape)\n",
    "        return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n",
    "\n",
    "    def LoadData(self):\n",
    "        trnMat = self.loadOneFile(self.trnfile)\n",
    "        tstMat = self.loadOneFile(self.tstfile)\n",
    "        self.trnMat = trnMat\n",
    "        args.user, args.item = trnMat.shape\n",
    "        self.torchBiAdj = self.makeTorchAdj(trnMat)\n",
    "        trnData = TrnData(trnMat)\n",
    "        self.trnLoader = dataloader.DataLoader(trnData, batch_size=args.batch, shuffle=True, num_workers=0)\n",
    "        tstData = my_TstData(tstMat, trnMat)\n",
    "        self.tstLoader = dataloader.DataLoader(tstData, batch_size=args.tstBat, shuffle=False, num_workers=0)\n",
    "\n",
    "class TrnData(data.Dataset):\n",
    "    def __init__(self, coomat):\n",
    "        self.rows = coomat.row\n",
    "        self.cols = coomat.col\n",
    "        self.dokmat = coomat.todok()\n",
    "        self.negs = np.zeros(len(self.rows)).astype(np.int32)\n",
    "\n",
    "    def negSampling(self):\n",
    "        for i in range(len(self.rows)):\n",
    "            u = self.rows[i]\n",
    "            while True:\n",
    "                iNeg = np.random.randint(args.item)\n",
    "                if (u, iNeg) not in self.dokmat:\n",
    "                    break\n",
    "            self.negs[i] = iNeg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rows[idx], self.cols[idx], self.negs[idx]\n",
    "\n",
    "class my_TstData(data.Dataset):\n",
    "    def __init__(self, coomat, trnMat):\n",
    "        self.csrmat = (trnMat.tocsr() != 0) * 1.0\n",
    "        tstLocs = [None] * coomat.shape[0]\n",
    "        tstUsrs = set()\n",
    "        target_user=[]\n",
    "        target_item=[]\n",
    "        for i in range(len(coomat.data)):\n",
    "            row = coomat.row[i]\n",
    "            col = coomat.col[i]\n",
    "            if tstLocs[row] is None:\n",
    "                tstLocs[row] = list()\n",
    "            tstLocs[row].append(col)\n",
    "            tstUsrs.add(row)\n",
    "            target_user.append(row)\n",
    "            target_item.append(col)\n",
    "        tstUsrs = np.array(list(tstUsrs))\n",
    "        self.tstUsrs = tstUsrs\n",
    "        self.tstLocs = tstLocs\n",
    "        self.target_user=target_user\n",
    "        self.target_item=target_item\n",
    "        print(len(self.target_user),len(self.target_item))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_user)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.target_user[idx], self.target_item[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b8b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(rank, k):\n",
    "    \"\"\"Hit Rate.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: hit rate.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1\n",
    "    return res / len(rank)\n",
    "\n",
    "\n",
    "def mrr(rank, k):\n",
    "    \"\"\"Mean Reciprocal Rank.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: mrr.\n",
    "    \"\"\"\n",
    "    mrr = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            mrr += 1 / (r + 1)\n",
    "    return mrr / len(rank)\n",
    "\n",
    "\n",
    "def ndcg(rank, k):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: ndcg.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1 / np.log2(r + 2)\n",
    "    return res / len(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51650149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "E:/datasets/yelp/yelp2018/24_07_30/yelp2018_adagcl_train_data.pkl\n",
      "E:/datasets/yelp/yelp2018/24_07_30/yelp2018_adagcl_test_data.pkl\n",
      "19766 19766\n",
      "Load Data\n",
      "USER 7963 ITEM 9587\n",
      "NUM OF INTERACTIONS 70587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_8548\\2995634190.py:47: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:607.)\n",
      "  return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prepared\n",
      "Model Initialized\n",
      "Epoch 0/100, Train: Gen_1 Loss = 3.5992, Gen_2 Loss = 0.7021, BPR Loss = 0.7012, IM Loss = 7.4708, IB Loss = 0.1484, Reg Loss = 0.0014  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.001632 \t mrr: 0.00045\t ndcg: 0.00072\t acc: 0.00020\n",
      "Epoch 1/100, Train: Gen_1 Loss = 3.5506, Gen_2 Loss = 0.7021, BPR Loss = 0.7003, IM Loss = 7.4610, IB Loss = 0.1481, Reg Loss = 0.0014  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.005305 \t mrr: 0.00155\t ndcg: 0.00241\t acc: 0.00050\n",
      "Epoch 2/100, Train: Gen_1 Loss = 3.4981, Gen_2 Loss = 0.7021, BPR Loss = 0.6991, IM Loss = 7.4500, IB Loss = 0.1481, Reg Loss = 0.0014  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.009772 \t mrr: 0.00274\t ndcg: 0.00436\t acc: 0.00065\n",
      "Epoch 3/100, Train: Gen_1 Loss = 3.4746, Gen_2 Loss = 0.7021, BPR Loss = 0.6974, IM Loss = 7.4532, IB Loss = 0.1481, Reg Loss = 0.0015  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.014652 \t mrr: 0.00420\t ndcg: 0.00660\t acc: 0.00117\n",
      "Epoch 4/100, Train: Gen_1 Loss = 3.4262, Gen_2 Loss = 0.7020, BPR Loss = 0.6951, IM Loss = 7.4505, IB Loss = 0.1481, Reg Loss = 0.0016  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.017963 \t mrr: 0.00537\t ndcg: 0.00826\t acc: 0.00175\n",
      "Epoch 5/100, Train: Gen_1 Loss = 3.3393, Gen_2 Loss = 0.7021, BPR Loss = 0.6919, IM Loss = 7.4500, IB Loss = 0.1481, Reg Loss = 0.0018  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.020898 \t mrr: 0.00633\t ndcg: 0.00969\t acc: 0.00208\n",
      "Epoch 6/100, Train: Gen_1 Loss = 3.1470, Gen_2 Loss = 0.7021, BPR Loss = 0.6882, IM Loss = 7.4253, IB Loss = 0.1481, Reg Loss = 0.0021  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.020556 \t mrr: 0.00651\t ndcg: 0.00975\t acc: 0.00230\n",
      "Epoch 7/100, Train: Gen_1 Loss = 3.0010, Gen_2 Loss = 0.7020, BPR Loss = 0.6837, IM Loss = 7.4193, IB Loss = 0.1481, Reg Loss = 0.0025  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.022055 \t mrr: 0.00682\t ndcg: 0.01031\t acc: 0.00238\n",
      "Epoch 8/100, Train: Gen_1 Loss = 2.8794, Gen_2 Loss = 0.7020, BPR Loss = 0.6772, IM Loss = 7.4268, IB Loss = 0.1481, Reg Loss = 0.0030  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.022658 \t mrr: 0.00715\t ndcg: 0.01073\t acc: 0.00249\n",
      "Epoch 9/100, Train: Gen_1 Loss = 2.7913, Gen_2 Loss = 0.7020, BPR Loss = 0.6683, IM Loss = 7.4270, IB Loss = 0.1482, Reg Loss = 0.0038  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.022795 \t mrr: 0.00748\t ndcg: 0.01102\t acc: 0.00277\n",
      "Epoch 10/100, Train: Gen_1 Loss = 2.7302, Gen_2 Loss = 0.7020, BPR Loss = 0.6564, IM Loss = 7.4244, IB Loss = 0.1482, Reg Loss = 0.0048  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.023301 \t mrr: 0.00777\t ndcg: 0.01135\t acc: 0.00314\n",
      "Epoch 11/100, Train: Gen_1 Loss = 2.6989, Gen_2 Loss = 0.7020, BPR Loss = 0.6414, IM Loss = 7.4234, IB Loss = 0.1482, Reg Loss = 0.0062  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.023987 \t mrr: 0.00803\t ndcg: 0.01172\t acc: 0.00319\n",
      "Epoch 12/100, Train: Gen_1 Loss = 2.6429, Gen_2 Loss = 0.7020, BPR Loss = 0.6238, IM Loss = 7.4231, IB Loss = 0.1482, Reg Loss = 0.0079  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.025259 \t mrr: 0.00847\t ndcg: 0.01234\t acc: 0.00347\n",
      "Epoch 13/100, Train: Gen_1 Loss = 2.5496, Gen_2 Loss = 0.7020, BPR Loss = 0.6035, IM Loss = 7.4220, IB Loss = 0.1482, Reg Loss = 0.0100  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.027344 \t mrr: 0.00895\t ndcg: 0.01319\t acc: 0.00337\n",
      "Epoch 14/100, Train: Gen_1 Loss = 2.4667, Gen_2 Loss = 0.7020, BPR Loss = 0.5828, IM Loss = 7.4199, IB Loss = 0.1482, Reg Loss = 0.0124  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.029107 \t mrr: 0.00950\t ndcg: 0.01401\t acc: 0.00366\n",
      "Epoch 15/100, Train: Gen_1 Loss = 2.4158, Gen_2 Loss = 0.7020, BPR Loss = 0.5611, IM Loss = 7.4194, IB Loss = 0.1483, Reg Loss = 0.0151  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.031346 \t mrr: 0.01021\t ndcg: 0.01507\t acc: 0.00392\n",
      "Epoch 16/100, Train: Gen_1 Loss = 2.3937, Gen_2 Loss = 0.7020, BPR Loss = 0.5383, IM Loss = 7.4201, IB Loss = 0.1483, Reg Loss = 0.0180  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.033872 \t mrr: 0.01095\t ndcg: 0.01623\t acc: 0.00402\n",
      "Epoch 17/100, Train: Gen_1 Loss = 2.3590, Gen_2 Loss = 0.7019, BPR Loss = 0.5126, IM Loss = 7.4208, IB Loss = 0.1483, Reg Loss = 0.0214  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.036566 \t mrr: 0.01180\t ndcg: 0.01751\t acc: 0.00443\n",
      "Epoch 18/100, Train: Gen_1 Loss = 2.3587, Gen_2 Loss = 0.7019, BPR Loss = 0.4843, IM Loss = 7.4222, IB Loss = 0.1483, Reg Loss = 0.0252  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.039375 \t mrr: 0.01271\t ndcg: 0.01884\t acc: 0.00495\n",
      "Epoch 19/100, Train: Gen_1 Loss = 2.3213, Gen_2 Loss = 0.7019, BPR Loss = 0.4539, IM Loss = 7.4240, IB Loss = 0.1484, Reg Loss = 0.0294  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.042318 \t mrr: 0.01361\t ndcg: 0.02022\t acc: 0.00516\n",
      "Epoch 20/100, Train: Gen_1 Loss = 2.3380, Gen_2 Loss = 0.7019, BPR Loss = 0.4203, IM Loss = 7.4260, IB Loss = 0.1484, Reg Loss = 0.0340  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.045605 \t mrr: 0.01463\t ndcg: 0.02176\t acc: 0.00555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train: Gen_1 Loss = 2.3126, Gen_2 Loss = 0.7019, BPR Loss = 0.3855, IM Loss = 7.4278, IB Loss = 0.1485, Reg Loss = 0.0390  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.048805 \t mrr: 0.01552\t ndcg: 0.02317\t acc: 0.00584\n",
      "Epoch 22/100, Train: Gen_1 Loss = 2.2967, Gen_2 Loss = 0.7019, BPR Loss = 0.3505, IM Loss = 7.4300, IB Loss = 0.1485, Reg Loss = 0.0444  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.051563 \t mrr: 0.01628\t ndcg: 0.02439\t acc: 0.00595\n",
      "Epoch 23/100, Train: Gen_1 Loss = 2.2932, Gen_2 Loss = 0.7019, BPR Loss = 0.3148, IM Loss = 7.4321, IB Loss = 0.1485, Reg Loss = 0.0500  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.053285 \t mrr: 0.01697\t ndcg: 0.02532\t acc: 0.00625\n",
      "Epoch 24/100, Train: Gen_1 Loss = 2.2807, Gen_2 Loss = 0.7019, BPR Loss = 0.2803, IM Loss = 7.4338, IB Loss = 0.1486, Reg Loss = 0.0558  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.054675 \t mrr: 0.01763\t ndcg: 0.02616\t acc: 0.00666\n",
      "Epoch 25/100, Train: Gen_1 Loss = 2.2563, Gen_2 Loss = 0.7018, BPR Loss = 0.2487, IM Loss = 7.4354, IB Loss = 0.1486, Reg Loss = 0.0617  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.056544 \t mrr: 0.01793\t ndcg: 0.02681\t acc: 0.00652\n",
      "Epoch 26/100, Train: Gen_1 Loss = 2.2550, Gen_2 Loss = 0.7018, BPR Loss = 0.2212, IM Loss = 7.4366, IB Loss = 0.1486, Reg Loss = 0.0673  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058158 \t mrr: 0.01811\t ndcg: 0.02730\t acc: 0.00662\n",
      "Epoch 27/100, Train: Gen_1 Loss = 2.2534, Gen_2 Loss = 0.7018, BPR Loss = 0.1975, IM Loss = 7.4374, IB Loss = 0.1486, Reg Loss = 0.0728  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.059116 \t mrr: 0.01828\t ndcg: 0.02765\t acc: 0.00666\n",
      "Epoch 28/100, Train: Gen_1 Loss = 2.2469, Gen_2 Loss = 0.7018, BPR Loss = 0.1776, IM Loss = 7.4376, IB Loss = 0.1486, Reg Loss = 0.0780  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.059584 \t mrr: 0.01840\t ndcg: 0.02785\t acc: 0.00657\n",
      "Epoch 29/100, Train: Gen_1 Loss = 2.2449, Gen_2 Loss = 0.7018, BPR Loss = 0.1609, IM Loss = 7.4371, IB Loss = 0.1486, Reg Loss = 0.0827  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.059605 \t mrr: 0.01837\t ndcg: 0.02782\t acc: 0.00664\n",
      "Epoch 30/100, Train: Gen_1 Loss = 2.2415, Gen_2 Loss = 0.7018, BPR Loss = 0.1475, IM Loss = 7.4371, IB Loss = 0.1486, Reg Loss = 0.0872  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.059329 \t mrr: 0.01838\t ndcg: 0.02777\t acc: 0.00669\n",
      "Epoch 31/100, Train: Gen_1 Loss = 2.2278, Gen_2 Loss = 0.7017, BPR Loss = 0.1358, IM Loss = 7.4359, IB Loss = 0.1486, Reg Loss = 0.0912  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.059260 \t mrr: 0.01830\t ndcg: 0.02770\t acc: 0.00664\n",
      "Epoch 32/100, Train: Gen_1 Loss = 2.2260, Gen_2 Loss = 0.7017, BPR Loss = 0.1264, IM Loss = 7.4353, IB Loss = 0.1486, Reg Loss = 0.0950  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.059371 \t mrr: 0.01822\t ndcg: 0.02766\t acc: 0.00655\n",
      "Epoch 33/100, Train: Gen_1 Loss = 2.2137, Gen_2 Loss = 0.7017, BPR Loss = 0.1178, IM Loss = 7.4342, IB Loss = 0.1486, Reg Loss = 0.0983  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058900 \t mrr: 0.01809\t ndcg: 0.02745\t acc: 0.00645\n",
      "Epoch 34/100, Train: Gen_1 Loss = 2.2241, Gen_2 Loss = 0.7016, BPR Loss = 0.1108, IM Loss = 7.4337, IB Loss = 0.1486, Reg Loss = 0.1014  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058988 \t mrr: 0.01810\t ndcg: 0.02748\t acc: 0.00646\n",
      "Epoch 35/100, Train: Gen_1 Loss = 2.2118, Gen_2 Loss = 0.7016, BPR Loss = 0.1052, IM Loss = 7.4322, IB Loss = 0.1485, Reg Loss = 0.1042  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058684 \t mrr: 0.01798\t ndcg: 0.02732\t acc: 0.00635\n",
      "Epoch 36/100, Train: Gen_1 Loss = 2.2200, Gen_2 Loss = 0.7016, BPR Loss = 0.1002, IM Loss = 7.4314, IB Loss = 0.1485, Reg Loss = 0.1068  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058507 \t mrr: 0.01793\t ndcg: 0.02725\t acc: 0.00625\n",
      "Epoch 37/100, Train: Gen_1 Loss = 2.2134, Gen_2 Loss = 0.7016, BPR Loss = 0.0952, IM Loss = 7.4305, IB Loss = 0.1485, Reg Loss = 0.1091  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058643 \t mrr: 0.01777\t ndcg: 0.02714\t acc: 0.00610\n",
      "Epoch 38/100, Train: Gen_1 Loss = 2.1856, Gen_2 Loss = 0.7015, BPR Loss = 0.0924, IM Loss = 7.4298, IB Loss = 0.1485, Reg Loss = 0.1111  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058340 \t mrr: 0.01755\t ndcg: 0.02691\t acc: 0.00599\n",
      "Epoch 39/100, Train: Gen_1 Loss = 2.1953, Gen_2 Loss = 0.7015, BPR Loss = 0.0891, IM Loss = 7.4295, IB Loss = 0.1485, Reg Loss = 0.1130  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058391 \t mrr: 0.01747\t ndcg: 0.02686\t acc: 0.00583\n",
      "Epoch 40/100, Train: Gen_1 Loss = 2.1710, Gen_2 Loss = 0.7015, BPR Loss = 0.0856, IM Loss = 7.4290, IB Loss = 0.1485, Reg Loss = 0.1147  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058273 \t mrr: 0.01753\t ndcg: 0.02687\t acc: 0.00597\n",
      "Epoch 41/100, Train: Gen_1 Loss = 2.1711, Gen_2 Loss = 0.7014, BPR Loss = 0.0830, IM Loss = 7.4288, IB Loss = 0.1485, Reg Loss = 0.1162  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058489 \t mrr: 0.01753\t ndcg: 0.02692\t acc: 0.00590\n",
      "Epoch 42/100, Train: Gen_1 Loss = 2.1605, Gen_2 Loss = 0.7014, BPR Loss = 0.0816, IM Loss = 7.4284, IB Loss = 0.1485, Reg Loss = 0.1176  \n",
      "rating shape: torch.Size([4096, 9588])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058528 \t mrr: 0.01753\t ndcg: 0.02693\t acc: 0.00596\n",
      "Epoch 43/100, Train: Gen_1 Loss = 2.1399, Gen_2 Loss = 0.7014, BPR Loss = 0.0799, IM Loss = 7.4281, IB Loss = 0.1484, Reg Loss = 0.1188  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058607 \t mrr: 0.01742\t ndcg: 0.02686\t acc: 0.00578\n",
      "Epoch 44/100, Train: Gen_1 Loss = 2.1388, Gen_2 Loss = 0.7013, BPR Loss = 0.0776, IM Loss = 7.4273, IB Loss = 0.1484, Reg Loss = 0.1199  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([3382, 9588])\n",
      "hr: 0.058980 \t mrr: 0.01736\t ndcg: 0.02689\t acc: 0.00564\n",
      "Epoch 45/100, Train: Gen_1 Loss = 2.1181, Gen_2 Loss = 0.7013, BPR Loss = 0.0760, IM Loss = 7.4271, IB Loss = 0.1484, Reg Loss = 0.1209  \n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n",
      "rating shape: torch.Size([4096, 9588])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 256\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    255\u001b[0m coach \u001b[38;5;241m=\u001b[39m Coach(handler)\n\u001b[1;32m--> 256\u001b[0m coach\u001b[38;5;241m.\u001b[39mrun()\n",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m, in \u001b[0;36mCoach.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakePrint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, ep, reses, tstFlag))\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tstFlag:\n\u001b[1;32m---> 51\u001b[0m     f_hr, f_mrr, f_ndcg, f_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestEpoch()\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhr: \u001b[39m\u001b[38;5;132;01m{:5f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m mrr: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m ndcg: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m acc: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f_hr, f_mrr, f_ndcg, f_acc))\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (f_mrr \u001b[38;5;241m>\u001b[39m mrrMax):\n",
      "Cell \u001b[1;32mIn[8], line 185\u001b[0m, in \u001b[0;36mCoach.testEpoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating shape:\u001b[39m\u001b[38;5;124m'\u001b[39m,allPreds\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    184\u001b[0m rank \u001b[38;5;241m=\u001b[39m allPreds\u001b[38;5;241m.\u001b[39margsort()\u001b[38;5;241m.\u001b[39margsort()[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 185\u001b[0m rank\u001b[38;5;241m=\u001b[39mrank\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    186\u001b[0m res_1 \u001b[38;5;241m=\u001b[39m hr(rank, args\u001b[38;5;241m.\u001b[39mtopk)\n\u001b[0;32m    187\u001b[0m res_2 \u001b[38;5;241m=\u001b[39m ndcg(rank, args\u001b[38;5;241m.\u001b[39mtopk)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import Utils.TimeLogger as logger\n",
    "#from Utils.TimeLogger import log\n",
    "#from Params import args\n",
    "#from Model import Model, vgae_encoder, vgae_decoder, vgae, DenoisingNet\n",
    "#from DataHandler import DataHandler\n",
    "import numpy as np\n",
    "#from Utils.Utils import calcRegLoss, pairPredict\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import scipy.sparse as sp\n",
    "import random\n",
    "\n",
    "class Coach:\n",
    "    def __init__(self, handler):\n",
    "        self.handler = handler\n",
    "\n",
    "        print('USER', args.user, 'ITEM', args.item)\n",
    "        print('NUM OF INTERACTIONS', self.handler.trnLoader.dataset.__len__())\n",
    "        self.metrics = dict()\n",
    "        mets = ['Loss', 'preLoss', 'Recall', 'NDCG']\n",
    "        for met in mets:\n",
    "            self.metrics['Train' + met] = list()\n",
    "            self.metrics['Test' + met] = list()\n",
    "    def makePrint(self, name, ep, reses, save):\n",
    "        ret = 'Epoch %d/%d, %s: ' % (ep, args.epoch, name)\n",
    "        for metric in reses:\n",
    "            val = reses[metric]\n",
    "            ret += '%s = %.4f, ' % (metric, val)\n",
    "            tem = name + metric\n",
    "            if save and tem in self.metrics:\n",
    "                self.metrics[tem].append(val)\n",
    "        ret = ret[:-2] + '  '\n",
    "        return ret\n",
    "    def run(self):\n",
    "        self.prepareModel()\n",
    "        print('Model Prepared')\n",
    "\n",
    "        bestEpoch = 0\n",
    "        hrMax, mrrMax,ndcgMax, accMax=0,0,0,0\n",
    "            \n",
    "        stloc = 0\n",
    "        print('Model Initialized')\n",
    "\n",
    "        for ep in range(stloc, args.epoch):\n",
    "            temperature = max(0.05, args.init_temperature * pow(args.temperature_decay, ep))\n",
    "            tstFlag = (ep % args.tstEpoch == 0)\n",
    "            reses = self.trainEpoch(temperature)\n",
    "            print(self.makePrint('Train', ep, reses, tstFlag))\n",
    "            if tstFlag:\n",
    "                f_hr, f_mrr, f_ndcg, f_acc = self.testEpoch()\n",
    "                print(\"hr: {:5f} \\t mrr: {:.5f}\\t ndcg: {:.5f}\\t acc: {:.5f}\".format(f_hr, f_mrr, f_ndcg, f_acc))\n",
    "                if (f_mrr > mrrMax):\n",
    "                    hrMax, mrrMax,ndcgMax, accMax=f_hr, f_mrr, f_ndcg, f_acc\n",
    "                    bestEpoch = ep\n",
    "        print('Best epoch : ', bestEpoch, \"hr: {:5f} \\t mrr: {:.5f}\\t ndcg: {:.5f}\\t acc: {:.5f}\".format(f_hr, f_mrr, f_ndcg, f_acc))\n",
    "    def prepareModel(self):\n",
    "        self.model = Model().cuda()\n",
    "\n",
    "        encoder = vgae_encoder().cuda()\n",
    "        decoder = vgae_decoder().cuda()\n",
    "        self.generator_1 = vgae(encoder, decoder).cuda()\n",
    "        self.generator_2 = DenoisingNet(self.model.getGCN(), self.model.getEmbeds()).cuda()\n",
    "        self.generator_2.set_fea_adj(args.user+args.item, deepcopy(self.handler.torchBiAdj).cuda())\n",
    "\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(), lr=args.lr, weight_decay=0)\n",
    "        self.opt_gen_1 = torch.optim.Adam(self.generator_1.parameters(), lr=args.lr, weight_decay=0)\n",
    "        self.opt_gen_2 = torch.optim.Adam(filter(lambda p: p.requires_grad, self.generator_2.parameters()), lr=args.lr, weight_decay=0, eps=args.eps)\n",
    "    def trainEpoch(self, temperature):\n",
    "        trnLoader = self.handler.trnLoader\n",
    "        trnLoader.dataset.negSampling()\n",
    "        generate_loss_1, generate_loss_2, bpr_loss, im_loss, ib_loss, reg_loss = 0, 0, 0, 0, 0, 0\n",
    "        steps = trnLoader.dataset.__len__() // args.batch\n",
    "\n",
    "        for i, tem in enumerate(trnLoader):\n",
    "            data = deepcopy(self.handler.torchBiAdj).cuda()\n",
    "\n",
    "            data1 = self.generator_generate(self.generator_1)\n",
    "\n",
    "            self.opt.zero_grad()\n",
    "            self.opt_gen_1.zero_grad()\n",
    "            self.opt_gen_2.zero_grad()\n",
    "\n",
    "            ancs, poss, negs = tem\n",
    "            ancs = ancs.long().cuda()\n",
    "            poss = poss.long().cuda()\n",
    "            negs = negs.long().cuda()\n",
    "\n",
    "            out1 = self.model.forward_graphcl(data1)\n",
    "            out2 = self.model.forward_graphcl_(self.generator_2)\n",
    "\n",
    "            loss = self.model.loss_graphcl(out1, out2, ancs, poss).mean() * args.ssl_reg\n",
    "            im_loss += float(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            # info bottleneck\n",
    "            _out1 = self.model.forward_graphcl(data1)\n",
    "            _out2 = self.model.forward_graphcl_(self.generator_2)\n",
    "\n",
    "            loss_ib = self.model.loss_graphcl(_out1, out1.detach(), ancs, poss) + self.model.loss_graphcl(_out2, out2.detach(), ancs, poss)\n",
    "            loss= loss_ib.mean() * args.ib_reg\n",
    "            ib_loss += float(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            # BPR\n",
    "            usrEmbeds, itmEmbeds = self.model.forward_gcn(data)\n",
    "            ancEmbeds = usrEmbeds[ancs]\n",
    "            posEmbeds = itmEmbeds[poss]\n",
    "            negEmbeds = itmEmbeds[negs]\n",
    "            scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "            bprLoss = - (scoreDiff).sigmoid().log().sum() / args.batch\n",
    "            regLoss = calcRegLoss(self.model) * args.reg\n",
    "            loss = bprLoss + regLoss\n",
    "            bpr_loss += float(bprLoss)\n",
    "            reg_loss += float(regLoss)\n",
    "            loss.backward()\n",
    "\n",
    "            loss_1 = self.generator_1(deepcopy(self.handler.torchBiAdj).cuda(), ancs, poss, negs)\n",
    "            loss_2 = self.generator_2(ancs, poss, negs, temperature)\n",
    "\n",
    "            loss = loss_1 + loss_2\n",
    "            generate_loss_1 += float(loss_1)\n",
    "            generate_loss_2 += float(loss_2)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt_gen_1.step()\n",
    "            self.opt_gen_2.step()\n",
    "            if False:\n",
    "                print('Step %d/%d: gen 1 : %.3f ; gen 2 : %.3f ; bpr : %.3f ; im : %.3f ; ib : %.3f ; reg : %.3f  ' % (\n",
    "                i, \n",
    "                steps,\n",
    "                generate_loss_1,\n",
    "                generate_loss_2,\n",
    "                bpr_loss,\n",
    "                im_loss,\n",
    "                ib_loss,\n",
    "                reg_loss,\n",
    "                ))\n",
    "\n",
    "        ret = dict()\n",
    "        ret['Gen_1 Loss'] = generate_loss_1 / steps\n",
    "        ret['Gen_2 Loss'] = generate_loss_2 / steps\n",
    "        ret['BPR Loss'] = bpr_loss / steps\n",
    "        ret['IM Loss'] = im_loss / steps\n",
    "        ret['IB Loss'] = ib_loss / steps\n",
    "        ret['Reg Loss'] = reg_loss / steps\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def testEpoch(self):\n",
    "        tstLoader = self.handler.tstLoader\n",
    "        epRecall, epNdcg = [0] * 2\n",
    "        i = 0\n",
    "        num = tstLoader.dataset.__len__()\n",
    "        #print('tst num',num)\n",
    "        steps = num // args.tstBat\n",
    "        hr_b,mrr_b,ndcg_b,acc_b=[],[],[],[]\n",
    "        for usr, tar_i in tstLoader:\n",
    "            i += 1\n",
    "            usr = usr.long().cuda()\n",
    "            tar_i=tar_i.long().cuda()\n",
    "            #trnMask = trnMask.cuda()\n",
    "            neg_indx = torch.arange(args.item).cuda().unsqueeze(0)\n",
    "            #neg_indx = torch.randint(low=1, high=args.item, size=(tar_i.shape[0], 1000)).cuda() \n",
    "\n",
    "            usrEmbeds, itmEmbeds = self.model.forward_gcn(self.handler.torchBiAdj)\n",
    "            \n",
    "            tar_i_emb=itmEmbeds[tar_i].unsqueeze(1)\n",
    "            tar_u_emb=usrEmbeds[usr].unsqueeze(1)\n",
    "            neg_i_emb=itmEmbeds[neg_indx].expand(tar_i_emb.shape[0], -1, -1)\n",
    "            \n",
    "            test_i_embeds=torch.cat([tar_i_emb,neg_i_emb],dim=1)\n",
    "            \n",
    "            allPreds = -torch.matmul(tar_u_emb, test_i_embeds.transpose(1,2)).squeeze(1)\n",
    "\n",
    "            print('rating shape:',allPreds.shape)\n",
    "            rank = allPreds.argsort().argsort()[:, 0]\n",
    "            rank=rank.cpu()\n",
    "            res_1 = hr(rank, args.topk)\n",
    "            res_2 = ndcg(rank, args.topk)\n",
    "            res_3 = mrr(rank, args.topk)\n",
    "            res_4 = hr(rank, 1)\n",
    "            \n",
    "            hr_b.append(res_1)\n",
    "            ndcg_b.append(res_2)\n",
    "            mrr_b.append(res_3)\n",
    "            acc_b.append(res_4)\n",
    "            \n",
    "        f_hr=np.mean(hr_b)\n",
    "        f_mrr=np.mean(mrr_b)\n",
    "        f_ndcg=np.mean(ndcg_b)\n",
    "        f_acc=np.mean(acc_b)\n",
    "\n",
    "        return f_hr, f_mrr, f_ndcg, f_acc\n",
    "\n",
    "    def calcRes(self, topLocs, tstLocs, batIds):\n",
    "        assert topLocs.shape[0] == len(batIds)\n",
    "        allRecall = allNdcg = 0\n",
    "        for i in range(len(batIds)):\n",
    "            temTopLocs = list(topLocs[i])\n",
    "            temTstLocs = tstLocs[batIds[i]]\n",
    "            tstNum = len(temTstLocs)\n",
    "            maxDcg = np.sum([np.reciprocal(np.log2(loc + 2)) for loc in range(min(tstNum, args.topk))])\n",
    "            recall = dcg = 0\n",
    "            for val in temTstLocs:\n",
    "                if val in temTopLocs:\n",
    "                    recall += 1\n",
    "                    dcg += np.reciprocal(np.log2(temTopLocs.index(val) + 2))\n",
    "            recall = recall / tstNum\n",
    "            ndcg = dcg / maxDcg\n",
    "            allRecall += recall\n",
    "            allNdcg += ndcg\n",
    "        return allRecall, allNdcg\n",
    "\n",
    "    def generator_generate(self, generator):\n",
    "        edge_index = []\n",
    "        edge_index.append([])\n",
    "        edge_index.append([])\n",
    "        adj = deepcopy(self.handler.torchBiAdj)\n",
    "        idxs = adj._indices()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            view = generator.generate(self.handler.torchBiAdj, idxs, adj)\n",
    "\n",
    "        return view\n",
    "\n",
    "def seed_it(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with torch.cuda.device(args.gpu):\n",
    "        #logger.saveDefault = True\n",
    "        seed_it(args.seed)\n",
    "\n",
    "        print('Start')\n",
    "        handler = my_DataHandler()\n",
    "        handler.LoadData()\n",
    "        print('Load Data')\n",
    "\n",
    "        coach = Coach(handler)\n",
    "        coach.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963087bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
