{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9cd72b0-eace-4468-bb8a-d2187f1d4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "import gc\n",
    "import configparser\n",
    "import time\n",
    "import argparse\n",
    "#from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff5053cb-0390-4cc5-855c-4f0bb03fc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_param_prepare(config_file):\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file)\n",
    "\n",
    "    params = {}\n",
    "\n",
    "    embedding_dim = config.getint('Model', 'embedding_dim')\n",
    "    params['embedding_dim'] = embedding_dim\n",
    "    ii_neighbor_num = config.getint('Model', 'ii_neighbor_num')\n",
    "    params['ii_neighbor_num'] = ii_neighbor_num\n",
    "    model_save_path = config['Model']['model_save_path']\n",
    "    params['model_save_path'] = model_save_path\n",
    "    max_epoch = config.getint('Model', 'max_epoch')\n",
    "    params['max_epoch'] = max_epoch\n",
    "\n",
    "    params['enable_tensorboard'] = config.getboolean('Model', 'enable_tensorboard')\n",
    "    \n",
    "    initial_weight = config.getfloat('Model', 'initial_weight')\n",
    "    params['initial_weight'] = initial_weight\n",
    "\n",
    "    dataset = config['Training']['dataset']\n",
    "    params['dataset'] = dataset\n",
    "    train_file_path = config['Training']['train_file_path']\n",
    "    gpu = config['Training']['gpu']\n",
    "    params['gpu'] = gpu\n",
    "    device = torch.device('cuda:'+ params['gpu'] if torch.cuda.is_available() else \"cpu\")\n",
    "    params['device'] = device\n",
    "    lr = config.getfloat('Training', 'learning_rate')\n",
    "    params['lr'] = lr\n",
    "    batch_size = config.getint('Training', 'batch_size')\n",
    "    params['batch_size'] = batch_size\n",
    "    early_stop_epoch = config.getint('Training', 'early_stop_epoch')\n",
    "    params['early_stop_epoch'] = early_stop_epoch\n",
    "    w1 = config.getfloat('Training', 'w1')\n",
    "    w2 = config.getfloat('Training', 'w2')\n",
    "    w3 = config.getfloat('Training', 'w3')\n",
    "    w4 = config.getfloat('Training', 'w4')\n",
    "    params['w1'] = w1\n",
    "    params['w2'] = w2\n",
    "    params['w3'] = w3\n",
    "    params['w4'] = w4\n",
    "    negative_num = config.getint('Training', 'negative_num')\n",
    "    negative_weight = config.getfloat('Training', 'negative_weight')\n",
    "    params['negative_num'] = negative_num\n",
    "    params['negative_weight'] = negative_weight\n",
    "\n",
    "    gamma = config.getfloat('Training', 'gamma')\n",
    "    params['gamma'] = gamma\n",
    "    lambda_ = config.getfloat('Training', 'lambda')\n",
    "    params['lambda'] = lambda_\n",
    "    sampling_sift_pos = config.getboolean('Training', 'sampling_sift_pos')\n",
    "    params['sampling_sift_pos'] = sampling_sift_pos\n",
    "    \n",
    "    test_batch_size = config.getint('Testing', 'test_batch_size')\n",
    "    params['test_batch_size'] = test_batch_size\n",
    "    topk = config.getint('Testing', 'topk') \n",
    "    params['topk'] = topk\n",
    "\n",
    "    test_file_path = config['Testing']['test_file_path']\n",
    "\n",
    "    # dataset processing\n",
    "    train_data, test_data, train_mat, user_num, item_num, constraint_mat = load_data(train_file_path, test_file_path)\n",
    "    train_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle = True, num_workers=5)\n",
    "    #test_loader = data.DataLoader(list(range(user_num)), batch_size=test_batch_size, shuffle=False, num_workers=5)\n",
    "    \n",
    "    test_loader = data.DataLoader(test_data, batch_size=test_batch_size, shuffle=False, num_workers=5)\n",
    "    \n",
    "    params['user_num'] = user_num\n",
    "    params['item_num'] = item_num\n",
    "\n",
    "    # mask matrix for testing to accelarate testing speed\n",
    "    mask = torch.zeros(user_num, item_num)\n",
    "    interacted_items = [[] for _ in range(user_num)]\n",
    "    for (u, i) in train_data:\n",
    "        mask[u][i] = -np.inf\n",
    "        interacted_items[u].append(i)\n",
    "\n",
    "    # test user-item interaction, which is ground truth\n",
    "    test_ground_truth_list = [[] for _ in range(user_num)]\n",
    "    for (u, i) in test_data:\n",
    "        test_ground_truth_list[u].append(i)\n",
    "\n",
    "    # Compute \\Omega to extend UltraGCN to the item-item co-occurrence graph\n",
    "    ii_cons_mat_path = './' + dataset + '_ii_constraint_mat'\n",
    "    ii_neigh_mat_path = './' + dataset + '_ii_neighbor_mat'\n",
    "    \n",
    "    if os.path.exists(ii_cons_mat_path):\n",
    "        ii_constraint_mat = pload(ii_cons_mat_path)\n",
    "        ii_neighbor_mat = pload(ii_neigh_mat_path)\n",
    "    else:\n",
    "        ii_neighbor_mat, ii_constraint_mat = get_ii_constraint_mat(train_mat, ii_neighbor_num)\n",
    "        pstore(ii_neighbor_mat, ii_neigh_mat_path)\n",
    "        pstore(ii_constraint_mat, ii_cons_mat_path)\n",
    "\n",
    "    return params, constraint_mat, ii_constraint_mat, ii_neighbor_mat, train_loader, test_loader, mask, test_ground_truth_list, interacted_items\n",
    "\n",
    "\n",
    "def get_ii_constraint_mat(train_mat, num_neighbors, ii_diagonal_zero = False):\n",
    "    print('Computing \\\\Omega for the item-item graph... ')\n",
    "    A = train_mat.T.dot(train_mat)\t# I * I\n",
    "    n_items = A.shape[0]\n",
    "    res_mat = torch.zeros((n_items, num_neighbors))\n",
    "    res_sim_mat = torch.zeros((n_items, num_neighbors))\n",
    "    if ii_diagonal_zero:\n",
    "        A[range(n_items), range(n_items)] = 0\n",
    "    items_D = np.sum(A, axis = 0).reshape(-1)\n",
    "    users_D = np.sum(A, axis = 1).reshape(-1)\n",
    "\n",
    "    beta_uD = (np.sqrt(users_D + 1) / users_D).reshape(-1, 1)\n",
    "    beta_iD = (1 / np.sqrt(items_D + 1)).reshape(1, -1)\n",
    "    all_ii_constraint_mat = torch.from_numpy(beta_uD.dot(beta_iD))\n",
    "    for i in range(n_items):\n",
    "        row = all_ii_constraint_mat[i] * torch.from_numpy(A.getrow(i).toarray()[0])\n",
    "        row_sims, row_idxs = torch.topk(row, num_neighbors)\n",
    "        res_mat[i] = row_idxs\n",
    "        res_sim_mat[i] = row_sims\n",
    "        if i % 15000 == 0:\n",
    "            print('i-i constraint matrix {} ok'.format(i))\n",
    "\n",
    "    print('Computation \\\\Omega OK!')\n",
    "    return res_mat.long(), res_sim_mat.float()\n",
    "\n",
    "    \n",
    "def load_data(train_file, test_file):\n",
    "    trainUniqueUsers, trainItem, trainUser = [], [], []\n",
    "    testUniqueUsers, testItem, testUser = [], [], []\n",
    "    n_user, m_item = 0, 0\n",
    "    trainDataSize, testDataSize = 0, 0\n",
    "    with open(train_file, 'r') as f:\n",
    "        for l in f.readlines():\n",
    "            if len(l) > 0:\n",
    "                l = l.strip('\\n').split(' ')\n",
    "                items = [int(i) for i in l[1:]]\n",
    "                uid = int(l[0])\n",
    "                trainUniqueUsers.append(uid)\n",
    "                trainUser.extend([uid] * len(items))\n",
    "                trainItem.extend(items)\n",
    "                m_item = max(m_item, max(items))\n",
    "                n_user = max(n_user, uid)\n",
    "                trainDataSize += len(items)\n",
    "    trainUniqueUsers = np.array(trainUniqueUsers)\n",
    "    trainUser = np.array(trainUser)\n",
    "    trainItem = np.array(trainItem)\n",
    "\n",
    "    with open(test_file) as f:\n",
    "        for l in f.readlines():\n",
    "            if len(l) > 0:\n",
    "                l = l.strip('\\n').split(' ')\n",
    "                try:\n",
    "                    items = [int(i) for i in l[1:]]\n",
    "                except:\n",
    "                    items = []\n",
    "                uid = int(l[0])\n",
    "                testUniqueUsers.append(uid)\n",
    "                testUser.extend([uid] * len(items))\n",
    "                testItem.extend(items)\n",
    "                try:\n",
    "                    m_item = max(m_item, max(items))\n",
    "                except:\n",
    "                    m_item = m_item\n",
    "                n_user = max(n_user, uid)\n",
    "                testDataSize += len(items)\n",
    "\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    n_user += 1\n",
    "    m_item += 1\n",
    "\n",
    "    for i in range(len(trainUser)):\n",
    "        train_data.append([trainUser[i], trainItem[i]])\n",
    "    for i in range(len(testUser)):\n",
    "        test_data.append([testUser[i], testItem[i]])\n",
    "    train_mat = sp.dok_matrix((n_user, m_item), dtype=np.float32)\n",
    "\n",
    "    for x in train_data:\n",
    "        train_mat[x[0], x[1]] = 1.0\n",
    "\n",
    "    # construct degree matrix for graphmf\n",
    "\n",
    "    items_D = np.sum(train_mat, axis = 0).reshape(-1)\n",
    "    users_D = np.sum(train_mat, axis = 1).reshape(-1)\n",
    "\n",
    "    beta_uD = (np.sqrt(users_D + 1) / users_D).reshape(-1, 1)\n",
    "    beta_iD = (1 / np.sqrt(items_D + 1)).reshape(1, -1)\n",
    "\n",
    "    constraint_mat = {\"beta_uD\": torch.from_numpy(beta_uD).reshape(-1),\n",
    "                      \"beta_iD\": torch.from_numpy(beta_iD).reshape(-1)}\n",
    "\n",
    "    return train_data, test_data, train_mat, n_user, m_item, constraint_mat\n",
    "\n",
    "\n",
    "def pload(path):\n",
    "\twith open(path, 'rb') as f:\n",
    "\t\tres = pickle.load(f)\n",
    "\tprint('load path = {} object'.format(path))\n",
    "\treturn res\n",
    "\n",
    "def pstore(x, path):\n",
    "\twith open(path, 'wb') as f:\n",
    "\t\tpickle.dump(x, f)\n",
    "\tprint('store object in path = {} ok'.format(path))\n",
    "\n",
    "\n",
    "def Sampling(pos_train_data, item_num, neg_ratio, interacted_items, sampling_sift_pos):\n",
    "\tneg_candidates = np.arange(item_num)\n",
    "\n",
    "\tif sampling_sift_pos:\n",
    "\t\tneg_items = []\n",
    "\t\tfor u in pos_train_data[0]:\n",
    "\t\t\tprobs = np.ones(item_num)\n",
    "\t\t\tprobs[interacted_items[u]] = 0\n",
    "\t\t\tprobs /= np.sum(probs)\n",
    "\n",
    "\t\t\tu_neg_items = np.random.choice(neg_candidates, size = neg_ratio, p = probs, replace = True).reshape(1, -1)\n",
    "\t\n",
    "\t\t\tneg_items.append(u_neg_items)\n",
    "\n",
    "\t\tneg_items = np.concatenate(neg_items, axis = 0) \n",
    "\telse:\n",
    "\t\tneg_items = np.random.choice(neg_candidates, (len(pos_train_data[0]), neg_ratio), replace = True)\n",
    "\t\n",
    "\tneg_items = torch.from_numpy(neg_items)\n",
    "\t\n",
    "\treturn pos_train_data[0], pos_train_data[1], neg_items\t# users, pos_items, neg_items\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089004cd-dfe8-4d8c-ac2b-9e61b3bde6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################### UltraGCN ######################\n",
      "Loading Configuration...\n",
      "Computing \\Omega for the item-item graph... \n",
      "i-i constraint matrix 0 ok\n",
      "Computation \\Omega OK!\n",
      "store object in path = ./gowalla_ii_neighbor_mat ok\n",
      "store object in path = ./gowalla_ii_constraint_mat ok\n",
      "Load Configuration OK, show them below\n",
      "Configuration:\n",
      "{'embedding_dim': 64, 'ii_neighbor_num': 10, 'model_save_path': 'ultragcn_ml-latest-small.pt', 'max_epoch': 100, 'enable_tensorboard': False, 'initial_weight': 0.0001, 'dataset': 'gowalla', 'gpu': '0', 'device': device(type='cuda', index=0), 'lr': 0.001, 'batch_size': 1024, 'early_stop_epoch': 3, 'w1': 1e-07, 'w2': 1.0, 'w3': 1e-07, 'w4': 1.0, 'negative_num': 4, 'negative_weight': 4.0, 'gamma': 0.0001, 'lambda': 0.0005, 'sampling_sift_pos': False, 'test_batch_size': 2048, 'topk': 10, 'user_num': 8710, 'item_num': 5855}\n",
      "Total training batches = 36\n",
      "epoch: 0\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 0 is: train time = 00: 00: 11, test time = 00: 00: 11\n",
      "Loss = 118.66911, hr: 0.003836 \t mrr: 0.00131\t ndcg: 0.00189\t acc: 0.00054\n",
      "epoch: 1\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 1 is: train time = 00: 00: 11, test time = 00: 00: 11\n",
      "Loss = 127.00137, hr: 0.048404 \t mrr: 0.01697\t ndcg: 0.02431\t acc: 0.00611\n",
      "epoch: 2\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 2 is: train time = 00: 00: 11, test time = 00: 00: 11\n",
      "Loss = 111.80769, hr: 0.052574 \t mrr: 0.01835\t ndcg: 0.02629\t acc: 0.00744\n",
      "epoch: 3\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 3 is: train time = 00: 00: 11, test time = 00: 00: 11\n",
      "Loss = 110.44009, hr: 0.052770 \t mrr: 0.01821\t ndcg: 0.02622\t acc: 0.00697\n",
      "epoch: 4\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 4 is: train time = 00: 00: 11, test time = 00: 00: 10\n",
      "Loss = 96.88686, hr: 0.052965 \t mrr: 0.01853\t ndcg: 0.02654\t acc: 0.00716\n",
      "epoch: 5\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 5 is: train time = 00: 00: 11, test time = 00: 00: 11\n",
      "Loss = 85.03598, hr: 0.052323 \t mrr: 0.01843\t ndcg: 0.02633\t acc: 0.00696\n",
      "epoch: 6\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 6 is: train time = 00: 00: 11, test time = 00: 00: 10\n",
      "Loss = 74.50789, hr: 0.052784 \t mrr: 0.01831\t ndcg: 0.02634\t acc: 0.00690\n",
      "epoch: 7\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 7 is: train time = 00: 00: 11, test time = 00: 00: 11\n",
      "Loss = 76.70490, hr: 0.053676 \t mrr: 0.01832\t ndcg: 0.02651\t acc: 0.00695\n",
      "epoch: 8\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 8 is: train time = 00: 00: 12, test time = 00: 00: 11\n",
      "Loss = 76.05495, hr: 0.053676 \t mrr: 0.01825\t ndcg: 0.02647\t acc: 0.00672\n",
      "epoch: 9\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 9 is: train time = 00: 00: 11, test time = 00: 00: 11\n",
      "Loss = 78.27660, hr: 0.053425 \t mrr: 0.01880\t ndcg: 0.02682\t acc: 0.00776\n",
      "epoch: 10\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([2048, 5855]) torch.Size([2048, 1])\n",
      "rating shape: torch.Size([2048, 5856])\n",
      "rating shape: torch.Size([1304, 5855]) torch.Size([1304, 1])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "The time for epoch 10 is: train time = 00: 00: 11, test time = 00: 00: 11\n",
      "Loss = 69.40182, hr: 0.053230 \t mrr: 0.01799\t ndcg: 0.02617\t acc: 0.00631\n",
      "##########################################\n",
      "Early stop is triggered at 10 epochs.\n",
      "Results:\n",
      "best epoch = 7, best recall = 0, best ndcg = 0.026513181860902076\n",
      "The best model is saved at ultragcn_ml-latest-small.pt\n",
      "Training end!\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "class UltraGCN(nn.Module):\n",
    "    def __init__(self, params, constraint_mat, ii_constraint_mat, ii_neighbor_mat):\n",
    "        super(UltraGCN, self).__init__()\n",
    "        device = torch.device('cuda:'+ params['gpu'] if torch.cuda.is_available() else \"cpu\")\n",
    "        self.user_num = params['user_num']\n",
    "        self.item_num = params['item_num']\n",
    "        self.embedding_dim = params['embedding_dim']\n",
    "        self.w1 = params['w1']\n",
    "        self.w2 = params['w2']\n",
    "        self.w3 = params['w3']\n",
    "        self.w4 = params['w4']\n",
    "\n",
    "        self.negative_weight = params['negative_weight']\n",
    "        self.gamma = params['gamma']\n",
    "        self.lambda_ = params['lambda']\n",
    "\n",
    "        self.user_embeds = nn.Embedding(self.user_num, self.embedding_dim)\n",
    "        self.item_embeds = nn.Embedding(self.item_num, self.embedding_dim)\n",
    "\n",
    "        self.constraint_mat = constraint_mat\n",
    "        self.ii_constraint_mat = ii_constraint_mat.to(device)\n",
    "        self.ii_neighbor_mat = ii_neighbor_mat.to(device)\n",
    "\n",
    "        self.initial_weight = params['initial_weight']\n",
    "        self.initial_weights()\n",
    "\n",
    "    def initial_weights(self):\n",
    "        nn.init.normal_(self.user_embeds.weight, std=self.initial_weight)\n",
    "        nn.init.normal_(self.item_embeds.weight, std=self.initial_weight)\n",
    "\n",
    "    def get_omegas(self, users, pos_items, neg_items):\n",
    "        device = self.get_device()\n",
    "        #users=users.to('cpu')\n",
    "        #pos_items=pos_items.to('cpu')\n",
    "        self.constraint_mat['beta_uD']=self.constraint_mat['beta_uD'].to(device)\n",
    "        self.constraint_mat['beta_iD']=self.constraint_mat['beta_iD'].to(device)\n",
    "\n",
    "        if self.w2 > 0:\n",
    "            pos_weight = torch.mul(self.constraint_mat['beta_uD'][users], self.constraint_mat['beta_iD'][pos_items]).to(device)\n",
    "            pos_weight = self.w1 + self.w2 * pos_weight\n",
    "        else:\n",
    "            pos_weight = self.w1 * torch.ones(len(pos_items)).to(device)\n",
    "        \n",
    "        # users = (users * self.item_num).unsqueeze(0)\n",
    "        if self.w4 > 0:\n",
    "            neg_weight = torch.mul(torch.repeat_interleave(self.constraint_mat['beta_uD'][users], neg_items.size(1)), self.constraint_mat['beta_iD'][neg_items.flatten()]).to(device)\n",
    "            neg_weight = self.w3 + self.w4 * neg_weight\n",
    "        else:\n",
    "            neg_weight = self.w3 * torch.ones(neg_items.size(0) * neg_items.size(1)).to(device)\n",
    "\n",
    "\n",
    "        weight = torch.cat((pos_weight, neg_weight))\n",
    "        return weight\n",
    "\n",
    "    def cal_loss_L(self, users, pos_items, neg_items, omega_weight):\n",
    "        device = self.get_device()\n",
    "        user_embeds = self.user_embeds(users)\n",
    "        pos_embeds = self.item_embeds(pos_items)\n",
    "        neg_embeds = self.item_embeds(neg_items)\n",
    "      \n",
    "        pos_scores = (user_embeds * pos_embeds).sum(dim=-1) # batch_size\n",
    "        user_embeds = user_embeds.unsqueeze(1)\n",
    "        neg_scores = (user_embeds * neg_embeds).sum(dim=-1) # batch_size * negative_num\n",
    "\n",
    "        neg_labels = torch.zeros(neg_scores.size()).to(device)\n",
    "        neg_loss = F.binary_cross_entropy_with_logits(neg_scores, neg_labels, weight = omega_weight[len(pos_scores):].view(neg_scores.size()), reduction='none').mean(dim = -1)\n",
    "        \n",
    "        pos_labels = torch.ones(pos_scores.size()).to(device)\n",
    "        pos_loss = F.binary_cross_entropy_with_logits(pos_scores, pos_labels, weight = omega_weight[:len(pos_scores)], reduction='none')\n",
    "\n",
    "        loss = pos_loss + neg_loss * self.negative_weight\n",
    "      \n",
    "        return loss.sum()\n",
    "\n",
    "    def cal_loss_I(self, users, pos_items):\n",
    "        device = self.get_device()\n",
    "        neighbor_embeds = self.item_embeds(self.ii_neighbor_mat[pos_items].to(device))    # len(pos_items) * num_neighbors * dim\n",
    "        sim_scores = self.ii_constraint_mat[pos_items].to(device)     # len(pos_items) * num_neighbors\n",
    "        user_embeds = self.user_embeds(users).unsqueeze(1)\n",
    "        \n",
    "        loss = -sim_scores * (user_embeds * neighbor_embeds).sum(dim=-1).sigmoid().log()\n",
    "      \n",
    "        # loss = loss.sum(-1)\n",
    "        return loss.sum()\n",
    "\n",
    "    def norm_loss(self):\n",
    "        loss = 0.0\n",
    "        for parameter in self.parameters():\n",
    "            loss += torch.sum(parameter ** 2)\n",
    "        return loss / 2\n",
    "\n",
    "    def forward(self, users, pos_items, neg_items):\n",
    "        omega_weight = self.get_omegas(users, pos_items, neg_items)\n",
    "        \n",
    "        loss = self.cal_loss_L(users, pos_items, neg_items, omega_weight)\n",
    "        loss += self.gamma * self.norm_loss()\n",
    "        loss += self.lambda_ * self.cal_loss_I(users, pos_items)\n",
    "        return loss\n",
    "\n",
    "    def test_foward(self, users):\n",
    "        items = torch.arange(self.item_num).to(users.device)\n",
    "        user_embeds = self.user_embeds(users)\n",
    "        item_embeds = self.item_embeds(items)\n",
    "         \n",
    "        return user_embeds.mm(item_embeds.t())\n",
    "    \n",
    "    def my_test_foward(self, users,targets):\n",
    "        #items = torch.arange(self.item_num).to(users.device)\n",
    "        user_embeds = self.user_embeds(users).unsqueeze(1)#[b,1,h]\n",
    "        tar_item_embeds = self.item_embeds(targets).unsqueeze(1)#[b,1,h]\n",
    "        #print(tar_item_embeds.shape)\n",
    "        #neg_indx = torch.randint(low=1, high=self.item_num, size=(tar_item_embeds.shape[0], 1000)).to(users.device)  \n",
    "        neg_indx = torch.arange(self.item_num).to(users.device).unsqueeze(0)\n",
    "        neg_item_embeds = self.item_embeds(neg_indx).expand(tar_item_embeds.shape[0], -1, -1)\n",
    "        #print(neg_item_embeds.shape)\n",
    "        test_item_embeds=torch.cat([tar_item_embeds,neg_item_embeds],dim=1)#[b,1+1000,h]\n",
    "        #print('user_embeds',user_embeds.shape)\n",
    "        #print('test_item_embeds',test_item_embeds.shape)\n",
    "        \n",
    "        return torch.matmul(user_embeds,neg_item_embeds.transpose(1,2)).squeeze(1),\\\n",
    "    torch.matmul(user_embeds,tar_item_embeds.transpose(1,2)).squeeze(1)\n",
    "    \n",
    "\n",
    "    def get_device(self):\n",
    "        return self.user_embeds.weight.device\n",
    "\n",
    "\n",
    "########################### TRAINING #####################################\n",
    "\n",
    "def train(model, optimizer, train_loader, test_loader, mask, test_ground_truth_list, interacted_items, params): \n",
    "    device = params['device']\n",
    "    best_epoch, best_recall, best_ndcg, best_hr = 0, 0, 0, 0\n",
    "    early_stop_count = 0\n",
    "    early_stop = False\n",
    "\n",
    "    batches = len(train_loader.dataset) // params['batch_size']\n",
    "    if len(train_loader.dataset) % params['batch_size'] != 0:\n",
    "        batches += 1\n",
    "    print('Total training batches = {}'.format(batches))\n",
    "    \n",
    "    if params['enable_tensorboard']:\n",
    "        writer = SummaryWriter()\n",
    "\n",
    "    for epoch in range(params['max_epoch']):\n",
    "        model.train() \n",
    "        start_time = time.time()\n",
    "        print('epoch:',epoch)\n",
    "        \n",
    "        for batch, x in enumerate(train_loader): # x: tensor:[users, pos_items]\n",
    "            users, pos_items, neg_items = Sampling(x, params['item_num'], params['negative_num'], interacted_items, params['sampling_sift_pos'])\n",
    "            users = users.to(device)\n",
    "            pos_items = pos_items.to(device)\n",
    "            neg_items = neg_items.to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss = model(users, pos_items, neg_items)\n",
    "            if params['enable_tensorboard']:\n",
    "                writer.add_scalar(\"Loss/train_batch\", loss, batches * epoch + batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_time = time.strftime(\"%H: %M: %S\", time.gmtime(time.time() - start_time))\n",
    "        if params['enable_tensorboard']:\n",
    "            writer.add_scalar(\"Loss/train_epoch\", loss, epoch)\n",
    "\n",
    "        need_test = True\n",
    "        '''\n",
    "        if epoch < 50 and epoch % 5 != 0:\n",
    "            need_test = False\n",
    "        '''\n",
    "        if need_test:\n",
    "            start_time = time.time()\n",
    "            f_hr, f_mrr, f_ndcg, f_acc = my_test(model, test_loader, test_ground_truth_list, mask, params['topk'], params['user_num'])\n",
    "            if params['enable_tensorboard']:\n",
    "                writer.add_scalar('Results/recall@20', Recall, epoch)\n",
    "                writer.add_scalar('Results/ndcg@20', NDCG, epoch)\n",
    "            test_time = time.strftime(\"%H: %M: %S\", time.gmtime(time.time() - start_time))\n",
    "            \n",
    "            print('The time for epoch {} is: train time = {}, test time = {}'.format(epoch, train_time, test_time))\n",
    "            print(\"Loss = {:.5f}, hr: {:5f} \\t mrr: {:.5f}\\t ndcg: {:.5f}\\t acc: {:.5f}\".format(loss.item(), f_hr, f_mrr, f_ndcg, f_acc))\n",
    "\n",
    "            if f_hr > best_hr:\n",
    "                best_hr, best_mrr, best_ndcg,best_acc, best_epoch = f_hr, f_mrr, f_ndcg, f_acc, epoch\n",
    "                early_stop_count = 0\n",
    "                torch.save(model.state_dict(), params['model_save_path'])\n",
    "\n",
    "            else:\n",
    "                early_stop_count += 1\n",
    "                if early_stop_count == params['early_stop_epoch']:\n",
    "                    early_stop = True\n",
    "        \n",
    "        if early_stop:\n",
    "            print('##########################################')\n",
    "            print('Early stop is triggered at {} epochs.'.format(epoch))\n",
    "            print('Results:')\n",
    "            print('best epoch = {}, best recall = {}, best ndcg = {}'.format(best_epoch, best_recall, best_ndcg))\n",
    "            print('The best model is saved at {}'.format(params['model_save_path']))\n",
    "            break\n",
    "\n",
    "\n",
    "    print('Training end!')\n",
    "\n",
    "\n",
    "########################### TESTING #####################################\n",
    "\n",
    "def hit(gt_item, pred_items):\n",
    "\tif gt_item in pred_items:\n",
    "\t\treturn 1\n",
    "\treturn 0\n",
    "\n",
    "\n",
    "def ndcg(gt_item, pred_items):\n",
    "\tif gt_item in pred_items:\n",
    "\t\tindex = pred_items.index(gt_item)\n",
    "\t\treturn np.reciprocal(np.log2(index+2))\n",
    "\treturn 0\n",
    "\n",
    "\n",
    "def RecallPrecision_ATk(test_data, r, k):\n",
    "\t\"\"\"\n",
    "    test_data should be a list? cause users may have different amount of pos items. shape (test_batch, k)\n",
    "    pred_data : shape (test_batch, k) NOTE: pred_data should be pre-sorted\n",
    "    k : top-k\n",
    "    \"\"\"\n",
    "\tright_pred = r[:, :k].sum(1)\n",
    "\tprecis_n = k\n",
    "\t\n",
    "\trecall_n = np.array([len(test_data[i]) for i in range(len(test_data))])\n",
    "\trecall_n = np.where(recall_n != 0, recall_n, 1)\n",
    "\trecall = np.sum(right_pred / recall_n)\n",
    "\tprecis = np.sum(right_pred) / precis_n\n",
    "\treturn {'recall': recall, 'precision': precis}\n",
    "\n",
    "\n",
    "def MRRatK_r(r, k):\n",
    "\t\"\"\"\n",
    "    Mean Reciprocal Rank\n",
    "    \"\"\"\n",
    "\tpred_data = r[:, :k]\n",
    "\tscores = np.log2(1. / np.arange(1, k + 1))\n",
    "\tpred_data = pred_data / scores\n",
    "\tpred_data = pred_data.sum(1)\n",
    "\treturn np.sum(pred_data)\n",
    "\n",
    "\n",
    "def NDCGatK_r(test_data, r, k):\n",
    "\t\"\"\"\n",
    "    Normalized Discounted Cumulative Gain\n",
    "    rel_i = 1 or 0, so 2^{rel_i} - 1 = 1 or 0\n",
    "    \"\"\"\n",
    "\tassert len(r) == len(test_data)\n",
    "\tpred_data = r[:, :k]\n",
    "\n",
    "\ttest_matrix = np.zeros((len(pred_data), k))\n",
    "\tfor i, items in enumerate(test_data):\n",
    "\t\tlength = k if k <= len(items) else len(items)\n",
    "\t\ttest_matrix[i, :length] = 1\n",
    "\tmax_r = test_matrix\n",
    "\tidcg = np.sum(max_r * 1. / np.log2(np.arange(2, k + 2)), axis=1)\n",
    "\tdcg = pred_data * (1. / np.log2(np.arange(2, k + 2)))\n",
    "\tdcg = np.sum(dcg, axis=1)\n",
    "\tidcg[idcg == 0.] = 1.\n",
    "\tndcg = dcg / idcg\n",
    "\tndcg[np.isnan(ndcg)] = 0.\n",
    "\treturn np.sum(ndcg)\n",
    "\n",
    "\n",
    "def test_one_batch(X, k):\n",
    "    X_0=X[0].cpu()#rating\n",
    "    sorted_items = X_0.numpy()\n",
    "    groundTrue = X[1]#ground_true\n",
    "    r = getLabel(groundTrue, sorted_items)\n",
    "    ret = RecallPrecision_ATk(groundTrue, r, k)\n",
    "    return ret['precision'], ret['recall'], NDCGatK_r(groundTrue,r,k) ,MRRatK_r\n",
    "\n",
    "def getLabel(test_data, pred_data):\n",
    "    r = []\n",
    "    for i in range(len(test_data)):\n",
    "        groundTrue = test_data[i]\n",
    "        predictTopK = pred_data[i]\n",
    "        pred = list(map(lambda x: x in groundTrue, predictTopK))\n",
    "        pred = np.array(pred).astype(\"float\")\n",
    "        r.append(pred)\n",
    "    return np.array(r).astype('float')\n",
    "\n",
    "def hr(rank, k):\n",
    "    \"\"\"Hit Rate.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: hit rate.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1\n",
    "    return res / len(rank)\n",
    "\n",
    "\n",
    "def mrr(rank, k):\n",
    "    \"\"\"Mean Reciprocal Rank.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: mrr.\n",
    "    \"\"\"\n",
    "    mrr = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            mrr += 1 / (r + 1)\n",
    "    return mrr / len(rank)\n",
    "\n",
    "\n",
    "def ndcg(rank, k):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: ndcg.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1 / np.log2(r + 2)\n",
    "    return res / len(rank)\n",
    "\n",
    "\n",
    "def my_test_one_batch(X, k):\n",
    "    X_0=X[0].cpu()#rating\n",
    "    sorted_items = X_0.numpy()\n",
    "    groundTrue = X[1]#ground_true\n",
    "    rank=[]\n",
    "    ave_dict={'hr':[],'mrr':[],'ndcg':[],'precision':[]}\n",
    "    print('rating shape:',sorted_items.shape)\n",
    "    for idx,x in enumerate(groundTrue):\n",
    "        for target in x:\n",
    "            if target in list(sorted_items[idx]):\n",
    "                rank.append(list(sorted_items[idx]).index(target))\n",
    "            else:\n",
    "                rank.append(1000)\n",
    "    res_1 = hr(rank, k)\n",
    "    res_2 = ndcg(rank, k)\n",
    "    res_3 = mrr(rank, k)\n",
    "    res_4 = hr(rank, 1)\n",
    "    return res_1,res_2,res_3,res_4\n",
    "            \n",
    "def my_test(model, test_loader, test_ground_truth_list, mask, topk, n_user):\n",
    "    users_list = []\n",
    "    rating_list = []\n",
    "    groundTrue_list = []\n",
    "    hr_b,mrr_b,ndcg_b,acc_b=[],[],[],[]\n",
    "    mask=mask.to(model.get_device())\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for idx, (batch_users,batch_target) in enumerate(test_loader):\n",
    "            \n",
    "            batch_users = batch_users.to(model.get_device())\n",
    "            batch_target = batch_target.to(model.get_device())\n",
    "            all_rating,pos_rating = model.my_test_foward(batch_users,batch_target)\n",
    "            print('rating shape:',all_rating.shape,pos_rating.shape)\n",
    "            #rating = rating.cpu()\n",
    "            #all_rating += mask[batch_users]\n",
    "            rating=-torch.cat([pos_rating,all_rating],dim=1)\n",
    "            print('rating shape:',rating.shape)\n",
    "            #rating_list.append(rating)\n",
    "            rank = rating.argsort().argsort()[:, 0]\n",
    "            \n",
    "            rank=rank.cpu()\n",
    "            res_1 = hr(rank, topk)\n",
    "            res_2 = ndcg(rank, topk)\n",
    "            res_3 = mrr(rank, topk)\n",
    "            res_4 = hr(rank, 1)\n",
    "            \n",
    "            hr_b.append(res_1)\n",
    "            ndcg_b.append(res_2)\n",
    "            mrr_b.append(res_3)\n",
    "            acc_b.append(res_4)\n",
    "            \n",
    "    f_hr=np.mean(hr_b)\n",
    "    f_mrr=np.mean(mrr_b)\n",
    "    f_ndcg=np.mean(ndcg_b)\n",
    "    f_acc=np.mean(acc_b)\n",
    "\n",
    "    return f_hr, f_mrr, f_ndcg, f_acc            \n",
    "        \n",
    "\n",
    "\n",
    "def test(model, test_loader, test_ground_truth_list, mask, topk, n_user):\n",
    "    users_list = []\n",
    "    rating_list = []\n",
    "    groundTrue_list = []\n",
    "    mask=mask.to(model.get_device())\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for idx, batch_users in enumerate(test_loader):\n",
    "            batch_users = [lbl.to(model.get_device()) for lbl in batch_users]\n",
    "\n",
    "            #batch_users = batch_users.to()\n",
    "            rating = model.test_foward(batch_users)\n",
    "            #print('rating shape:',rating.shape)\n",
    "            #rating = rating.cpu()\n",
    "            rating += mask[batch_users]\n",
    "            \n",
    "            _, rating_K = torch.topk(rating, k=topk)\n",
    "            rating_list.append(rating_K)\n",
    "\n",
    "            groundTrue_list.append([test_ground_truth_list[u] for u in batch_users])\n",
    "\n",
    "    X = zip(rating_list, groundTrue_list)\n",
    "    Recall, Precision, NDCG = 0, 0, 0\n",
    "\n",
    "    for i, x in enumerate(X):\n",
    "        #print(x[0],x[1])\n",
    "        precision, recall, ndcg = test_one_batch(x, topk)\n",
    "        Recall += recall\n",
    "        Precision += precision\n",
    "        NDCG += ndcg\n",
    "        \n",
    "    Precision /= n_user\n",
    "    Recall /= n_user\n",
    "    NDCG /= n_user\n",
    "    F1_score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "    return F1_score, Precision, Recall, NDCG\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config_file='C:/Users/Zhouziyue/workspace/tensorflow2.5_torch2.1/AAAI_feedback/gowalla/config.ini'\n",
    "\n",
    "    print('###################### UltraGCN ######################')\n",
    "\n",
    "    print('Loading Configuration...')\n",
    "    params, constraint_mat, ii_constraint_mat, ii_neighbor_mat, train_loader, test_loader, mask, test_ground_truth_list, interacted_items = data_param_prepare(config_file)\n",
    "    \n",
    "    print('Load Configuration OK, show them below')\n",
    "    print('Configuration:')\n",
    "    print(params)\n",
    "\n",
    "    ultragcn = UltraGCN(params, constraint_mat, ii_constraint_mat, ii_neighbor_mat)\n",
    "    ultragcn = ultragcn.to(params['device'])\n",
    "    optimizer = torch.optim.Adam(ultragcn.parameters(), lr=params['lr'])\n",
    "\n",
    "    train(ultragcn, optimizer, train_loader, test_loader, mask, test_ground_truth_list, interacted_items, params)\n",
    "\n",
    "    print('END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b3c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
