{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73dcde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    lr = 1e-3\n",
    "    batch = 4096\n",
    "    tstBat = 4096\n",
    "    reg = 1e-5\n",
    "    epoch = 100\n",
    "    latdim = 32\n",
    "    gnn_layer = 2\n",
    "    topk = 10\n",
    "    #data = 'yelp'\n",
    "    ssl_reg = 1\n",
    "    ib_reg = 0.01\n",
    "    temp = 0.5\n",
    "    tstEpoch = 1\n",
    "    gpu = -1\n",
    "    lambda0 = 1e-4\n",
    "    gamma = -0.45\n",
    "    zeta = 1.05\n",
    "    init_temperature = 2.0\n",
    "    temperature_decay = 0.98\n",
    "    eps = 1e-3\n",
    "    seed = 421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f89e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='gowalla'\n",
    "dataset_folder='gowalla'\n",
    "preflix_folder='24_07_30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0911bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def innerProduct(usrEmbeds, itmEmbeds):\n",
    "    return t.sum(usrEmbeds * itmEmbeds, dim=-1)\n",
    "\n",
    "def pairPredict(ancEmbeds, posEmbeds, negEmbeds):\n",
    "    return innerProduct(ancEmbeds, posEmbeds) - innerProduct(ancEmbeds, negEmbeds)\n",
    "\n",
    "def calcRegLoss(model):\n",
    "    ret = 0\n",
    "    for W in model.parameters():\n",
    "        ret += W.norm(2).square()\n",
    "    return ret\n",
    "\n",
    "def contrastLoss(embeds1, embeds2, nodes, temp):\n",
    "    embeds1 = F.normalize(embeds1, p=2)\n",
    "    embeds2 = F.normalize(embeds2, p=2)\n",
    "    pckEmbeds1 = embeds1[nodes]\n",
    "    pckEmbeds2 = embeds2[nodes]\n",
    "    nume = t.exp(t.sum(pckEmbeds1 * pckEmbeds2, dim=-1) / temp)\n",
    "    deno = t.exp(pckEmbeds1 @ embeds2.T / temp).sum(-1)\n",
    "    return -t.log(nume / deno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "589e8075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "#from Params import args\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.sparse as sp\n",
    "#from Utils.Utils import contrastLoss, calcRegLoss, pairPredict\n",
    "import time\n",
    "#import torch_sparse\n",
    "\n",
    "init = nn.init.xavier_uniform_\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.uEmbeds = nn.Parameter(init(torch.empty(args.user, args.latdim)))\n",
    "        self.iEmbeds = nn.Parameter(init(torch.empty(args.item, args.latdim)))\n",
    "        self.gcnLayers = nn.Sequential(*[GCNLayer() for i in range(args.gnn_layer)])\n",
    "\n",
    "    def forward_gcn(self, adj):\n",
    "        iniEmbeds = torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "        embedsLst = [iniEmbeds]\n",
    "        for gcn in self.gcnLayers:\n",
    "            embeds = gcn(adj, embedsLst[-1])\n",
    "            embedsLst.append(embeds)\n",
    "        mainEmbeds = sum(embedsLst)\n",
    "\n",
    "        return mainEmbeds[:args.user], mainEmbeds[args.user:]\n",
    "\n",
    "    def forward_graphcl(self, adj):\n",
    "        iniEmbeds = torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "        embedsLst = [iniEmbeds]\n",
    "        for gcn in self.gcnLayers:\n",
    "            embeds = gcn(adj, embedsLst[-1])\n",
    "            embedsLst.append(embeds)\n",
    "        mainEmbeds = sum(embedsLst)\n",
    "\n",
    "        return mainEmbeds\n",
    "\n",
    "    def forward_graphcl_(self, generator):\n",
    "        iniEmbeds = torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "        embedsLst = [iniEmbeds]\t\t\n",
    "        count = 0\n",
    "        for gcn in self.gcnLayers:\n",
    "            with torch.no_grad():\n",
    "                adj = generator.generate(x=embedsLst[-1], layer=count)\n",
    "            embeds = gcn(adj, embedsLst[-1])\n",
    "            embedsLst.append(embeds)\n",
    "            count += 1\n",
    "        mainEmbeds = sum(embedsLst)\n",
    "\n",
    "        return mainEmbeds\n",
    "\n",
    "    def loss_graphcl(self, x1, x2, users, items):\n",
    "        T = args.temp\n",
    "        user_embeddings1, item_embeddings1 = torch.split(x1, [args.user, args.item], dim=0)\n",
    "        user_embeddings2, item_embeddings2 = torch.split(x2, [args.user, args.item], dim=0)\n",
    "\n",
    "        user_embeddings1 = F.normalize(user_embeddings1, dim=1)\n",
    "        item_embeddings1 = F.normalize(item_embeddings1, dim=1)\n",
    "        user_embeddings2 = F.normalize(user_embeddings2, dim=1)\n",
    "        item_embeddings2 = F.normalize(item_embeddings2, dim=1)\n",
    "\n",
    "        user_embs1 = F.embedding(users, user_embeddings1)\n",
    "        item_embs1 = F.embedding(items, item_embeddings1)\n",
    "        user_embs2 = F.embedding(users, user_embeddings2)\n",
    "        item_embs2 = F.embedding(items, item_embeddings2)\n",
    "\n",
    "        all_embs1 = torch.cat([user_embs1, item_embs1], dim=0)\n",
    "        all_embs2 = torch.cat([user_embs2, item_embs2], dim=0)\n",
    "\n",
    "        all_embs1_abs = all_embs1.norm(dim=1)\n",
    "        all_embs2_abs = all_embs2.norm(dim=1)\n",
    "\n",
    "        sim_matrix = torch.einsum('ik,jk->ij', all_embs1, all_embs2) / torch.einsum('i,j->ij', all_embs1_abs, all_embs2_abs)\n",
    "        sim_matrix = torch.exp(sim_matrix / T)\n",
    "        pos_sim = sim_matrix[np.arange(all_embs1.shape[0]), np.arange(all_embs1.shape[0])]\n",
    "        loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)\n",
    "        loss = - torch.log(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def getEmbeds(self):\n",
    "        self.unfreeze(self.gcnLayers)\n",
    "        return torch.concat([self.uEmbeds, self.iEmbeds], axis=0)\n",
    "\n",
    "    def unfreeze(self, layer):\n",
    "        for child in layer.children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "    def getGCN(self):\n",
    "        return self.gcnLayers\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCNLayer, self).__init__()\n",
    "\n",
    "    def forward(self, adj, embeds, flag=True):\n",
    "        if (flag):\n",
    "            return torch.spmm(adj, embeds)\n",
    "        else:\n",
    "            return torch.spmm(adj, embeds)\n",
    "        #torch_sparse.spmm(adj.indices(), adj.values(), adj.shape[0], adj.shape[1], embeds)\n",
    "\n",
    "class vgae_encoder(Model):\n",
    "    def __init__(self):\n",
    "        super(vgae_encoder, self).__init__()\n",
    "        hidden = args.latdim\n",
    "        self.encoder_mean = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, hidden))\n",
    "        self.encoder_std = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, hidden), nn.Softplus())\n",
    "\n",
    "    def forward(self, adj):\n",
    "        x = self.forward_graphcl(adj)\n",
    "\n",
    "        x_mean = self.encoder_mean(x)\n",
    "        x_std = self.encoder_std(x)\n",
    "        gaussian_noise = torch.randn(x_mean.shape).cuda()\n",
    "        x = gaussian_noise * x_std + x_mean\n",
    "        return x, x_mean, x_std\n",
    "\n",
    "class vgae_decoder(nn.Module):\n",
    "    def __init__(self, hidden=args.latdim):\n",
    "        super(vgae_decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(nn.ReLU(inplace=True), nn.Linear(hidden, hidden), nn.ReLU(inplace=True), nn.Linear(hidden, 1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bceloss = nn.BCELoss(reduction='none')\n",
    "\n",
    "    def forward(self, x, x_mean, x_std, users, items, neg_items, encoder):\n",
    "        x_user, x_item = torch.split(x, [args.user, args.item], dim=0)\n",
    "\n",
    "        edge_pos_pred = self.sigmoid(self.decoder(x_user[users] * x_item[items]))\n",
    "        edge_neg_pred = self.sigmoid(self.decoder(x_user[users] * x_item[neg_items]))\n",
    "\n",
    "        loss_edge_pos = self.bceloss( edge_pos_pred, torch.ones(edge_pos_pred.shape).cuda() )\n",
    "        loss_edge_neg = self.bceloss( edge_neg_pred, torch.zeros(edge_neg_pred.shape).cuda() )\n",
    "        loss_rec = loss_edge_pos + loss_edge_neg\n",
    "\n",
    "        kl_divergence = - 0.5 * (1 + 2 * torch.log(x_std) - x_mean**2 - x_std**2).sum(dim=1)\n",
    "\n",
    "        ancEmbeds = x_user[users]\n",
    "        posEmbeds = x_item[items]\n",
    "        negEmbeds = x_item[neg_items]\n",
    "        scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "        bprLoss = - (scoreDiff).sigmoid().log().sum() / args.batch\n",
    "        regLoss = calcRegLoss(encoder) * args.reg\n",
    "\n",
    "        beta = 0.1\n",
    "        loss = (loss_rec + beta * kl_divergence.mean() + bprLoss + regLoss).mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class vgae(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(vgae, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, data, users, items, neg_items):\n",
    "        x, x_mean, x_std = self.encoder(data)\n",
    "        loss = self.decoder(x, x_mean, x_std, users, items, neg_items, self.encoder)\n",
    "        return loss\n",
    "\n",
    "    def generate(self, data, edge_index, adj):\n",
    "        x, _, _ = self.encoder(data)\n",
    "\n",
    "        edge_pred = self.decoder.sigmoid(self.decoder.decoder(x[edge_index[0]] * x[edge_index[1]]))\n",
    "\n",
    "        vals = adj._values()\n",
    "        idxs = adj._indices()\n",
    "        edgeNum = vals.size()\n",
    "        edge_pred = edge_pred[:, 0]\n",
    "        mask = ((edge_pred + 0.5).floor()).type(torch.bool)\n",
    "\n",
    "        newVals = vals[mask]\n",
    "\n",
    "        newVals = newVals / (newVals.shape[0] / edgeNum[0])\n",
    "        newIdxs = idxs[:, mask]\n",
    "\n",
    "        return torch.sparse.FloatTensor(newIdxs, newVals, adj.shape)\n",
    "\n",
    "class DenoisingNet(nn.Module):\n",
    "    def __init__(self, gcnLayers, features):\n",
    "        super(DenoisingNet, self).__init__()\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        self.gcnLayers = gcnLayers\n",
    "\n",
    "        self.edge_weights = []\n",
    "        self.nblayers = []\n",
    "        self.selflayers = []\n",
    "\n",
    "        self.attentions = []\n",
    "        self.attentions.append([])\n",
    "        self.attentions.append([])\n",
    "\n",
    "        hidden = args.latdim\n",
    "\n",
    "        self.nblayers_0 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "        self.nblayers_1 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "\n",
    "        self.selflayers_0 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "        self.selflayers_1 = nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(inplace=True))\n",
    "\n",
    "        self.attentions_0 = nn.Sequential(nn.Linear( 2 * hidden, 1))\n",
    "        self.attentions_1 = nn.Sequential(nn.Linear( 2 * hidden, 1))\n",
    "\n",
    "    def freeze(self, layer):\n",
    "        for child in layer.children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def get_attention(self, input1, input2, layer=0):\n",
    "        if layer == 0:\n",
    "            nb_layer = self.nblayers_0\n",
    "            selflayer = self.selflayers_0\n",
    "        if layer == 1:\n",
    "            nb_layer = self.nblayers_1\n",
    "            selflayer = self.selflayers_1\n",
    "\n",
    "        input1 = nb_layer(input1)\n",
    "        input2 = selflayer(input2)\n",
    "\n",
    "        input10 = torch.concat([input1, input2], axis=1)\n",
    "\n",
    "        if layer == 0:\n",
    "            weight10 = self.attentions_0(input10)\n",
    "        if layer == 1:\n",
    "            weight10 = self.attentions_1(input10)\n",
    "\n",
    "        return weight10\n",
    "\n",
    "    def hard_concrete_sample(self, log_alpha, beta=1.0, training=True):\n",
    "        gamma = args.gamma\n",
    "        zeta = args.zeta\n",
    "\n",
    "        if training:\n",
    "            debug_var = 1e-7\n",
    "            bias = 0.0\n",
    "            np_random = np.random.uniform(low=debug_var, high=1.0-debug_var, size=np.shape(log_alpha.cpu().detach().numpy()))\n",
    "            random_noise = bias + torch.tensor(np_random)\n",
    "            gate_inputs = torch.log(random_noise) - torch.log(1.0 - random_noise)\n",
    "            gate_inputs = (gate_inputs.cuda() + log_alpha) / beta\n",
    "            gate_inputs = torch.sigmoid(gate_inputs)\n",
    "        else:\n",
    "            gate_inputs = torch.sigmoid(log_alpha)\n",
    "\n",
    "        stretched_values = gate_inputs * (zeta-gamma) +gamma\n",
    "        cliped = torch.clamp(stretched_values, 0.0, 1.0)\n",
    "        return cliped.float()\n",
    "\n",
    "    def generate(self, x, layer=0):\n",
    "        f1_features = x[self.row, :]\n",
    "        f2_features = x[self.col, :]\n",
    "\n",
    "        weight = self.get_attention(f1_features, f2_features, layer)\n",
    "\n",
    "        mask = self.hard_concrete_sample(weight, training=False)\n",
    "\n",
    "        mask = torch.squeeze(mask)\n",
    "        adj = torch.sparse.FloatTensor(self.adj_mat._indices(), mask, self.adj_mat.shape)\n",
    "\n",
    "        ind = deepcopy(adj._indices())\n",
    "        row = ind[0, :]\n",
    "        col = ind[1, :]\n",
    "\n",
    "        rowsum = torch.sparse.sum(adj, dim=-1).to_dense()\n",
    "        d_inv_sqrt = torch.reshape(torch.pow(rowsum, -0.5), [-1])\n",
    "        d_inv_sqrt = torch.clamp(d_inv_sqrt, 0.0, 10.0)\n",
    "        row_inv_sqrt = d_inv_sqrt[row]\n",
    "        col_inv_sqrt = d_inv_sqrt[col]\n",
    "        values = torch.mul(adj._values(), row_inv_sqrt)\n",
    "        values = torch.mul(values, col_inv_sqrt)\n",
    "\n",
    "        support = torch.sparse.FloatTensor(adj._indices(), values, adj.shape)\n",
    "\n",
    "        return support\n",
    "\n",
    "    def l0_norm(self, log_alpha, beta):\n",
    "        gamma = args.gamma\n",
    "        zeta = args.zeta\n",
    "        gamma = torch.tensor(gamma)\n",
    "        zeta = torch.tensor(zeta)\n",
    "        reg_per_weight = torch.sigmoid(log_alpha - beta * torch.log(-gamma/zeta))\n",
    "\n",
    "        return torch.mean(reg_per_weight)\n",
    "\n",
    "    def set_fea_adj(self, nodes, adj):\n",
    "        self.node_size = nodes\n",
    "        self.adj_mat = adj\n",
    "\n",
    "        ind = deepcopy(adj._indices())\n",
    "\n",
    "        self.row = ind[0, :]\n",
    "        self.col = ind[1, :]\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            temperature = inputs\n",
    "        else:\n",
    "            temperature = 1.0\n",
    "\n",
    "        self.maskes = []\n",
    "\n",
    "        x = self.features.detach()\n",
    "        layer_index = 0\n",
    "        embedsLst = [self.features.detach()]\n",
    "\n",
    "        for layer in self.gcnLayers:\n",
    "            xs = []\n",
    "            f1_features = x[self.row, :]\n",
    "            f2_features = x[self.col, :]\n",
    "\n",
    "            weight = self.get_attention(f1_features, f2_features, layer=layer_index)\n",
    "            mask = self.hard_concrete_sample(weight, temperature, training)\n",
    "\n",
    "            self.edge_weights.append(weight)\n",
    "            self.maskes.append(mask)\n",
    "            mask = torch.squeeze(mask)\n",
    "\n",
    "            adj = torch.sparse.FloatTensor(self.adj_mat._indices(), mask, self.adj_mat.shape).coalesce()\n",
    "            ind = deepcopy(adj._indices())\n",
    "            row = ind[0, :]\n",
    "            col = ind[1, :]\n",
    "\n",
    "            rowsum = torch.sparse.sum(adj, dim=-1).to_dense() + 1e-6\n",
    "            d_inv_sqrt = torch.reshape(torch.pow(rowsum, -0.5), [-1])\n",
    "            d_inv_sqrt = torch.clamp(d_inv_sqrt, 0.0, 10.0)\n",
    "            row_inv_sqrt = d_inv_sqrt[row]\n",
    "            col_inv_sqrt = d_inv_sqrt[col]\n",
    "            values = torch.mul(adj.values(), row_inv_sqrt)\n",
    "            values = torch.mul(values, col_inv_sqrt)\n",
    "            support = torch.sparse.FloatTensor(adj._indices(), values, adj.shape).coalesce()\n",
    "\n",
    "            nextx = layer(support, x, False)\n",
    "            xs.append(nextx)\n",
    "            x = xs[0]\n",
    "            embedsLst.append(x)\n",
    "            layer_index += 1\n",
    "        return sum(embedsLst)\n",
    "\n",
    "    def lossl0(self, temperature):\n",
    "        l0_loss = torch.zeros([]).cuda()\n",
    "        for weight in self.edge_weights:\n",
    "            l0_loss += self.l0_norm(weight, temperature)\n",
    "        self.edge_weights = []\n",
    "        return l0_loss\n",
    "\n",
    "    def forward(self, users, items, neg_items, temperature):\n",
    "        self.freeze(self.gcnLayers)\n",
    "        x = self.call(temperature, True)\n",
    "        x_user, x_item = torch.split(x, [args.user, args.item], dim=0)\n",
    "        ancEmbeds = x_user[users]\n",
    "        posEmbeds = x_item[items]\n",
    "        negEmbeds = x_item[neg_items]\n",
    "        scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "        bprLoss = - (scoreDiff).sigmoid().log().sum() / args.batch\n",
    "        regLoss = calcRegLoss(self) * args.reg\n",
    "\n",
    "        lossl0 = self.lossl0(temperature) * args.lambda0\n",
    "        return bprLoss + regLoss + lossl0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84c8378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix, dok_matrix\n",
    "#from Params import args\n",
    "import scipy.sparse as sp\n",
    "#from Utils.TimeLogger import log\n",
    "import torch as t\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data as dataloader\n",
    "\n",
    "class DataHandler:\n",
    "    def __init__(self):\n",
    "        predir='E:/datasets/'+dataset_folder+'/'+dataset_name+'/'+preflix_folder+'/'\n",
    "        self.predir = predir\n",
    "        self.trnfile = predir + dataset_name+'_adagcl_train_data.pkl'\n",
    "        self.tstfile = predir + dataset_name+'_adagcl_test_data.pkl'\n",
    "\n",
    "    def loadOneFile(self, filename):\n",
    "        print(filename)\n",
    "        with open(filename, 'rb') as fs:\n",
    "            ret = (pickle.load(fs) != 0).astype(np.float32)\n",
    "        if type(ret) != coo_matrix:\n",
    "            ret = sp.coo_matrix(ret)\n",
    "        return ret\n",
    "\n",
    "    def normalizeAdj(self, mat):\n",
    "        degree = np.array(mat.sum(axis=-1))\n",
    "        dInvSqrt = np.reshape(np.power(degree, -0.5), [-1])\n",
    "        dInvSqrt[np.isinf(dInvSqrt)] = 0.0\n",
    "        dInvSqrtMat = sp.diags(dInvSqrt)\n",
    "        return mat.dot(dInvSqrtMat).transpose().dot(dInvSqrtMat).tocoo()\n",
    "\n",
    "    def makeTorchAdj(self, mat):\n",
    "        # make ui adj\n",
    "        a = sp.csr_matrix((args.user, args.user))\n",
    "        b = sp.csr_matrix((args.item, args.item))\n",
    "        mat = sp.vstack([sp.hstack([a, mat]), sp.hstack([mat.transpose(), b])])\n",
    "        mat = (mat != 0) * 1.0\n",
    "        mat = (mat + sp.eye(mat.shape[0])) * 1.0\n",
    "        mat = self.normalizeAdj(mat)\n",
    "\n",
    "        # make cuda tensor\n",
    "        idxs = t.from_numpy(np.vstack([mat.row, mat.col]).astype(np.int64))\n",
    "        vals = t.from_numpy(mat.data.astype(np.float32))\n",
    "        shape = t.Size(mat.shape)\n",
    "        return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n",
    "\n",
    "    def LoadData(self):\n",
    "        trnMat = self.loadOneFile(self.trnfile)\n",
    "        tstMat = self.loadOneFile(self.tstfile)\n",
    "        self.trnMat = trnMat\n",
    "        args.user, args.item = trnMat.shape\n",
    "        self.torchBiAdj = self.makeTorchAdj(trnMat)\n",
    "        trnData = TrnData(trnMat)\n",
    "        self.trnLoader = dataloader.DataLoader(trnData, batch_size=args.batch, shuffle=True, num_workers=0)\n",
    "        tstData = TstData(tstMat, trnMat)\n",
    "        self.tstLoader = dataloader.DataLoader(tstData, batch_size=args.tstBat, shuffle=False, num_workers=0)\n",
    "\n",
    "class TrnData(data.Dataset):\n",
    "    def __init__(self, coomat):\n",
    "        self.rows = coomat.row\n",
    "        self.cols = coomat.col\n",
    "        self.dokmat = coomat.todok()\n",
    "        self.negs = np.zeros(len(self.rows)).astype(np.int32)\n",
    "\n",
    "    def negSampling(self):\n",
    "        for i in range(len(self.rows)):\n",
    "            u = self.rows[i]\n",
    "            while True:\n",
    "                iNeg = np.random.randint(args.item)\n",
    "                if (u, iNeg) not in self.dokmat:\n",
    "                    break\n",
    "            self.negs[i] = iNeg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rows[idx], self.cols[idx], self.negs[idx]\n",
    "\n",
    "class TstData(data.Dataset):\n",
    "    def __init__(self, coomat, trnMat):\n",
    "        self.csrmat = (trnMat.tocsr() != 0) * 1.0\n",
    "\n",
    "        tstLocs = [None] * coomat.shape[0]\n",
    "        tstUsrs = set()\n",
    "        for i in range(len(coomat.data)):\n",
    "            row = coomat.row[i]\n",
    "            col = coomat.col[i]\n",
    "            if tstLocs[row] is None:\n",
    "                tstLocs[row] = list()\n",
    "            tstLocs[row].append(col)\n",
    "            tstUsrs.add(row)\n",
    "        tstUsrs = np.array(list(tstUsrs))\n",
    "        self.tstUsrs = tstUsrs\n",
    "        self.tstLocs = tstLocs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tstUsrs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tstUsrs[idx], np.reshape(self.csrmat[self.tstUsrs[idx]].toarray(), [-1]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ade36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, coo_matrix, dok_matrix\n",
    "#from Params import args\n",
    "import scipy.sparse as sp\n",
    "#from Utils.TimeLogger import log\n",
    "import torch as t\n",
    "import torch.utils.data as data\n",
    "import torch.utils.data as dataloader\n",
    "\n",
    "class my_DataHandler:\n",
    "    def __init__(self):\n",
    "        predir='E:/datasets/'+dataset_folder+'/'+dataset_name+'/'+preflix_folder+'/'\n",
    "        self.predir = predir\n",
    "        self.trnfile = predir + dataset_name+'_adagcl_train_data.pkl'\n",
    "        self.tstfile = predir + dataset_name+'_adagcl_test_data.pkl'\n",
    "\n",
    "    def loadOneFile(self, filename):\n",
    "        print(filename)\n",
    "        with open(filename, 'rb') as fs:\n",
    "            ret = (pickle.load(fs) != 0).astype(np.float32)\n",
    "        if type(ret) != coo_matrix:\n",
    "            ret = sp.coo_matrix(ret)\n",
    "        return ret\n",
    "\n",
    "    def normalizeAdj(self, mat):\n",
    "        degree = np.array(mat.sum(axis=-1))\n",
    "        dInvSqrt = np.reshape(np.power(degree, -0.5), [-1])\n",
    "        dInvSqrt[np.isinf(dInvSqrt)] = 0.0\n",
    "        dInvSqrtMat = sp.diags(dInvSqrt)\n",
    "        return mat.dot(dInvSqrtMat).transpose().dot(dInvSqrtMat).tocoo()\n",
    "\n",
    "    def makeTorchAdj(self, mat):\n",
    "        # make ui adj\n",
    "        a = sp.csr_matrix((args.user, args.user))\n",
    "        b = sp.csr_matrix((args.item, args.item))\n",
    "        mat = sp.vstack([sp.hstack([a, mat]), sp.hstack([mat.transpose(), b])])\n",
    "        mat = (mat != 0) * 1.0\n",
    "        mat = (mat + sp.eye(mat.shape[0])) * 1.0\n",
    "        mat = self.normalizeAdj(mat)\n",
    "\n",
    "        # make cuda tensor\n",
    "        idxs = t.from_numpy(np.vstack([mat.row, mat.col]).astype(np.int64))\n",
    "        vals = t.from_numpy(mat.data.astype(np.float32))\n",
    "        shape = t.Size(mat.shape)\n",
    "        return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n",
    "\n",
    "    def LoadData(self):\n",
    "        trnMat = self.loadOneFile(self.trnfile)\n",
    "        tstMat = self.loadOneFile(self.tstfile)\n",
    "        self.trnMat = trnMat\n",
    "        args.user, args.item = trnMat.shape\n",
    "        self.torchBiAdj = self.makeTorchAdj(trnMat)\n",
    "        trnData = TrnData(trnMat)\n",
    "        self.trnLoader = dataloader.DataLoader(trnData, batch_size=args.batch, shuffle=True, num_workers=0)\n",
    "        tstData = my_TstData(tstMat, trnMat)\n",
    "        self.tstLoader = dataloader.DataLoader(tstData, batch_size=args.tstBat, shuffle=False, num_workers=0)\n",
    "\n",
    "class TrnData(data.Dataset):\n",
    "    def __init__(self, coomat):\n",
    "        self.rows = coomat.row\n",
    "        self.cols = coomat.col\n",
    "        self.dokmat = coomat.todok()\n",
    "        self.negs = np.zeros(len(self.rows)).astype(np.int32)\n",
    "\n",
    "    def negSampling(self):\n",
    "        for i in range(len(self.rows)):\n",
    "            u = self.rows[i]\n",
    "            while True:\n",
    "                iNeg = np.random.randint(args.item)\n",
    "                if (u, iNeg) not in self.dokmat:\n",
    "                    break\n",
    "            self.negs[i] = iNeg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.rows[idx], self.cols[idx], self.negs[idx]\n",
    "\n",
    "class my_TstData(data.Dataset):\n",
    "    def __init__(self, coomat, trnMat):\n",
    "        self.csrmat = (trnMat.tocsr() != 0) * 1.0\n",
    "        tstLocs = [None] * coomat.shape[0]\n",
    "        tstUsrs = set()\n",
    "        target_user=[]\n",
    "        target_item=[]\n",
    "        for i in range(len(coomat.data)):\n",
    "            row = coomat.row[i]\n",
    "            col = coomat.col[i]\n",
    "            if tstLocs[row] is None:\n",
    "                tstLocs[row] = list()\n",
    "            tstLocs[row].append(col)\n",
    "            tstUsrs.add(row)\n",
    "            target_user.append(row)\n",
    "            target_item.append(col)\n",
    "        tstUsrs = np.array(list(tstUsrs))\n",
    "        self.tstUsrs = tstUsrs\n",
    "        self.tstLocs = tstLocs\n",
    "        self.target_user=target_user\n",
    "        self.target_item=target_item\n",
    "        print(len(self.target_user),len(self.target_item))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_user)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.target_user[idx], self.target_item[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b8b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr(rank, k):\n",
    "    \"\"\"Hit Rate.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: hit rate.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1\n",
    "    return res / len(rank)\n",
    "\n",
    "\n",
    "def mrr(rank, k):\n",
    "    \"\"\"Mean Reciprocal Rank.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: mrr.\n",
    "    \"\"\"\n",
    "    mrr = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            mrr += 1 / (r + 1)\n",
    "    return mrr / len(rank)\n",
    "\n",
    "\n",
    "def ndcg(rank, k):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: ndcg.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1 / np.log2(r + 2)\n",
    "    return res / len(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51650149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "E:/datasets/gowalla/gowalla/24_07_30/gowalla_adagcl_train_data.pkl\n",
      "E:/datasets/gowalla/gowalla/24_07_30/gowalla_adagcl_test_data.pkl\n",
      "9496 9496\n",
      "Load Data\n",
      "USER 8710 ITEM 5855\n",
      "NUM OF INTERACTIONS 35994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_19028\\2995634190.py:47: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:607.)\n",
      "  return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prepared\n",
      "Model Initialized\n",
      "Epoch 0/100, Train: Gen_1 Loss = 3.8636, Gen_2 Loss = 0.7590, BPR Loss = 0.7580, IM Loss = 8.0115, IB Loss = 0.1588, Reg Loss = 0.0014  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.003627 \t mrr: 0.00139\t ndcg: 0.00189\t acc: 0.00092\n",
      "Epoch 1/100, Train: Gen_1 Loss = 3.8380, Gen_2 Loss = 0.7590, BPR Loss = 0.7561, IM Loss = 8.0177, IB Loss = 0.1586, Reg Loss = 0.0015  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.008834 \t mrr: 0.00275\t ndcg: 0.00412\t acc: 0.00141\n",
      "Epoch 2/100, Train: Gen_1 Loss = 3.8050, Gen_2 Loss = 0.7590, BPR Loss = 0.7538, IM Loss = 7.9888, IB Loss = 0.1586, Reg Loss = 0.0015  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.013763 \t mrr: 0.00482\t ndcg: 0.00688\t acc: 0.00216\n",
      "Epoch 3/100, Train: Gen_1 Loss = 3.7824, Gen_2 Loss = 0.7589, BPR Loss = 0.7512, IM Loss = 7.9773, IB Loss = 0.1586, Reg Loss = 0.0016  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.020191 \t mrr: 0.00720\t ndcg: 0.01021\t acc: 0.00308\n",
      "Epoch 4/100, Train: Gen_1 Loss = 3.7579, Gen_2 Loss = 0.7589, BPR Loss = 0.7481, IM Loss = 7.9785, IB Loss = 0.1586, Reg Loss = 0.0017  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.028107 \t mrr: 0.00946\t ndcg: 0.01375\t acc: 0.00408\n",
      "Epoch 5/100, Train: Gen_1 Loss = 3.7562, Gen_2 Loss = 0.7588, BPR Loss = 0.7439, IM Loss = 7.9762, IB Loss = 0.1586, Reg Loss = 0.0018  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.037730 \t mrr: 0.01294\t ndcg: 0.01866\t acc: 0.00549\n",
      "Epoch 6/100, Train: Gen_1 Loss = 3.7228, Gen_2 Loss = 0.7588, BPR Loss = 0.7389, IM Loss = 7.9769, IB Loss = 0.1586, Reg Loss = 0.0020  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.044891 \t mrr: 0.01567\t ndcg: 0.02241\t acc: 0.00680\n",
      "Epoch 7/100, Train: Gen_1 Loss = 3.7066, Gen_2 Loss = 0.7588, BPR Loss = 0.7325, IM Loss = 7.9747, IB Loss = 0.1586, Reg Loss = 0.0023  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.052621 \t mrr: 0.01835\t ndcg: 0.02623\t acc: 0.00812\n",
      "Epoch 8/100, Train: Gen_1 Loss = 3.6906, Gen_2 Loss = 0.7588, BPR Loss = 0.7246, IM Loss = 7.9782, IB Loss = 0.1586, Reg Loss = 0.0027  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.057933 \t mrr: 0.02075\t ndcg: 0.02934\t acc: 0.00901\n",
      "Epoch 9/100, Train: Gen_1 Loss = 3.6606, Gen_2 Loss = 0.7587, BPR Loss = 0.7146, IM Loss = 7.9798, IB Loss = 0.1586, Reg Loss = 0.0032  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.061281 \t mrr: 0.02237\t ndcg: 0.03137\t acc: 0.01025\n",
      "Epoch 10/100, Train: Gen_1 Loss = 3.6315, Gen_2 Loss = 0.7587, BPR Loss = 0.7023, IM Loss = 7.9820, IB Loss = 0.1587, Reg Loss = 0.0038  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.070021 \t mrr: 0.02480\t ndcg: 0.03523\t acc: 0.01098\n",
      "Epoch 11/100, Train: Gen_1 Loss = 3.5440, Gen_2 Loss = 0.7586, BPR Loss = 0.6871, IM Loss = 7.9722, IB Loss = 0.1587, Reg Loss = 0.0046  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.073288 \t mrr: 0.02672\t ndcg: 0.03748\t acc: 0.01222\n",
      "Epoch 12/100, Train: Gen_1 Loss = 3.4731, Gen_2 Loss = 0.7586, BPR Loss = 0.6687, IM Loss = 7.9589, IB Loss = 0.1587, Reg Loss = 0.0056  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.077379 \t mrr: 0.02883\t ndcg: 0.04005\t acc: 0.01355\n",
      "Epoch 13/100, Train: Gen_1 Loss = 3.3997, Gen_2 Loss = 0.7586, BPR Loss = 0.6470, IM Loss = 7.9459, IB Loss = 0.1587, Reg Loss = 0.0068  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.079506 \t mrr: 0.03027\t ndcg: 0.04171\t acc: 0.01405\n",
      "Epoch 14/100, Train: Gen_1 Loss = 3.3249, Gen_2 Loss = 0.7585, BPR Loss = 0.6218, IM Loss = 7.9406, IB Loss = 0.1587, Reg Loss = 0.0083  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.085527 \t mrr: 0.03247\t ndcg: 0.04474\t acc: 0.01546\n",
      "Epoch 15/100, Train: Gen_1 Loss = 3.2686, Gen_2 Loss = 0.7585, BPR Loss = 0.5926, IM Loss = 7.9414, IB Loss = 0.1587, Reg Loss = 0.0101  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.090293 \t mrr: 0.03400\t ndcg: 0.04703\t acc: 0.01587\n",
      "Epoch 16/100, Train: Gen_1 Loss = 3.1918, Gen_2 Loss = 0.7584, BPR Loss = 0.5593, IM Loss = 7.9463, IB Loss = 0.1587, Reg Loss = 0.0122  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.093094 \t mrr: 0.03531\t ndcg: 0.04871\t acc: 0.01660\n",
      "Epoch 17/100, Train: Gen_1 Loss = 3.1679, Gen_2 Loss = 0.7584, BPR Loss = 0.5236, IM Loss = 7.9524, IB Loss = 0.1587, Reg Loss = 0.0146  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.098383 \t mrr: 0.03693\t ndcg: 0.05117\t acc: 0.01718\n",
      "Epoch 18/100, Train: Gen_1 Loss = 3.1302, Gen_2 Loss = 0.7584, BPR Loss = 0.4861, IM Loss = 7.9547, IB Loss = 0.1588, Reg Loss = 0.0173  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.104357 \t mrr: 0.03874\t ndcg: 0.05391\t acc: 0.01775\n",
      "Epoch 19/100, Train: Gen_1 Loss = 3.1128, Gen_2 Loss = 0.7583, BPR Loss = 0.4468, IM Loss = 7.9569, IB Loss = 0.1588, Reg Loss = 0.0203  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.108914 \t mrr: 0.04020\t ndcg: 0.05608\t acc: 0.01850\n",
      "Epoch 20/100, Train: Gen_1 Loss = 3.0841, Gen_2 Loss = 0.7583, BPR Loss = 0.4090, IM Loss = 7.9586, IB Loss = 0.1588, Reg Loss = 0.0234  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.113098 \t mrr: 0.04204\t ndcg: 0.05847\t acc: 0.01949\n",
      "Epoch 21/100, Train: Gen_1 Loss = 3.0447, Gen_2 Loss = 0.7582, BPR Loss = 0.3715, IM Loss = 7.9586, IB Loss = 0.1588, Reg Loss = 0.0267  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.116480 \t mrr: 0.04334\t ndcg: 0.06027\t acc: 0.01991\n",
      "Epoch 22/100, Train: Gen_1 Loss = 3.0614, Gen_2 Loss = 0.7583, BPR Loss = 0.3359, IM Loss = 7.9592, IB Loss = 0.1588, Reg Loss = 0.0301  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.119700 \t mrr: 0.04415\t ndcg: 0.06164\t acc: 0.01999\n",
      "Epoch 23/100, Train: Gen_1 Loss = 3.0132, Gen_2 Loss = 0.7582, BPR Loss = 0.3030, IM Loss = 7.9598, IB Loss = 0.1589, Reg Loss = 0.0335  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.121920 \t mrr: 0.04517\t ndcg: 0.06294\t acc: 0.02048\n",
      "Epoch 24/100, Train: Gen_1 Loss = 3.0021, Gen_2 Loss = 0.7581, BPR Loss = 0.2738, IM Loss = 7.9601, IB Loss = 0.1589, Reg Loss = 0.0370  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.124547 \t mrr: 0.04598\t ndcg: 0.06417\t acc: 0.02090\n",
      "Epoch 25/100, Train: Gen_1 Loss = 2.9870, Gen_2 Loss = 0.7580, BPR Loss = 0.2465, IM Loss = 7.9602, IB Loss = 0.1589, Reg Loss = 0.0403  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.127372 \t mrr: 0.04681\t ndcg: 0.06544\t acc: 0.02141\n",
      "Epoch 26/100, Train: Gen_1 Loss = 2.9571, Gen_2 Loss = 0.7579, BPR Loss = 0.2218, IM Loss = 7.9603, IB Loss = 0.1589, Reg Loss = 0.0436  \n",
      "rating shape: torch.Size([4096, 5856])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.129696 \t mrr: 0.04723\t ndcg: 0.06628\t acc: 0.02157\n",
      "Epoch 27/100, Train: Gen_1 Loss = 2.9689, Gen_2 Loss = 0.7579, BPR Loss = 0.1998, IM Loss = 7.9607, IB Loss = 0.1589, Reg Loss = 0.0468  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.131335 \t mrr: 0.04751\t ndcg: 0.06685\t acc: 0.02190\n",
      "Epoch 28/100, Train: Gen_1 Loss = 2.9601, Gen_2 Loss = 0.7578, BPR Loss = 0.1820, IM Loss = 7.9609, IB Loss = 0.1589, Reg Loss = 0.0499  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.133171 \t mrr: 0.04794\t ndcg: 0.06759\t acc: 0.02214\n",
      "Epoch 29/100, Train: Gen_1 Loss = 2.9229, Gen_2 Loss = 0.7576, BPR Loss = 0.1648, IM Loss = 7.9602, IB Loss = 0.1589, Reg Loss = 0.0528  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.134497 \t mrr: 0.04824\t ndcg: 0.06810\t acc: 0.02231\n",
      "Epoch 30/100, Train: Gen_1 Loss = 2.9295, Gen_2 Loss = 0.7575, BPR Loss = 0.1505, IM Loss = 7.9604, IB Loss = 0.1589, Reg Loss = 0.0555  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.134055 \t mrr: 0.04802\t ndcg: 0.06786\t acc: 0.02190\n",
      "Epoch 31/100, Train: Gen_1 Loss = 2.9042, Gen_2 Loss = 0.7575, BPR Loss = 0.1374, IM Loss = 7.9596, IB Loss = 0.1589, Reg Loss = 0.0582  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.134636 \t mrr: 0.04833\t ndcg: 0.06821\t acc: 0.02232\n",
      "Epoch 32/100, Train: Gen_1 Loss = 2.8855, Gen_2 Loss = 0.7574, BPR Loss = 0.1263, IM Loss = 7.9591, IB Loss = 0.1589, Reg Loss = 0.0607  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.136066 \t mrr: 0.04830\t ndcg: 0.06850\t acc: 0.02191\n",
      "Epoch 33/100, Train: Gen_1 Loss = 2.8860, Gen_2 Loss = 0.7572, BPR Loss = 0.1177, IM Loss = 7.9590, IB Loss = 0.1589, Reg Loss = 0.0630  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.135729 \t mrr: 0.04824\t ndcg: 0.06838\t acc: 0.02183\n",
      "Epoch 34/100, Train: Gen_1 Loss = 2.8836, Gen_2 Loss = 0.7570, BPR Loss = 0.1094, IM Loss = 7.9582, IB Loss = 0.1589, Reg Loss = 0.0652  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.134625 \t mrr: 0.04818\t ndcg: 0.06811\t acc: 0.02199\n",
      "Epoch 35/100, Train: Gen_1 Loss = 2.8792, Gen_2 Loss = 0.7570, BPR Loss = 0.1022, IM Loss = 7.9578, IB Loss = 0.1589, Reg Loss = 0.0672  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.133707 \t mrr: 0.04815\t ndcg: 0.06789\t acc: 0.02207\n",
      "Epoch 36/100, Train: Gen_1 Loss = 2.8623, Gen_2 Loss = 0.7569, BPR Loss = 0.0957, IM Loss = 7.9568, IB Loss = 0.1589, Reg Loss = 0.0692  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.134962 \t mrr: 0.04835\t ndcg: 0.06829\t acc: 0.02241\n",
      "Epoch 37/100, Train: Gen_1 Loss = 2.8371, Gen_2 Loss = 0.7568, BPR Loss = 0.0911, IM Loss = 7.9565, IB Loss = 0.1589, Reg Loss = 0.0710  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.133800 \t mrr: 0.04807\t ndcg: 0.06783\t acc: 0.02217\n",
      "Epoch 38/100, Train: Gen_1 Loss = 2.8638, Gen_2 Loss = 0.7566, BPR Loss = 0.0858, IM Loss = 7.9558, IB Loss = 0.1589, Reg Loss = 0.0727  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.133056 \t mrr: 0.04789\t ndcg: 0.06753\t acc: 0.02217\n",
      "Epoch 39/100, Train: Gen_1 Loss = 2.8244, Gen_2 Loss = 0.7566, BPR Loss = 0.0813, IM Loss = 7.9555, IB Loss = 0.1589, Reg Loss = 0.0743  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.131615 \t mrr: 0.04781\t ndcg: 0.06714\t acc: 0.02250\n",
      "Epoch 40/100, Train: Gen_1 Loss = 2.8226, Gen_2 Loss = 0.7564, BPR Loss = 0.0776, IM Loss = 7.9547, IB Loss = 0.1589, Reg Loss = 0.0758  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.131615 \t mrr: 0.04762\t ndcg: 0.06699\t acc: 0.02234\n",
      "Epoch 41/100, Train: Gen_1 Loss = 2.8149, Gen_2 Loss = 0.7561, BPR Loss = 0.0738, IM Loss = 7.9546, IB Loss = 0.1589, Reg Loss = 0.0772  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.130789 \t mrr: 0.04739\t ndcg: 0.06662\t acc: 0.02226\n",
      "Epoch 42/100, Train: Gen_1 Loss = 2.8197, Gen_2 Loss = 0.7561, BPR Loss = 0.0705, IM Loss = 7.9539, IB Loss = 0.1588, Reg Loss = 0.0785  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.130441 \t mrr: 0.04725\t ndcg: 0.06644\t acc: 0.02218\n",
      "Epoch 43/100, Train: Gen_1 Loss = 2.8102, Gen_2 Loss = 0.7558, BPR Loss = 0.0685, IM Loss = 7.9538, IB Loss = 0.1588, Reg Loss = 0.0797  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([1304, 5856])\n",
      "hr: 0.129616 \t mrr: 0.04705\t ndcg: 0.06610\t acc: 0.02218\n",
      "Epoch 44/100, Train: Gen_1 Loss = 2.8149, Gen_2 Loss = 0.7555, BPR Loss = 0.0658, IM Loss = 7.9532, IB Loss = 0.1588, Reg Loss = 0.0809  \n",
      "rating shape: torch.Size([4096, 5856])\n",
      "rating shape: torch.Size([4096, 5856])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 256\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    255\u001b[0m coach \u001b[38;5;241m=\u001b[39m Coach(handler)\n\u001b[1;32m--> 256\u001b[0m coach\u001b[38;5;241m.\u001b[39mrun()\n",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m, in \u001b[0;36mCoach.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakePrint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m, ep, reses, tstFlag))\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tstFlag:\n\u001b[1;32m---> 51\u001b[0m     f_hr, f_mrr, f_ndcg, f_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestEpoch()\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhr: \u001b[39m\u001b[38;5;132;01m{:5f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m mrr: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m ndcg: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m acc: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(f_hr, f_mrr, f_ndcg, f_acc))\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (f_mrr \u001b[38;5;241m>\u001b[39m mrrMax):\n",
      "Cell \u001b[1;32mIn[8], line 185\u001b[0m, in \u001b[0;36mCoach.testEpoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating shape:\u001b[39m\u001b[38;5;124m'\u001b[39m,allPreds\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    184\u001b[0m rank \u001b[38;5;241m=\u001b[39m allPreds\u001b[38;5;241m.\u001b[39margsort()\u001b[38;5;241m.\u001b[39margsort()[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 185\u001b[0m rank\u001b[38;5;241m=\u001b[39mrank\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    186\u001b[0m res_1 \u001b[38;5;241m=\u001b[39m hr(rank, args\u001b[38;5;241m.\u001b[39mtopk)\n\u001b[0;32m    187\u001b[0m res_2 \u001b[38;5;241m=\u001b[39m ndcg(rank, args\u001b[38;5;241m.\u001b[39mtopk)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import Utils.TimeLogger as logger\n",
    "#from Utils.TimeLogger import log\n",
    "#from Params import args\n",
    "#from Model import Model, vgae_encoder, vgae_decoder, vgae, DenoisingNet\n",
    "#from DataHandler import DataHandler\n",
    "import numpy as np\n",
    "#from Utils.Utils import calcRegLoss, pairPredict\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import scipy.sparse as sp\n",
    "import random\n",
    "\n",
    "class Coach:\n",
    "    def __init__(self, handler):\n",
    "        self.handler = handler\n",
    "\n",
    "        print('USER', args.user, 'ITEM', args.item)\n",
    "        print('NUM OF INTERACTIONS', self.handler.trnLoader.dataset.__len__())\n",
    "        self.metrics = dict()\n",
    "        mets = ['Loss', 'preLoss', 'Recall', 'NDCG']\n",
    "        for met in mets:\n",
    "            self.metrics['Train' + met] = list()\n",
    "            self.metrics['Test' + met] = list()\n",
    "    def makePrint(self, name, ep, reses, save):\n",
    "        ret = 'Epoch %d/%d, %s: ' % (ep, args.epoch, name)\n",
    "        for metric in reses:\n",
    "            val = reses[metric]\n",
    "            ret += '%s = %.4f, ' % (metric, val)\n",
    "            tem = name + metric\n",
    "            if save and tem in self.metrics:\n",
    "                self.metrics[tem].append(val)\n",
    "        ret = ret[:-2] + '  '\n",
    "        return ret\n",
    "    def run(self):\n",
    "        self.prepareModel()\n",
    "        print('Model Prepared')\n",
    "\n",
    "        bestEpoch = 0\n",
    "        hrMax, mrrMax,ndcgMax, accMax=0,0,0,0\n",
    "            \n",
    "        stloc = 0\n",
    "        print('Model Initialized')\n",
    "\n",
    "        for ep in range(stloc, args.epoch):\n",
    "            temperature = max(0.05, args.init_temperature * pow(args.temperature_decay, ep))\n",
    "            tstFlag = (ep % args.tstEpoch == 0)\n",
    "            reses = self.trainEpoch(temperature)\n",
    "            print(self.makePrint('Train', ep, reses, tstFlag))\n",
    "            if tstFlag:\n",
    "                f_hr, f_mrr, f_ndcg, f_acc = self.testEpoch()\n",
    "                print(\"hr: {:5f} \\t mrr: {:.5f}\\t ndcg: {:.5f}\\t acc: {:.5f}\".format(f_hr, f_mrr, f_ndcg, f_acc))\n",
    "                if (f_mrr > mrrMax):\n",
    "                    hrMax, mrrMax,ndcgMax, accMax=f_hr, f_mrr, f_ndcg, f_acc\n",
    "                    bestEpoch = ep\n",
    "        print('Best epoch : ', bestEpoch, \"hr: {:5f} \\t mrr: {:.5f}\\t ndcg: {:.5f}\\t acc: {:.5f}\".format(f_hr, f_mrr, f_ndcg, f_acc))\n",
    "    def prepareModel(self):\n",
    "        self.model = Model().cuda()\n",
    "\n",
    "        encoder = vgae_encoder().cuda()\n",
    "        decoder = vgae_decoder().cuda()\n",
    "        self.generator_1 = vgae(encoder, decoder).cuda()\n",
    "        self.generator_2 = DenoisingNet(self.model.getGCN(), self.model.getEmbeds()).cuda()\n",
    "        self.generator_2.set_fea_adj(args.user+args.item, deepcopy(self.handler.torchBiAdj).cuda())\n",
    "\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(), lr=args.lr, weight_decay=0)\n",
    "        self.opt_gen_1 = torch.optim.Adam(self.generator_1.parameters(), lr=args.lr, weight_decay=0)\n",
    "        self.opt_gen_2 = torch.optim.Adam(filter(lambda p: p.requires_grad, self.generator_2.parameters()), lr=args.lr, weight_decay=0, eps=args.eps)\n",
    "    def trainEpoch(self, temperature):\n",
    "        trnLoader = self.handler.trnLoader\n",
    "        trnLoader.dataset.negSampling()\n",
    "        generate_loss_1, generate_loss_2, bpr_loss, im_loss, ib_loss, reg_loss = 0, 0, 0, 0, 0, 0\n",
    "        steps = trnLoader.dataset.__len__() // args.batch\n",
    "\n",
    "        for i, tem in enumerate(trnLoader):\n",
    "            data = deepcopy(self.handler.torchBiAdj).cuda()\n",
    "\n",
    "            data1 = self.generator_generate(self.generator_1)\n",
    "\n",
    "            self.opt.zero_grad()\n",
    "            self.opt_gen_1.zero_grad()\n",
    "            self.opt_gen_2.zero_grad()\n",
    "\n",
    "            ancs, poss, negs = tem\n",
    "            ancs = ancs.long().cuda()\n",
    "            poss = poss.long().cuda()\n",
    "            negs = negs.long().cuda()\n",
    "\n",
    "            out1 = self.model.forward_graphcl(data1)\n",
    "            out2 = self.model.forward_graphcl_(self.generator_2)\n",
    "\n",
    "            loss = self.model.loss_graphcl(out1, out2, ancs, poss).mean() * args.ssl_reg\n",
    "            im_loss += float(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            # info bottleneck\n",
    "            _out1 = self.model.forward_graphcl(data1)\n",
    "            _out2 = self.model.forward_graphcl_(self.generator_2)\n",
    "\n",
    "            loss_ib = self.model.loss_graphcl(_out1, out1.detach(), ancs, poss) + self.model.loss_graphcl(_out2, out2.detach(), ancs, poss)\n",
    "            loss= loss_ib.mean() * args.ib_reg\n",
    "            ib_loss += float(loss)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            # BPR\n",
    "            usrEmbeds, itmEmbeds = self.model.forward_gcn(data)\n",
    "            ancEmbeds = usrEmbeds[ancs]\n",
    "            posEmbeds = itmEmbeds[poss]\n",
    "            negEmbeds = itmEmbeds[negs]\n",
    "            scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "            bprLoss = - (scoreDiff).sigmoid().log().sum() / args.batch\n",
    "            regLoss = calcRegLoss(self.model) * args.reg\n",
    "            loss = bprLoss + regLoss\n",
    "            bpr_loss += float(bprLoss)\n",
    "            reg_loss += float(regLoss)\n",
    "            loss.backward()\n",
    "\n",
    "            loss_1 = self.generator_1(deepcopy(self.handler.torchBiAdj).cuda(), ancs, poss, negs)\n",
    "            loss_2 = self.generator_2(ancs, poss, negs, temperature)\n",
    "\n",
    "            loss = loss_1 + loss_2\n",
    "            generate_loss_1 += float(loss_1)\n",
    "            generate_loss_2 += float(loss_2)\n",
    "            loss.backward()\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt_gen_1.step()\n",
    "            self.opt_gen_2.step()\n",
    "            if False:\n",
    "                print('Step %d/%d: gen 1 : %.3f ; gen 2 : %.3f ; bpr : %.3f ; im : %.3f ; ib : %.3f ; reg : %.3f  ' % (\n",
    "                i, \n",
    "                steps,\n",
    "                generate_loss_1,\n",
    "                generate_loss_2,\n",
    "                bpr_loss,\n",
    "                im_loss,\n",
    "                ib_loss,\n",
    "                reg_loss,\n",
    "                ))\n",
    "\n",
    "        ret = dict()\n",
    "        ret['Gen_1 Loss'] = generate_loss_1 / steps\n",
    "        ret['Gen_2 Loss'] = generate_loss_2 / steps\n",
    "        ret['BPR Loss'] = bpr_loss / steps\n",
    "        ret['IM Loss'] = im_loss / steps\n",
    "        ret['IB Loss'] = ib_loss / steps\n",
    "        ret['Reg Loss'] = reg_loss / steps\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def testEpoch(self):\n",
    "        tstLoader = self.handler.tstLoader\n",
    "        epRecall, epNdcg = [0] * 2\n",
    "        i = 0\n",
    "        num = tstLoader.dataset.__len__()\n",
    "        #print('tst num',num)\n",
    "        steps = num // args.tstBat\n",
    "        hr_b,mrr_b,ndcg_b,acc_b=[],[],[],[]\n",
    "        for usr, tar_i in tstLoader:\n",
    "            i += 1\n",
    "            usr = usr.long().cuda()\n",
    "            tar_i=tar_i.long().cuda()\n",
    "            #trnMask = trnMask.cuda()\n",
    "            neg_indx = torch.arange(args.item).cuda().unsqueeze(0)\n",
    "            #neg_indx = torch.randint(low=1, high=args.item, size=(tar_i.shape[0], 1000)).cuda() \n",
    "\n",
    "            usrEmbeds, itmEmbeds = self.model.forward_gcn(self.handler.torchBiAdj)\n",
    "            \n",
    "            tar_i_emb=itmEmbeds[tar_i].unsqueeze(1)\n",
    "            tar_u_emb=usrEmbeds[usr].unsqueeze(1)\n",
    "            neg_i_emb=itmEmbeds[neg_indx].expand(tar_i_emb.shape[0], -1, -1)\n",
    "            \n",
    "            test_i_embeds=torch.cat([tar_i_emb,neg_i_emb],dim=1)\n",
    "            \n",
    "            allPreds = -torch.matmul(tar_u_emb, test_i_embeds.transpose(1,2)).squeeze(1)\n",
    "\n",
    "            print('rating shape:',allPreds.shape)\n",
    "            rank = allPreds.argsort().argsort()[:, 0]\n",
    "            rank=rank.cpu()\n",
    "            res_1 = hr(rank, args.topk)\n",
    "            res_2 = ndcg(rank, args.topk)\n",
    "            res_3 = mrr(rank, args.topk)\n",
    "            res_4 = hr(rank, 1)\n",
    "            \n",
    "            hr_b.append(res_1)\n",
    "            ndcg_b.append(res_2)\n",
    "            mrr_b.append(res_3)\n",
    "            acc_b.append(res_4)\n",
    "            \n",
    "        f_hr=np.mean(hr_b)\n",
    "        f_mrr=np.mean(mrr_b)\n",
    "        f_ndcg=np.mean(ndcg_b)\n",
    "        f_acc=np.mean(acc_b)\n",
    "\n",
    "        return f_hr, f_mrr, f_ndcg, f_acc\n",
    "\n",
    "    def calcRes(self, topLocs, tstLocs, batIds):\n",
    "        assert topLocs.shape[0] == len(batIds)\n",
    "        allRecall = allNdcg = 0\n",
    "        for i in range(len(batIds)):\n",
    "            temTopLocs = list(topLocs[i])\n",
    "            temTstLocs = tstLocs[batIds[i]]\n",
    "            tstNum = len(temTstLocs)\n",
    "            maxDcg = np.sum([np.reciprocal(np.log2(loc + 2)) for loc in range(min(tstNum, args.topk))])\n",
    "            recall = dcg = 0\n",
    "            for val in temTstLocs:\n",
    "                if val in temTopLocs:\n",
    "                    recall += 1\n",
    "                    dcg += np.reciprocal(np.log2(temTopLocs.index(val) + 2))\n",
    "            recall = recall / tstNum\n",
    "            ndcg = dcg / maxDcg\n",
    "            allRecall += recall\n",
    "            allNdcg += ndcg\n",
    "        return allRecall, allNdcg\n",
    "\n",
    "    def generator_generate(self, generator):\n",
    "        edge_index = []\n",
    "        edge_index.append([])\n",
    "        edge_index.append([])\n",
    "        adj = deepcopy(self.handler.torchBiAdj)\n",
    "        idxs = adj._indices()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            view = generator.generate(self.handler.torchBiAdj, idxs, adj)\n",
    "\n",
    "        return view\n",
    "\n",
    "def seed_it(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with torch.cuda.device(args.gpu):\n",
    "        #logger.saveDefault = True\n",
    "        seed_it(args.seed)\n",
    "\n",
    "        print('Start')\n",
    "        handler = my_DataHandler()\n",
    "        handler.LoadData()\n",
    "        print('Load Data')\n",
    "\n",
    "        coach = Coach(handler)\n",
    "        coach.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963087bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch=39"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
