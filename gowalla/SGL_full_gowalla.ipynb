{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acdc1e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import OrderedDict, defaultdict#, Iterable\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from torch.utils.data import dataloader\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc37b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad48209",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/Zhouziyue/workspace/tensorflow2.5_torch2.1/AAAI_feedback/gowalla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32e5f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(arg):\n",
    "    parser = argparse.ArgumentParser(description='Model Params')\n",
    "\n",
    "    # for gcn\n",
    "    parser.add_argument('--embed_dim', default=64, type=int)\n",
    "    parser.add_argument('--layer_num', default=3, type=int)\n",
    "\n",
    "    # for ssl\n",
    "    parser.add_argument('--SSL_reg', default=0.1, type=float)\n",
    "    parser.add_argument('--SSL_dropout_ratio', default=0.1, type=float)\n",
    "    parser.add_argument('--SSL_temp', default=0.2, type=float)\n",
    "\n",
    "    # for train\n",
    "    parser.add_argument('--batch_size', default=2048, type=int)\n",
    "    parser.add_argument('--epoch_num', default=500, type=int)\n",
    "    parser.add_argument('--stop_cnt', default=10, type=int)\n",
    "    parser.add_argument('--lr', default=0.001, type=float)\n",
    "    parser.add_argument('--reg', default=0.0001, type=float)\n",
    "\n",
    "    # for test\n",
    "    parser.add_argument('--k', default=10, type=int)\n",
    "\n",
    "    # for save and read\n",
    "    parser.add_argument('--train_data_path', default=path+'/train_imp.csv', type=str)\n",
    "    parser.add_argument('--test_data_path', default=path+'/test_imp.csv', type=str)\n",
    "\n",
    "    return parser.parse_args(arg)\n",
    "\n",
    "\n",
    "args = parse_args(arg=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63a6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from params import args\n",
    "\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, user_num, item_num, embed_dim, layer_num):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.user_num = user_num\n",
    "        self.item_num = item_num\n",
    "        self.embed_dim = embed_dim\n",
    "        self.layer_num = layer_num\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "        self.user_embedding = nn.Embedding(self.user_num, self.embed_dim)\n",
    "        self.item_embedding = nn.Embedding(self.item_num, self.embed_dim)\n",
    "\n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        init = torch.nn.init.xavier_uniform_\n",
    "        init(self.user_embedding.weight)\n",
    "        init(self.item_embedding.weight)\n",
    "\n",
    "    def forward(self, norm_adj):\n",
    "        ego_embedding = torch.cat([self.user_embedding.weight, self.item_embedding.weight], dim=0)\n",
    "        all_embedding = [ego_embedding]\n",
    "\n",
    "        for i in range(self.layer_num):\n",
    "            ego_embedding = torch.sparse.mm(norm_adj, ego_embedding)\n",
    "            all_embedding += [ego_embedding]\n",
    "\n",
    "        all_embedding = torch.stack(all_embedding, dim=1).mean(dim=1)\n",
    "        user_embedding, item_embedding = torch.split(all_embedding, [self.user_num, self.item_num], dim=0)\n",
    "\n",
    "        return user_embedding, item_embedding\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61c1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from params import args\n",
    "\n",
    "\n",
    "def sp_mat_to_tensor(sp_mat):\n",
    "    coo = sp_mat.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(np.asarray([coo.row, coo.col]))\n",
    "    return torch.sparse_coo_tensor(indices, coo.data, coo.shape).coalesce()\n",
    "\n",
    "\n",
    "def inner_product(x1, x2):\n",
    "    return torch.sum(torch.mul(x1, x2), dim=-1)\n",
    "\n",
    "\n",
    "def compute_bpr_loss(x1, x2):\n",
    "    #return -torch.sum(torch.log((x1.view(-1) - x2.view(-1)).sigmoid() + 1e-8))\n",
    "    return -torch.sum(F.logsigmoid(x1-x2))\n",
    "\n",
    "def compute_infoNCE_loss(x1, x2, temp):\n",
    "    return torch.logsumexp((x2 - x1[:, None]) / temp, dim=1)\n",
    "\n",
    "\n",
    "def compute_reg_loss(w1, w2, w3):\n",
    "    return 0.5 * torch.sum(torch.pow(w1, 2) + torch.pow(w2, 2) + torch.pow(w3, 2))\n",
    "\n",
    "\n",
    "def compute_metric(ratings, test_item):\n",
    "    hit = 0\n",
    "    DCG = 0.\n",
    "    iDCG = 0.\n",
    "\n",
    "    _, shoot_index = torch.topk(ratings, args.k)\n",
    "    shoot_index = shoot_index.cpu().tolist()\n",
    "\n",
    "    for i in range(len(shoot_index)):\n",
    "        if shoot_index[i] in test_item:\n",
    "            hit += 1\n",
    "            DCG += 1 / np.log2(i + 2)\n",
    "        if i < test_item.size()[0]:\n",
    "            iDCG += 1 / np.log2(i + 2)\n",
    "\n",
    "    recall = hit / test_item.size()[0]\n",
    "    NDCG = DCG / iDCG\n",
    "\n",
    "    return recall, NDCG\n",
    "\n",
    "\n",
    "def hr(rank, k):\n",
    "    \"\"\"Hit Rate.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: hit rate.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1\n",
    "    return res / len(rank)\n",
    "\n",
    "\n",
    "def mrr(rank, k):\n",
    "    \"\"\"Mean Reciprocal Rank.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: mrr.\n",
    "    \"\"\"\n",
    "    mrr = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            mrr += 1 / (r + 1)\n",
    "    return mrr / len(rank)\n",
    "\n",
    "\n",
    "def ndcg(rank, k):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain.\n",
    "    Args:\n",
    "        :param rank: A list.\n",
    "        :param k: A scalar(int).\n",
    "    :return: ndcg.\n",
    "    \"\"\"\n",
    "    res = 0.0\n",
    "    for r in rank:\n",
    "        if r < k:\n",
    "            res += 1 / np.log2(r + 2)\n",
    "    return res / len(rank)\n",
    "\n",
    "def my_compute_metric(ratings, test_item):\n",
    "    hit = 0\n",
    "    DCG = 0.\n",
    "    iDCG = 0.\n",
    "\n",
    "    _, shoot_index = torch.topk(ratings, args.k)\n",
    "    shoot_index = shoot_index.cpu().tolist()\n",
    "\n",
    "    rank=[]\n",
    "    for target in test_item:\n",
    "        if target in list(shoot_index):\n",
    "            rank.append(list(shoot_index).index(target))\n",
    "        else:\n",
    "            rank.append(1e10)\n",
    "\n",
    "    res_1 = hr(rank, args.k)\n",
    "    res_2 = ndcg(rank, args.k)\n",
    "    res_3 = mrr(rank, args.k)\n",
    "    res_4 = hr(rank, 1)\n",
    "    \n",
    "\n",
    "    return res_1,res_2,res_3,res_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffce2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from params import args\n",
    "\n",
    "\n",
    "class RecDataset_train(data.Dataset):\n",
    "    def __init__(self, data, user_num, item_num):\n",
    "        self.data = data\n",
    "        self.user_num = user_num\n",
    "        self.item_num = item_num\n",
    "\n",
    "        self.user_item_pair = self.data.values\n",
    "        self.user_index = self.user_item_pair[:, 0].flatten()\n",
    "        self.item_index = self.user_item_pair[:, 1].flatten()\n",
    "        self.interact_num = len(self.user_item_pair)\n",
    "\n",
    "        self.user_pos_dict = OrderedDict()\n",
    "        grouped_user = self.data.groupby('user')\n",
    "        for user, user_data in grouped_user:\n",
    "            self.user_pos_dict[user] = user_data['item'].to_numpy(dtype=np.int32)\n",
    "\n",
    "        self.user_list, self.pos_item_list, self.neg_item_list = self.sample()\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Sample user, pos_item, neg_item\n",
    "        \"\"\"\n",
    "        user_arr = np.array(list(self.user_pos_dict.keys()), dtype=np.int32)\n",
    "        user_list = np.random.choice(user_arr, size=self.interact_num, replace=True)\n",
    "\n",
    "        user_pos_len = defaultdict(int)\n",
    "        for u in user_list:\n",
    "            user_pos_len[u] += 1\n",
    "\n",
    "        user_pos_sample = dict()\n",
    "        user_neg_sample = dict()\n",
    "        for user, pos_len in user_pos_len.items():\n",
    "            pos_item = self.user_pos_dict[user]\n",
    "            pos_idx = np.random.choice(pos_item, size=pos_len, replace=True)\n",
    "            user_pos_sample[user] = list(pos_idx)\n",
    "\n",
    "            neg_item = np.random.randint(low=0, high=self.item_num, size=pos_len)\n",
    "            for i in range(len(neg_item)):\n",
    "                idx = neg_item[i]\n",
    "                while idx in pos_item:\n",
    "                    idx = np.random.randint(low=0, high=self.item_num)\n",
    "                neg_item[i] = idx\n",
    "            user_neg_sample[user] = list(neg_item)\n",
    "\n",
    "        pos_item_list = [user_pos_sample[user].pop() for user in user_list]\n",
    "        neg_item_list = [user_neg_sample[user].pop() for user in user_list]\n",
    "        return user_list, pos_item_list, neg_item_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.interact_num\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_list[idx], self.pos_item_list[idx], self.neg_item_list[idx]\n",
    "\n",
    "\n",
    "class RecDataset_test(data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "        self.user_item_pair = self.data.values\n",
    "\n",
    "        self.user_pos_dict = OrderedDict()\n",
    "        grouped_user = self.data.groupby('user')\n",
    "        for user, user_data in grouped_user:\n",
    "            self.user_pos_dict[user] = user_data['item'].to_numpy(dtype=np.int32)\n",
    "\n",
    "        self.user_list = np.array(list(self.user_pos_dict.keys()))  # 用户不重复\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.user_list.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_list[idx]\n",
    "\n",
    "def my_RecDataset_test(tensors_list, batch_size):\n",
    "    for i in range(0, len(tensors_list[0]), batch_size):\n",
    "        yield tensors_list[0][i:i + batch_size], tensors_list[1][i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb050ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  loss:1.5286402702331543                     bpr_loss:0.6924312114715576                     info_NCE_loss:0.8362060785293579                     reg_loss:2.9894345061620697e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 1: hr: 0.009904021280674847\n",
      "mrr: 0.0024722067173570395\n",
      "mdcg: 0.004164872262570393\n",
      "ac: 0.0005859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 41.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  loss:1.5214195251464844                     bpr_loss:0.6920197010040283                     info_NCE_loss:0.8293966054916382                     reg_loss:3.2214798011409584e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 2: hr: 0.012875647047546013\n",
      "mrr: 0.0029960444662719965\n",
      "mdcg: 0.005261441537699803\n",
      "ac: 0.000390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 45.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  loss:1.5161206722259521                     bpr_loss:0.6915963292121887                     info_NCE_loss:0.824521005153656                     reg_loss:3.4630863865459105e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 3: hr: 0.01619536042944785\n",
      "mrr: 0.0037705437280237675\n",
      "mdcg: 0.006623649481895792\n",
      "ac: 0.0001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 42.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  loss:1.5133748054504395                     bpr_loss:0.6911638975143433                     info_NCE_loss:0.8222070336341858                     reg_loss:3.709655402417411e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 4: hr: 0.017632045628834355\n",
      "mrr: 0.0040957387536764145\n",
      "mdcg: 0.007197381735175662\n",
      "ac: 0.0001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 48.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  loss:1.511637806892395                     bpr_loss:0.690710186958313                     info_NCE_loss:0.8209235668182373                     reg_loss:3.972638296545483e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 5: hr: 0.01961273006134969\n",
      "mrr: 0.004511501174420118\n",
      "mdcg: 0.007966017589129322\n",
      "ac: 0.00029296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 49.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  loss:1.509986162185669                     bpr_loss:0.6902310848236084                     info_NCE_loss:0.819750964641571                     reg_loss:4.259863544575637e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 6: hr: 0.019905698811349692\n",
      "mrr: 0.004760093986988068\n",
      "mdcg: 0.008235110634473887\n",
      "ac: 0.0005439992331288344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 55.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  loss:1.5083842277526855                     bpr_loss:0.6897238492965698                     info_NCE_loss:0.8186556696891785                     reg_loss:4.578759217110928e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 7: hr: 0.019529452645705523\n",
      "mrr: 0.004479072522372007\n",
      "mdcg: 0.007917313559036748\n",
      "ac: 0.0004463429831288343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 52.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  loss:1.5072216987609863                     bpr_loss:0.6891680955886841                     info_NCE_loss:0.8180485367774963                     reg_loss:4.941368842992233e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 8: hr: 0.01925026361196319\n",
      "mrr: 0.0043317838571965694\n",
      "mdcg: 0.00773817094314906\n",
      "ac: 0.00034868673312883435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 51.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:  loss:1.5059250593185425                     bpr_loss:0.6885450482368469                     info_NCE_loss:0.8173748254776001                     reg_loss:5.350452738639433e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 9: hr: 0.018329419095092024\n",
      "mrr: 0.004177154507488012\n",
      "mdcg: 0.0074107815896654146\n",
      "ac: 0.00034868673312883435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 38.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  loss:1.5049468278884888                     bpr_loss:0.6878482699394226                     info_NCE_loss:0.817092776298523                     reg_loss:5.812878953292966e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 10: hr: 0.01740857457822086\n",
      "mrr: 0.004028273280709982\n",
      "mdcg: 0.007077243231903091\n",
      "ac: 0.0004463429831288343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 50.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11:  loss:1.5037636756896973                     bpr_loss:0.687040388584137                     info_NCE_loss:0.8167169094085693                     reg_loss:6.34315392744611e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 11: hr: 0.017325297162576685\n",
      "mrr: 0.0038301318418234587\n",
      "mdcg: 0.006882965420784241\n",
      "ac: 0.0004463429831288343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 51.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12:  loss:1.5027706623077393                     bpr_loss:0.6861029267311096                     info_NCE_loss:0.8166608214378357                     reg_loss:6.94900563757983e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 12: hr: 0.015093582246932516\n",
      "mrr: 0.0035304694902151823\n",
      "mdcg: 0.00616073696726723\n",
      "ac: 0.0005020609662576686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 53.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  loss:1.5012606382369995                     bpr_loss:0.6850166916847229                     info_NCE_loss:0.8162361979484558                     reg_loss:7.643848221050575e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 13: hr: 0.01565136119631902\n",
      "mrr: 0.0035936259664595127\n",
      "mdcg: 0.006327927847379318\n",
      "ac: 0.0004463429831288343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 48.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:  loss:1.4997034072875977                     bpr_loss:0.6837472915649414                     info_NCE_loss:0.8159476518630981                     reg_loss:8.447934305877425e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 14: hr: 0.01545604869631902\n",
      "mrr: 0.0033980868756771088\n",
      "mdcg: 0.006135480760650115\n",
      "ac: 0.0001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 43.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15:  loss:1.4982867240905762                     bpr_loss:0.6822543740272522                     info_NCE_loss:0.8160231709480286                     reg_loss:9.385316843690816e-06\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhouziyue\\AppData\\Local\\Temp\\ipykernel_33728\\2660727092.py:266: RuntimeWarning: divide by zero encountered in power\n",
      "  d = np.power(row_sum, -0.5).flatten()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1304, 5856])\n",
      "Epoch 15: hr: 0.015107361963190184\n",
      "mrr: 0.0034028813242912292\n",
      "mdcg: 0.006063800804175616\n",
      "ac: 0.00029296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 52.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16:  loss:1.4964145421981812                     bpr_loss:0.6805011630058289                     info_NCE_loss:0.8159028887748718                     reg_loss:1.0480728633410763e-05\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([2048, 5856])\n",
      "torch.Size([1304, 5856])\n",
      "Epoch 16: hr: 0.015009705713190182\n",
      "mrr: 0.0034475799184292555\n",
      "mdcg: 0.006086454438874954\n",
      "ac: 0.0001953125\n",
      "Early stop at 6: best Recall: 0, best_NDCG: 0.008235110634473887\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#from LightGCN import LightGCN\n",
    "#from dataset import RecDataset_train, RecDataset_test\n",
    "#from utils import sp_mat_to_tensor, inner_product, compute_infoNCE_loss, compute_bpr_loss, compute_reg_loss, compute_metric\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_data_path = args.train_data_path\n",
    "        self.test_data_path = args.test_data_path\n",
    "        self.behavior_mats = {}\n",
    "        self.behavior_mats_T = {}\n",
    "\n",
    "        now_time = datetime.datetime.now()\n",
    "        self.time = datetime.datetime.strftime(now_time, '%Y_%m_%d__%H_%M_%S')\n",
    "\n",
    "        self.epoch = 0\n",
    "        self.cnt = 0\n",
    "        self.train_loss = []\n",
    "        self.bpr_loss = []\n",
    "        self.infoNCE_loss = []\n",
    "        self.reg_loss = []\n",
    "        self.recall_history = []\n",
    "        self.NDCG_history = []\n",
    "        self.best_recall = 0\n",
    "        self.best_NDCG = 0\n",
    "        self.best_epoch = 0\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Load data\n",
    "        train_data = pd.read_csv(self.train_data_path,  header=0, names=['user', 'item'])\n",
    "        test_data = pd.read_csv(self.test_data_path,  header=0, names=['user', 'item'])\n",
    "        \n",
    "        all_data = pd.concat([train_data, test_data])\n",
    "        self.user_num = 8710\n",
    "        self.item_num = 5855\n",
    "\n",
    "        self.train_dataset = RecDataset_train(train_data, self.user_num, self.item_num)\n",
    "        self.train_loader = dataloader.DataLoader(self.train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                                                  num_workers=0, pin_memory=True)\n",
    "\n",
    "        self.test_dataset = RecDataset_test(test_data)\n",
    "        self.test_loader = dataloader.DataLoader(self.test_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "                                                 num_workers=0, pin_memory=True)\n",
    "\n",
    "        # Model Config\n",
    "        self.embed_dim = args.embed_dim\n",
    "        self.layer_num = args.layer_num\n",
    "        self.lr = args.lr\n",
    "        self.model = LightGCN(self.user_num, self.item_num, self.embed_dim, self.layer_num).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.graph = self.create_adj_mat(is_subgraph=False)\n",
    "        self.graph = sp_mat_to_tensor(self.graph).to(self.device)\n",
    "\n",
    "    def run(self):\n",
    "        for epoch in range(1, args.epoch_num + 1):\n",
    "            self.epoch += 1\n",
    "\n",
    "            epoch_loss, bpr_loss, infoNCE_loss, reg_loss= self.train_epoch()\n",
    "            self.train_loss.append(epoch_loss)\n",
    "            self.bpr_loss.append(bpr_loss)\n",
    "            self.infoNCE_loss.append(infoNCE_loss)\n",
    "            self.reg_loss.append(reg_loss)\n",
    "            print(f\"Epoch {self.epoch}:  loss:{epoch_loss/self.train_dataset.interact_num} \\\n",
    "                    bpr_loss:{bpr_loss/self.train_dataset.interact_num} \\\n",
    "                    info_NCE_loss:{infoNCE_loss/self.train_dataset.interact_num} \\\n",
    "                    reg_loss:{reg_loss/self.train_dataset.interact_num}\")\n",
    "\n",
    "            f_hr,f_mrr,f_ndcg,f_acc = self.test_epoch()\n",
    "            #self.recall_history.append(epoch_recall)\n",
    "            #self.NDCG_history.append(epoch_NDCG)\n",
    "            print(f\"Epoch {self.epoch}: hr: {f_hr}\\n\" + f\"mrr: {f_mrr}\\n\" + f\"mdcg: {f_ndcg}\\n\" + f\"ac: {f_acc}\")\n",
    "            #print(f\"Epoch {self.epoch}:  recall:{epoch_recall}, NDCG:{epoch_NDCG}\")\n",
    "            \n",
    "            '''\n",
    "            if epoch_recall > self.best_recall:\n",
    "                self.cnt = 0\n",
    "                self.best_recall = epoch_recall\n",
    "                self.best_epoch = self.epoch\n",
    "'''\n",
    "            if f_ndcg > self.best_NDCG:\n",
    "                self.cnt = 0\n",
    "                self.best_NDCG = f_ndcg\n",
    "                self.best_epoch = self.epoch\n",
    "            else:\n",
    "                self.cnt += 1\n",
    "            '''    \n",
    "            if epoch_recall < self.best_recall and epoch_NDCG < self.best_NDCG:\n",
    "                self.cnt += 1'''\n",
    "\n",
    "            #self.save_metrics()\n",
    "\n",
    "            if self.cnt == args.stop_cnt:\n",
    "                print(f\"Early stop at {self.best_epoch}: best Recall: {self.best_recall}, best_NDCG: {self.best_NDCG}\\n\")\n",
    "                #self.save_metrics()\n",
    "                break\n",
    "\n",
    "    def train_epoch(self):\n",
    "        epoch_loss = 0\n",
    "        epoch_bpr_loss = 0\n",
    "        epoch_infoNCE_loss = 0\n",
    "        epoch_reg_loss = 0\n",
    "        sub_graph1 = self.create_adj_mat(is_subgraph=True)\n",
    "        sub_graph1 = sp_mat_to_tensor(sub_graph1).to(self.device)\n",
    "        sub_graph2 = self.create_adj_mat(is_subgraph=True)\n",
    "        sub_graph2 = sp_mat_to_tensor(sub_graph2).to(self.device)\n",
    "\n",
    "        for batch_user, batch_pos_item, batch_neg_item in tqdm(self.train_loader):\n",
    "            batch_user = batch_user.long().to(self.device)\n",
    "            batch_pos_item = batch_pos_item.long().to(self.device)\n",
    "            batch_neg_item = batch_neg_item.long().to(self.device)\n",
    "\n",
    "            all_user_embedding, all_item_embedding = self.model(self.graph)\n",
    "            SSL_user_embedding1, SSL_item_embedding1 = self.model(sub_graph1)\n",
    "            SSL_user_embedding2, SSL_item_embedding2 = self.model(sub_graph2)\n",
    "\n",
    "            # 归一化，消除嵌入的模对相似度衡量的影响+\n",
    "            SSL_user_embedding1 = F.normalize(SSL_user_embedding1)\n",
    "            SSL_user_embedding2 = F.normalize(SSL_user_embedding2)\n",
    "            SSL_item_embedding1 = F.normalize(SSL_item_embedding1)\n",
    "            SSL_item_embedding2 = F.normalize(SSL_item_embedding2)\n",
    "\n",
    "            batch_user_embedding = all_user_embedding[batch_user]\n",
    "            batch_pos_item_embedding = all_item_embedding[batch_pos_item]\n",
    "            batch_neg_item_embedding = all_item_embedding[batch_neg_item]\n",
    "            batch_SSL_user_embedding1 = SSL_user_embedding1[batch_user]\n",
    "            batch_SSL_user_embedding2 = SSL_user_embedding2[batch_user]\n",
    "            batch_SSL_item_embedding1 = SSL_item_embedding1[batch_pos_item]\n",
    "            batch_SSL_item_embedding2 = SSL_item_embedding2[batch_pos_item]\n",
    "\n",
    "            # [batch_size]\n",
    "            pos_score = inner_product(batch_user_embedding, batch_pos_item_embedding)  # [2048]\n",
    "            neg_score = inner_product(batch_user_embedding, batch_neg_item_embedding)\n",
    "\n",
    "            # [batch_size]\n",
    "            SSL_user_pos_score = inner_product(batch_SSL_user_embedding1, batch_SSL_user_embedding2)  # 全1\n",
    "            SSL_user_neg_score = torch.matmul(batch_SSL_user_embedding1, torch.transpose(SSL_user_embedding2, 0, 1))\n",
    "\n",
    "            SSL_item_pos_score = inner_product(batch_SSL_item_embedding1, batch_SSL_item_embedding2)\n",
    "            SSL_item_neg_score = torch.matmul(batch_SSL_item_embedding1, torch.transpose(SSL_item_embedding2, 0, 1))\n",
    "\n",
    "            bpr_loss = compute_bpr_loss(pos_score, neg_score)  # 1419\n",
    "\n",
    "            infoNCE_user_loss = compute_infoNCE_loss(SSL_user_pos_score, SSL_user_neg_score, args.SSL_temp)\n",
    "            infoNCE_item_loss = compute_infoNCE_loss(SSL_item_pos_score, SSL_item_neg_score, args.SSL_temp)\n",
    "            infoNCE_loss = torch.sum(infoNCE_user_loss + infoNCE_item_loss, dim=-1)  # 22375\n",
    "\n",
    "            reg_loss = compute_reg_loss(  # 11\n",
    "                self.model.user_embedding(batch_user),\n",
    "                self.model.item_embedding(batch_pos_item),\n",
    "                self.model.item_embedding(batch_neg_item)\n",
    "            )\n",
    "\n",
    "            loss = bpr_loss + infoNCE_loss * args.SSL_reg + reg_loss * args.reg  # 3657\n",
    "            epoch_loss += loss\n",
    "            epoch_bpr_loss += bpr_loss\n",
    "            epoch_infoNCE_loss += infoNCE_loss * args.SSL_reg\n",
    "            epoch_reg_loss += reg_loss * args.reg\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return epoch_loss, epoch_bpr_loss, epoch_infoNCE_loss, epoch_reg_loss\n",
    "\n",
    "    def test_epoch(self):\n",
    "        test_user_pos_dict = self.test_dataset.user_pos_dict\n",
    "        train_user_pos_dict = self.train_dataset.user_pos_dict\n",
    "\n",
    "        epoch_recall = 0\n",
    "        epoch_NDCG = 0\n",
    "        tot = 0\n",
    "        \n",
    "        hr_b=[]\n",
    "        mrr_b=[]\n",
    "        ndcg_b=[]\n",
    "        acc_b=[]\n",
    "        #test_data = pd.read_csv(self.test_data_path,  header=0, names=['user', 'item'])\n",
    "        df_test = pd.read_csv(self.test_data_path)\n",
    "        #self.testUniqueUsers = pd.unique(df_test[\"users\"])\n",
    "        test_user = df_test[\"users\"].to_numpy()\n",
    "        test_item = df_test[\"pos_item\"].to_numpy()\n",
    "        for batch_users,batch_target in my_RecDataset_test([test_user,test_item],args.batch_size):\n",
    "            #user_num = test_user.size()[0]\n",
    "            \n",
    "            test_user = batch_users#.long().to(self.device)\n",
    "            test_item = batch_target#.long().to(self.device)\n",
    "\n",
    "            all_user_embedding, all_item_embedding = self.model(self.graph)\n",
    "            test_user_embedding = all_user_embedding[test_user].unsqueeze(1)\n",
    "            \n",
    "            tar_item_embeds = all_item_embedding[test_item].unsqueeze(1)#[b,1,h]\n",
    "            #neg_indx = torch.randint(low=1, high=self.item_num, size=(tar_item_embeds.shape[0], 1000))#.to(users.device)\n",
    "            neg_indx = torch.arange(self.item_num).cuda().unsqueeze(0)\n",
    "            neg_item_embeds = all_item_embedding[neg_indx].expand(tar_item_embeds.shape[0], -1, -1)\n",
    "            test_item_embeding=torch.cat([tar_item_embeds,neg_item_embeds],dim=1)#[b,1+1000,h]\n",
    "            \n",
    "            ratings = -torch.matmul(test_user_embedding, test_item_embeding.transpose(1,2)).squeeze(1)\n",
    "            print(ratings.shape)\n",
    "            rank = ratings.argsort().argsort()[:, 0]\n",
    "            rank=rank.cpu()\n",
    "            res_1 = hr(rank, args.k)\n",
    "            res_2 = ndcg(rank, args.k)\n",
    "            res_3 = mrr(rank, args.k)\n",
    "            res_4 = hr(rank, 1)\n",
    "            \n",
    "            hr_b.append(res_1)\n",
    "            ndcg_b.append(res_2)\n",
    "            mrr_b.append(res_3)\n",
    "            acc_b.append(res_4)\n",
    "        f_hr=np.mean(hr_b)\n",
    "        f_mrr=np.mean(mrr_b)\n",
    "        f_ndcg=np.mean(ndcg_b)\n",
    "        f_acc=np.mean(acc_b)\n",
    "        return f_hr,f_mrr,f_ndcg,f_acc\n",
    "\n",
    "        '''\n",
    "                epoch_recall += recall\n",
    "                epoch_NDCG += NDCG\n",
    "\n",
    "            tot += user_num\n",
    "\n",
    "        epoch_recall /= tot\n",
    "        epoch_NDCG /= tot\n",
    "\n",
    "        return epoch_recall, epoch_NDCG'''\n",
    "        \n",
    "\n",
    "    def create_adj_mat(self, is_subgraph):\n",
    "        node_num = self.user_num + self.item_num\n",
    "        user_np, item_np = self.train_dataset.user_index, self.train_dataset.item_index\n",
    "\n",
    "        if is_subgraph:\n",
    "            sample_size = int(user_np.shape[0]*(1-args.SSL_dropout_ratio))\n",
    "            keep_index = np.arange(user_np.shape[0])\n",
    "            np.random.shuffle(keep_index)\n",
    "            keep_index = keep_index[:sample_size]\n",
    "            # keep_index = np.random.randint(user_np.shape[0], size=3*sample_size)\n",
    "            # keep_index = np.unique(keep_index)\n",
    "            # keep_index = keep_index[:sample_size]\n",
    "            # keep_idx = np.random.randint(user_np.shape[0], size=int(user_np.shape[0]*(1-args.SSL_dropout_ratio)))\n",
    "            # keep_idx = np.random.choice(user_np, size=int(user_np.shape[0]*(1-args.SSL_dropout_ratio)), replace=False)\n",
    "            user_np = np.array(user_np)[keep_index]\n",
    "            item_np = np.array(item_np)[keep_index]\n",
    "            ratings = np.ones_like(user_np)\n",
    "            tmp_adj = sp.csr_matrix((ratings, (user_np, item_np + self.user_num)), shape=(node_num, node_num))\n",
    "\n",
    "\n",
    "            # keep_idx = np.random.choice(user, size=int(len(user) * (1 - args.SSL_dropout_ratio)), replace=True)\n",
    "            # keep_idx.tolist()\n",
    "            # sub_user = np.array(user)[keep_idx]\n",
    "            # sub_item = np.array(item)[keep_idx]\n",
    "            # # rating = np.ones_like(sub_user, dtype=np.float32)\n",
    "            # c = np.ones_like(sub_user, dtype=np.float32)\n",
    "            # c = torch.ones(sub_user.shape[0])\n",
    "            # # tmp_adj = sp.csr_matrix((rating, (sub_user, sub_item + self.user_num)), shape=(node_num, node_num))\n",
    "            # a = sp.csr_matrix( (c, (sub_user, sub_item + self.user_num)), shape=(node_num, node_num))\n",
    "            # b = sp.csr_matrix((c, (sub_user, sub_item)), shape=(node_num, node_num))\n",
    "            # tmp_adj = sp.csr_matrix((c, (sub_user, sub_item + self.user_num)), shape=(node_num, node_num))\n",
    "        else:\n",
    "            rating = np.ones_like(user_np, dtype=np.float32)\n",
    "            tmp_adj = sp.csr_matrix((rating, (user_np, item_np + self.user_num)), shape=(node_num, node_num))\n",
    "        adj = tmp_adj + tmp_adj.T\n",
    "\n",
    "        row_sum = np.array(adj.sum(1))\n",
    "        d = np.power(row_sum, -0.5).flatten()\n",
    "        d[np.isinf(d)] = 0.\n",
    "        d_mat = sp.diags(d)\n",
    "        norm_adj = d_mat.dot(adj)\n",
    "        norm_adj = norm_adj.dot(d_mat)\n",
    "\n",
    "        return norm_adj\n",
    "\n",
    "    def save_metrics(self):\n",
    "        path = './runs/' + self.time + '/' + str(self.epoch) + '/'\n",
    "        writer = SummaryWriter(path)\n",
    "        for i in range(self.epoch):\n",
    "            writer.add_scalar('Loss', self.train_loss[i], i)\n",
    "            writer.add_scalar('bpr_loss', self.bpr_loss[i], i)\n",
    "            writer.add_scalar('infoNCE_loss', self.infoNCE_loss[i], i)\n",
    "            writer.add_scalar('reg_loss', self.reg_loss[i], i)\n",
    "            writer.add_scalar('Recall', self.recall_history[i], i)\n",
    "            writer.add_scalar('NDCG', self.NDCG_history[i], i)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = Model()\n",
    "    model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48117d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
